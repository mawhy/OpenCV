{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "colab": {
      "name": "Sampling & Fourier Transform",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mawhy/OpenCV/blob/master/Sampling_%26_Fourier_Transform.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_haMaUwSALAu",
        "colab_type": "text"
      },
      "source": [
        "# Hands-on Image Processing with Python\n",
        "##Sampling & Fourier Transform "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvbmMVu4ALAv",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdCL7mfjAji-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/PacktPublishing/Hands-On-Image-Processing-with-Python.git\n",
        "%cp -av \"/content/Hands-On-Image-Processing-with-Python/images/\" \"/\"\n",
        "%rm -rf \"/content/Hands-On-Image-Processing-with-Python\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7ZtqIzfALAv",
        "colab_type": "text"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gye_ES4eALAw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "% matplotlib inline \n",
        "from PIL import Image\n",
        "from skimage.io import imread, imshow, show\n",
        "import scipy.fftpack as fp\n",
        "from scipy import ndimage, misc, signal\n",
        "#from scipy.stats import signaltonoise\n",
        "from skimage import data, img_as_float\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.transform import rescale\n",
        "import matplotlib.pylab as pylab\n",
        "import numpy as np\n",
        "import numpy.fft\n",
        "import timeit\n",
        "\n",
        "import numpy as np\n",
        "def signaltonoise(a, axis=0, ddof=0):\n",
        "    a = np.asanyarray(a)\n",
        "    m = a.mean(axis)\n",
        "    sd = a.std(axis=axis, ddof=ddof)\n",
        "    return np.where(sd == 0, 0, m/sd)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0I6D1EPALAz",
        "colab_type": "text"
      },
      "source": [
        "### Up-Sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50EUOFobALA0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "im = Image.open(\"../images/clock.jpg\") # the original small clock image\n",
        "pylab.imshow(im), pylab.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lA6VxahALA3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "im1 = im.resize((im.width*5, im.height*5), Image.NEAREST) # nearest neighbor interpolation\n",
        "pylab.figure(figsize=(10,10)), pylab.imshow(im1), pylab.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQ8rUe_eALA5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "im1 = im.resize((im.width*5, im.height*5), Image.BILINEAR) # up-sample with bi-linear interpolation\n",
        "pylab.figure(figsize=(10,10)), pylab.imshow(im1), pylab.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fh1FDFgHALA8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "im.resize((im.width*10, im.height*10), Image.BICUBIC).show() # bi-cubic interpolation\n",
        "pylab.figure(figsize=(10,10)), pylab.imshow(im1), pylab.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4n6sUNjALA-",
        "colab_type": "text"
      },
      "source": [
        "### Down-sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlttM9nkALA_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "im = Image.open(\"../images/tajmahal.jpg\")\n",
        "im"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiDpULlrALBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "im = im.resize((im.width//5, im.height//5))\n",
        "pylab.figure(figsize=(15,10)), pylab.imshow(im), pylab.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkOY2tgEALBE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "im = Image.open(\"../images/tajmahal.jpg\")\n",
        "im = im.resize((im.width//5, im.height//5), Image.ANTIALIAS)\n",
        "pylab.figure(figsize=(15,10)), pylab.imshow(im), pylab.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVIqAF71ALBG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "im = imread('../images/umbc.png')\n",
        "im1 = im.copy()\n",
        "pylab.figure(figsize=(20,15))\n",
        "for i in range(4):\n",
        "    pylab.subplot(2,2,i+1), pylab.imshow(im1, cmap='gray'), pylab.axis('off')\n",
        "    pylab.title('image size = ' + str(im1.shape[1]) + 'x' + str(im1.shape[0]))\n",
        "    im1 = rescale(im1, scale = 0.5, multichannel=True, anti_aliasing=False)\n",
        "pylab.subplots_adjust(wspace=0.1, hspace=0.1)\n",
        "pylab.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfWRTY0KALBJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "im1 = rescale(im1, scale = 0.5, multichannel=True, anti_aliasing=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAxfhPMnALBL",
        "colab_type": "text"
      },
      "source": [
        "### Quantizing with PIL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taFlAOdZALBL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "im = Image.open('../images/parrot.jpg')\n",
        "pylab.figure(figsize=(20,30))\n",
        "num_colors_list = [1 << n for n in range(8,0,-1)]\n",
        "snr_list = []\n",
        "i = 1\n",
        "for num_colors in num_colors_list:\n",
        "    im1 = im.convert('P', palette=Image.ADAPTIVE, colors=num_colors)\n",
        "    pylab.subplot(4,2,i), pylab.imshow(im1), pylab.axis('off')\n",
        "    snr_list.append(signaltonoise(im1, axis=None))\n",
        "    pylab.title('Image with # colors = ' + str(num_colors) + ' SNR = ' +\n",
        "    str(np.round(snr_list[i-1],3)), size=20)\n",
        "    i += 1\n",
        "pylab.subplots_adjust(wspace=0.2, hspace=0)\n",
        "pylab.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcdXKw3DALBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pylab.plot(num_colors_list, snr_list, 'r.-')\n",
        "pylab.xlabel('# colors in the image')\n",
        "pylab.ylabel('SNR')\n",
        "pylab.title('Change in SNR w.r.t. # colors')\n",
        "pylab.xscale('log', basex=2)\n",
        "pylab.gca().invert_xaxis()\n",
        "pylab.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFB2-qXkALBQ",
        "colab_type": "text"
      },
      "source": [
        "### FFT with the scipy.fftpack module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLrb9Nj3ALBQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "im = np.array(Image.open('../images/rhino.jpg').convert('L')) # we shall work with grayscale image\n",
        "snr = signaltonoise(im, axis=None)\n",
        "print('SNR for the original image = ' + str(snr))\n",
        "# SNR for the original image = 2.023722773801701\n",
        "# now call FFT and IFFT\n",
        "freq = fp.fft2(im)\n",
        "im1 = fp.ifft2(freq).real\n",
        "snr = signaltonoise(im1, axis=None)\n",
        "print('SNR for the image obtained after reconstruction = ' + str(snr))\n",
        "# SNR for the image obtained after reconstruction = 2.0237227738013224\n",
        "assert(np.allclose(im, im1)) # make sure the forward and inverse FFT are close to each other\n",
        "pylab.figure(figsize=(20,10))\n",
        "pylab.subplot(121), pylab.imshow(im, cmap='gray'), pylab.axis('off')\n",
        "pylab.title('Original Image', size=20)\n",
        "pylab.subplot(122), pylab.imshow(im1, cmap='gray'), pylab.axis('off')\n",
        "pylab.title('Image obtained after reconstruction', size=20)\n",
        "pylab.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZSAoFWgALBT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the quadrants are needed to be shifted around in order that the low spatial frequencies are in the center of the 2D fourier-transformed image.\n",
        "freq2 = fp.fftshift(freq)\n",
        "pylab.figure(figsize=(10,10)), pylab.imshow( (20*np.log10( 0.1 + freq2)).astype(int)), pylab.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcd0WdEAALBV",
        "colab_type": "text"
      },
      "source": [
        "### FFT with the numpy.fft module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHLHckW5ALBV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy.fft as fp\n",
        "im1 = rgb2gray(imread('../images/house.png'))\n",
        "pylab.figure(figsize=(12,10))\n",
        "freq1 = fp.fft2(im1)\n",
        "im1_ = fp.ifft2(freq1).real\n",
        "pylab.subplot(2,2,1), pylab.imshow(im1, cmap='gray'), pylab.title('Original Image', size=20)\n",
        "pylab.subplot(2,2,2), pylab.imshow(20*np.log10( 0.01 +\n",
        "np.abs(fp.fftshift(freq1))), cmap='gray')\n",
        "pylab.title('FFT Spectrum Maginitude', size=20)\n",
        "pylab.subplot(2,2,3), pylab.imshow(np.angle(fp.fftshift(freq1)),cmap='gray')\n",
        "pylab.title('FFT Phase', size=20)\n",
        "pylab.subplot(2,2,4), pylab.imshow(np.clip(im1_,0,255), cmap='gray')\n",
        "pylab.title('Reconstructed Image', size=20)\n",
        "pylab.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgRbA15pALBY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "im2 = rgb2gray(imread('../images/house2.png'))\n",
        "pylab.figure(figsize=(12,10))\n",
        "freq2 = fp.fft2(im2)\n",
        "im2_ = fp.ifft2(freq2).real\n",
        "pylab.subplot(2,2,1), pylab.imshow(im2, cmap='gray'), pylab.title('Original Image', size=20)\n",
        "pylab.subplot(2,2,2), pylab.imshow(20*np.log10( 0.01 +\n",
        "np.abs(fp.fftshift(freq2))), cmap='gray')\n",
        "pylab.title('FFT Spectrum Maginitude', size=20)\n",
        "pylab.subplot(2,2,3), pylab.imshow(np.angle(fp.fftshift(freq2)), cmap='gray')\n",
        "pylab.title('FFT Phase', size=20)\n",
        "pylab.subplot(2,2,4), pylab.imshow(np.clip(im2_,0,255), cmap='gray')\n",
        "pylab.title('Reconstructed Image', size=20)\n",
        "pylab.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn2jM6VrALBa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pylab.figure(figsize=(20,15))\n",
        "im1_ = fp.ifft2(np.vectorize(complex)(freq1.real, freq2.imag)).real\n",
        "im2_ = fp.ifft2(np.vectorize(complex)(freq2.real, freq1.imag)).real\n",
        "pylab.subplot(211), pylab.imshow(np.clip(im1_,0,255), cmap='gray')\n",
        "pylab.title('Reconstructed Image (Re(F1) + Im(F2))', size=20)\n",
        "pylab.subplot(212), pylab.imshow(np.clip(im2_,0,255), cmap='gray')\n",
        "pylab.title('Reconstructed Image (Re(F2) + Im(F1))', size=20)\n",
        "pylab.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IG2Pm9uXALBd",
        "colab_type": "text"
      },
      "source": [
        "### Applying convolution to a grayscale image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9YI2MP7ALBd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "im = rgb2gray(imread('../images/cameraman.jpg')).astype(float)\n",
        "print(np.max(im))\n",
        "print(im.shape)\n",
        "blur_box_kernel = np.ones((3,3)) / 9\n",
        "edge_laplace_kernel = np.array([[0,1,0],[1,-4,1],[0,1,0]])\n",
        "im_blurred = signal.convolve2d(im, blur_box_kernel)\n",
        "im_edges = np.clip(signal.convolve2d(im, edge_laplace_kernel), 0, 1)\n",
        "fig, axes = pylab.subplots(ncols=3, sharex=True, sharey=True, figsize=(18,6))\n",
        "axes[0].imshow(im, cmap=pylab.cm.gray)\n",
        "axes[0].set_title('Original Image', size=20)\n",
        "axes[1].imshow(im_blurred, cmap=pylab.cm.gray)\n",
        "axes[1].set_title('Box Blur', size=20)\n",
        "axes[2].imshow(im_edges, cmap=pylab.cm.gray)\n",
        "axes[2].set_title('Laplace Edge Detection', size=20)\n",
        "for ax in axes:\n",
        "    ax.axis('off')\n",
        "pylab.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjIgvw3nALBf",
        "colab_type": "text"
      },
      "source": [
        "### Applying convolution to a color (RGB) image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DANrTpHnALBf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import imageio\n",
        "im = imageio.imread('../images/tajmahal.jpg')/255 # scale each pixel value in [0,1]\n",
        "print(np.max(im))\n",
        "print(im.shape)\n",
        "emboss_kernel = np.array([[-2,-1,0],[-1,1,1],[0,1,2]])\n",
        "edge_schar_kernel = np.array([[ -3-3j, 0-10j, +3 -3j], [-10+0j, 0+ 0j, +10+0j], [ -3+3j, 0+10j, +3 +3j]])\n",
        "im_embossed = np.ones(im.shape)\n",
        "im_edges = np.ones(im.shape)\n",
        "for i in range(3):\n",
        "    im_embossed[...,i] = np.clip(signal.convolve2d(im[...,i], emboss_kernel, mode='same', boundary=\"symm\"),0,1)\n",
        "for i in range(3):\n",
        "    im_edges[:,:,i] = np.clip(np.real(signal.convolve2d(im[...,i], edge_schar_kernel, mode='same', boundary=\"symm\")),0,1)\n",
        "fig, axes = pylab.subplots(nrows=3, figsize=(20, 30))\n",
        "axes[0].imshow(im)\n",
        "axes[0].set_title('Original Image', size=20)\n",
        "axes[1].imshow(im_embossed)\n",
        "axes[1].set_title('Embossed Image', size=20)\n",
        "axes[2].imshow(im_edges)\n",
        "axes[2].set_title('Schar Edge Detection', size=20)\n",
        "for ax in axes:\n",
        "    ax.axis('off')\n",
        "pylab.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PzrKYtjALBh",
        "colab_type": "text"
      },
      "source": [
        "### Convolution with SciPy ndimage.convolve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3syyXRNVALBi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import imageio\n",
        "im = imageio.imread('../images/victoria_memorial.png').astype(np.float) # read as float\n",
        "print(np.max(im))\n",
        "sharpen_kernel = np.array([0, -1, 0, -1, 5, -1, 0, -1, 0]).reshape((3, 3, 1))\n",
        "emboss_kernel = np.array(np.array([[-2,-1,0],[-1,1,1],[0,1,2]])).reshape((3, 3, 1))\n",
        "im_sharp = ndimage.convolve(im, sharpen_kernel, mode='nearest')\n",
        "im_sharp = np.clip(im_sharp, 0, 255).astype(np.uint8) # clip (0 to 255) and convert to unsigned int\n",
        "im_emboss = ndimage.convolve(im, emboss_kernel, mode='nearest')\n",
        "im_emboss = np.clip(im_emboss, 0, 255).astype(np.uint8)\n",
        "pylab.figure(figsize=(10,15))\n",
        "pylab.subplot(311), pylab.imshow(im.astype(np.uint8)), pylab.axis('off')\n",
        "pylab.title('Original Image', size=25)\n",
        "pylab.subplot(312), pylab.imshow(im_sharp), pylab.axis('off')\n",
        "pylab.title('Sharpened Image', size=25)\n",
        "pylab.subplot(313), pylab.imshow(im_emboss), pylab.axis('off')\n",
        "pylab.title('Embossed Image', size=25)\n",
        "pylab.tight_layout()\n",
        "pylab.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9huHxIzALBk",
        "colab_type": "text"
      },
      "source": [
        "### Template matching with cross-correlation between the image and template"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h15tQJCrALBk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "face_image = misc.face(gray=True) - misc.face(gray=True).mean()\n",
        "template_image = np.copy(face_image[300:365, 670:750]) # right eye\n",
        "template_image -= template_image.mean()\n",
        "face_image = face_image + np.random.randn(*face_image.shape) * 50 # add random noise\n",
        "correlation = signal.correlate2d(face_image, template_image, boundary='symm', mode='same')\n",
        "y, x = np.unravel_index(np.argmax(correlation), correlation.shape) # find the match\n",
        "fig, (ax_original, ax_template, ax_correlation) = pylab.subplots(3, 1, figsize=(6, 15))\n",
        "ax_original.imshow(face_image, cmap='gray')\n",
        "ax_original.set_title('Original', size=20)\n",
        "ax_original.set_axis_off()\n",
        "ax_template.imshow(template_image, cmap='gray')\n",
        "ax_template.set_title('Template', size=20)\n",
        "ax_template.set_axis_off()\n",
        "ax_correlation.imshow(correlation, cmap='afmhot')\n",
        "ax_correlation.set_title('Cross-correlation', size=20)\n",
        "ax_correlation.set_axis_off()\n",
        "ax_original.plot(x, y, 'ro')\n",
        "fig.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77NHN17ZALBm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}