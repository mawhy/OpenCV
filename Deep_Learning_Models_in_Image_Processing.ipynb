{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "colab": {
      "name": "Deep Learning Models in Image Processing",
      "provenance": [],
      "collapsed_sections": [
        "34bKZrfHsCmz",
        "rjRM8v4BsCm3",
        "TSOGSIrYsCnB"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mawhy/OpenCV/blob/master/Deep_Learning_Models_in_Image_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6CfxJVKsCmO",
        "colab_type": "text"
      },
      "source": [
        "# Hands-on Image Processing with Python\n",
        "## Deep Learning Models in Image Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzJGhqmqsiBU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/PacktPublishing/Hands-On-Image-Processing-with-Python.git\n",
        "%cp -av \"/content/Hands-On-Image-Processing-with-Python/images/\" \"/\"\n",
        "\n",
        "#%rm -rf \"/content/Hands-On-Image-Processing-with-Python\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNDnzqrhtJiQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cp -av \"/content/Hands-On-Image-Processing-with-Python/Chapter10/test\" \"/content/test/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5n60_jPtYj3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cp -av \"/content/Hands-On-Image-Processing-with-Python/Chapter10/train\" \"/content/train/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3r-GnWbVsCmQ",
        "colab_type": "text"
      },
      "source": [
        "### Classification of MNIST using FC network with TF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFGGWvwTujN7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior() \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RS-iY4OxsCmQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "# import data\n",
        "from keras.datasets import mnist\n",
        "#import tensorflow as tf\n",
        "%matplotlib inline\n",
        "\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "np.random.seed(0)\n",
        "train_indices = np.random.choice(60000, 50000, replace=False)\n",
        "valid_indices = [i for i in range(60000) if i not in train_indices]\n",
        "X_valid, y_valid = X_train[valid_indices,:,:], y_train[valid_indices]\n",
        "X_train, y_train = X_train[train_indices,:,:], y_train[train_indices]\n",
        "\n",
        "print(X_train.shape, X_valid.shape, X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHOfBn3psCmV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_size = 28\n",
        "num_labels = 10\n",
        "\n",
        "def reformat(dataset, labels):\n",
        "  dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)\n",
        "  # Map 1 to [0.0, 1.0, 0.0 ...], 2 to [0.0, 0.0, 1.0 ...]\n",
        "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
        "  return dataset, labels\n",
        "X_train, y_train = reformat(X_train, y_train)\n",
        "X_valid, y_valid = reformat(X_valid, y_valid)\n",
        "X_test, y_test = reformat(X_test, y_test)\n",
        "print('Training set', X_train.shape, X_train.shape)\n",
        "print('Validation set', X_valid.shape, X_valid.shape)\n",
        "print('Test set', X_test.shape, X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbeMk0_SsCmY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(predictions, labels):\n",
        "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
        "          / predictions.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1ymzXqisCmb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 256 #128\n",
        "num_hidden_units = 1024\n",
        "lambda1 = 0.05 #0.005 #0.01\n",
        "lambda2 = 0.05 #0.005 #0.01\n",
        "    \n",
        "graph = tf.Graph()\n",
        "with graph.as_default():\n",
        "\n",
        "  # Input data. For the training data, we use a placeholder that will be fed\n",
        "  # at run time with a training minibatch.\n",
        "  tf_train_dataset = tf.placeholder(tf.float32,\n",
        "                                    shape=(batch_size, image_size * image_size))\n",
        "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
        "  tf_valid_dataset = tf.constant(X_valid)\n",
        "  tf_test_dataset = tf.constant(X_test)\n",
        "  \n",
        "  # Variables.\n",
        "  weights1 = tf.Variable(tf.truncated_normal([image_size * image_size, num_hidden_units]))\n",
        "  biases1 = tf.Variable(tf.zeros([num_hidden_units]))\n",
        "\n",
        "  # connect inputs to every hidden unit. Add bias\n",
        "  layer_1_outputs = tf.nn.relu(tf.matmul(tf_train_dataset, weights1) + biases1)\n",
        "\n",
        "  weights2 = tf.Variable(tf.truncated_normal([num_hidden_units, num_labels]))\n",
        "  biases2 = tf.Variable(tf.zeros([num_labels]))  \n",
        "\n",
        "  # Training computation.\n",
        "  logits = tf.matmul(layer_1_outputs, weights2) + biases2\n",
        "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits) + \\\n",
        "                        lambda1*tf.nn.l2_loss(weights1) + lambda2*tf.nn.l2_loss(weights2))  \n",
        "    \n",
        "  # Optimizer.\n",
        "  optimizer = tf.train.GradientDescentOptimizer(0.003).minimize(loss)\n",
        "  \n",
        "  # Predictions for the training, validation, and test data.\n",
        "  train_prediction = tf.nn.softmax(logits)\n",
        "  layer_1_outputs = tf.nn.relu(tf.matmul(tf_valid_dataset, weights1) + biases1)\n",
        "  valid_prediction = tf.nn.softmax(tf.matmul(layer_1_outputs, weights2) + biases2)\n",
        "  layer_1_outputs = tf.nn.relu(tf.matmul(tf_test_dataset, weights1) + biases1)\n",
        "  test_prediction = tf.nn.softmax(tf.matmul(layer_1_outputs, weights2) + biases2)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoGhcsHLsCmd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_steps = 6001\n",
        "\n",
        "ll = []\n",
        "atr = []\n",
        "av = []\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "with tf.Session(graph=graph) as session:\n",
        "  #tf.global_variables_initializer().run()\n",
        "  session.run(tf.initialize_all_variables())\n",
        "  print(\"Initialized\")\n",
        "  for step in range(num_steps):\n",
        "    # Pick an offset within the training data, which has been randomized.\n",
        "    # Note: we could use better randomization across epochs.\n",
        "    offset = (step * batch_size) % (y_train.shape[0] - batch_size)\n",
        "    # Generate a minibatch.\n",
        "    batch_data = X_train[offset:(offset + batch_size), :]\n",
        "    batch_labels = y_train[offset:(offset + batch_size), :]\n",
        "    # Prepare a dictionary telling the session where to feed the minibatch.\n",
        "    # The key of the dictionary is the placeholder node of the graph to be fed,\n",
        "    # and the value is the numpy array to feed to it.\n",
        "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
        "    _, l, predictions = session.run(\n",
        "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
        "    if (step % 500 == 0):\n",
        "      ll.append(l)\n",
        "      a = accuracy(predictions, batch_labels)\n",
        "      atr.append(a)\n",
        "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
        "      print(\"Minibatch accuracy: %.1f%%\" % a)\n",
        "      a = accuracy(valid_prediction.eval(), y_valid)\n",
        "      av.append(a)\n",
        "      print(\"Validation accuracy: %.1f%%\" % a)\n",
        "      #images = weights1.eval()\n",
        "      images = weights1.eval() @ weights2.eval()\n",
        "      plt.figure(figsize=(8,10))\n",
        "      #indices = np.random.choice(num_hidden_units, 225)\n",
        "      for j in range(10):\n",
        "        #plt.subplot(15,15,j+1);plt.imshow(np.reshape(images[:,indices[j]], (image_size,image_size)), cmap='gray');\n",
        "        plt.subplot(4,3,j+1);plt.imshow(np.reshape(images[:,j], (image_size,image_size)), cmap='gray');\n",
        "        plt.xticks([],[]);plt.yticks([],[])\n",
        "      plt.suptitle('SGD after Step ' + str(step) + ' with lambda1=lambda2=' + str(lambda1), size=20)\n",
        "      #plt.tight_layout()\n",
        "      plt.show()\n",
        "  print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), y_test))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8otflkt5sCmg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images = weights1.eval()\n",
        "pylab.figure(figsize=(18,18))\n",
        "indices = np.random.choice(num_hidden_units, 225)\n",
        "for j in range(225):\n",
        "   pylab.subplot(15,15,j+1)\n",
        "   pylab.imshow(np.reshape(images[:,indices[j]], (image_size,image_size)), cmap='gray')\n",
        "   pylab.xticks([],[]), pylab.yticks([],[])\n",
        "   pylab.subtitle('SGD after Step ' + str(step) + ' with lambda1=lambda2=' + str(lambda1))\n",
        "pylab.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jstkH6O6sCmj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(8,12))\n",
        "plt.subplot(211) \n",
        "plt.plot(range(0,6001,500), atr, '.-', label='training accuracy')\n",
        "plt.plot(range(0,6001,500), av, '.-', label='validation accuracy')\n",
        "plt.xlabel('GD steps')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.subplot(212) \n",
        "plt.plot(range(0,6001,500), ll, '.-')\n",
        "plt.xlabel('GD steps')\n",
        "plt.ylabel('Softmax Loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3B-ECcvrsCmm",
        "colab_type": "text"
      },
      "source": [
        "### Classification of MNIST using Convolutional neural network with Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upA9SNGbsCmm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Dropout\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# import data\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "print(X_train.shape, X_test.shape)\n",
        "\n",
        "# reshape to be [samples][pixels][width][height]\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "num_classes = y_test.shape[1] # number of categories\n",
        "\n",
        "def convolutional_model():\n",
        "    \n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=(28,28,1)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    \n",
        "    # compile model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# build the model\n",
        "model = convolutional_model()\n",
        "model.summary()\n",
        "\n",
        "# fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: {} \\n Error: {}\".format(scores[1], 100-scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ynKOrVxwz3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pydot_ng "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ca-1IExzsCmo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pip install pydot_ng ## install pydot_ng if not already installed\n",
        "import pydot_ng as pydot\n",
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file='../images/model.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKwDjocMsCmr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "\n",
        "intermediate_layer_model = Model(inputs=model.input, outputs=model.get_layer('conv2d_1').output)\n",
        "intermediate_output = intermediate_layer_model.predict(X_train)\n",
        "print(model.input.shape, intermediate_output.shape)\n",
        "fig = plt.figure(figsize=(15,7))\n",
        "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05) \n",
        "plt.gray()\n",
        "i = 1 \n",
        "for c in range(32):\n",
        "    plt.subplot(4, 8, c+1), plt.imshow(intermediate_output[i,:,:,c]), plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JF0Hvzf-sCmt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "intermediate_layer_model = Model(inputs=model.input, outputs=model.get_layer('conv2d_2').output)\n",
        "intermediate_output = intermediate_layer_model.predict(X_train)\n",
        "print(model.input.shape, intermediate_output.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bcSJoM_sCmw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(15,15))\n",
        "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05) \n",
        "plt.gray()\n",
        "i = 1 \n",
        "for c in range(64):\n",
        "    plt.subplot(8, 8, c+1), plt.imshow(intermediate_output[i,:,:,c]), plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34bKZrfHsCmz",
        "colab_type": "text"
      },
      "source": [
        "### Classification of MNIST using Convolutional network with Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbGOVShWsCmz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers.convolutional import Conv2D # to add convolutional layers\n",
        "from keras.layers.convolutional import MaxPooling2D # to add pooling layers\n",
        "from keras.layers import Flatten # to flatten data for fully connected layers\n",
        "\n",
        "# import data\n",
        "from keras.datasets import mnist\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "print(X_train.shape, X_test.shape)\n",
        "# (60000, 28, 28) (10000, 28, 28)\n",
        "# reshape to be [samples][pixels][width][height]\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\n",
        "X_train = X_train / 255 # normalize training data\n",
        "X_test = X_test / 255 # normalize test data\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "num_classes = y_test.shape[1] # number of categories\n",
        "\n",
        "def convolutional_model():    \n",
        "\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, (5, 5), strides=(1, 1), activation='relu', input_shape=(28, 28, 1)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))  \n",
        "    # compile model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# build the model\n",
        "model = convolutional_model()\n",
        "model.summary()\n",
        "# fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: {} \\n Error: {}\".format(scores[1], 100-scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwADBGMwsCm1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "intermediate_layer_model = Model(inputs=model.input, outputs=model.get_layer('conv2d_1').output)\n",
        "intermediate_output = intermediate_layer_model.predict(X_train)\n",
        "print(model.input.shape, intermediate_output.shape)\n",
        "fig = plt.figure(figsize=(15,15))\n",
        "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05) \n",
        "plt.gray()\n",
        "i = 2 \n",
        "for c in range(64):\n",
        "    plt.subplot(8, 8, c+1), plt.imshow(intermediate_output[i,:,:,c]), plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjRM8v4BsCm3",
        "colab_type": "text"
      },
      "source": [
        "### Classification of MNIST using FC network with Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rl7BR97ksCm4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Dropout\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# import data\n",
        "from keras.datasets import mnist\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "print(X_train.shape, X_test.shape)\n",
        "# (60000, 28, 28) (10000, 28, 28)\n",
        "# reshape to be [samples][pixels][width][height]\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\n",
        "X_train = X_train / 255 # normalize training data\n",
        "X_test = X_test / 255 # normalize test data\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "num_classes = y_test.shape[1] # number of categories\n",
        "\n",
        "def FC_model():    \n",
        "\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=(28, 28, 1)))\n",
        "    model.add(Dense(200, activation='relu'))\n",
        "    model.add(Dropout(0.15))\n",
        "    model.add(Dense(200, activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))  \n",
        "    # compile model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# build the model\n",
        "model = FC_model()\n",
        "model.summary()\n",
        "# fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: {} \\n Error: {}\".format(scores[1], 100-scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XWNf5TpsCm6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pydot_ng as pydot\n",
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file='model.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHoDqnsmsCm9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "W1 = model.get_layer('dense_7').get_weights()\n",
        "W2 = model.get_layer('dense_8').get_weights()\n",
        "W3 = model.get_layer('dense_9').get_weights()\n",
        "print(W1[0].shape, W2[0].shape)\n",
        "W = W1[0] @ W2[0] @ W3[0]\n",
        "print(W.shape)\n",
        "fig = plt.figure(figsize=(5,8))\n",
        "fig.subplots_adjust(left=0, right=1, bottom=0, top=0.95, hspace=0.05, wspace=0.05) \n",
        "plt.gray()\n",
        "for i in range(10):\n",
        "    plt.subplot(4, 3, i+1), plt.imshow(np.reshape(W[:, i], (28,28))), plt.axis('off')\n",
        "plt.suptitle('What NN sees', size=20)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5-FxTwdsCm_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#! pip install pydot\n",
        "#! pip install pydot_ng graphviz\n",
        "import pydot_ng as pydot\n",
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file='../images/keras_model.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSOGSIrYsCnB",
        "colab_type": "text"
      },
      "source": [
        "### Classifying Cat/Dog images using VGG-16 in Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmPaTNUVsCnC",
        "colab_type": "text"
      },
      "source": [
        "* First download the compressed cats/dogs images train and test datasets from here: https://www.kaggle.com/c/dogs-vs-cats/data.\n",
        "* Then unzip the train.zip file under the **train** folder (should contain all the 25k train images) and test.zip file under the **test** folder (should contain all the test images)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJmON_k3sCnC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os                 \n",
        "import numpy as np        \n",
        "import cv2                \n",
        "from random import shuffle \n",
        "from tqdm import tqdm # percentage bar for tasks. \n",
        "\n",
        "# download the cats/dogs images compressed train and test datasets from here: https://www.kaggle.com/c/dogs-vs-cats/data\n",
        "# unzip the train.zip images under the train folder and test.zip images under the test folder\n",
        "train = './train'      \n",
        "test = './test'\n",
        "lr = 1e-6     # learning rate\n",
        "image_size = 50 # all the images will be resized to squaure images with this dimension\n",
        "\n",
        "model_name = 'cats_dogs-{}-{}.model'.format(lr, 'conv2') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AIraiwFsCnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def label_image(image):\n",
        "    word_label = image.split('.')[-3]\n",
        "    if word_label == 'cat': return 0\n",
        "    elif word_label == 'dog': return 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Og-_8XQsCnG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_training_data():\n",
        "    training_data = []\n",
        "    for image in tqdm(os.listdir(train)):\n",
        "        path = os.path.join(train, image)\n",
        "        label = label_image(image)\n",
        "        image = cv2.imread(path)\n",
        "        image = cv2.resize(image, (image_size, image_size))\n",
        "        training_data.append([np.array(image),np.array(label)])\n",
        "    shuffle(training_data)\n",
        "    np.save('train_data.npy', training_data)\n",
        "    return training_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4DTM7XesCnI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_test_data():\n",
        "    testing_data = []\n",
        "    for image in tqdm(os.listdir(test)):\n",
        "        path = os.path.join(test, image)\n",
        "        image = cv2.imread(path)\n",
        "        image = cv2.resize(image, (image_size, image_size))\n",
        "        testing_data.append(np.array(image))        \n",
        "    shuffle(testing_data)\n",
        "    np.save('test_data.npy', testing_data)\n",
        "    return testing_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjHiGH2MsCnL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = create_training_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q84mhVybsCnO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(train_data)\n",
        "#train_data[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfWGT23wsCnQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "train = train_data[:-5000] # 20k images for training\n",
        "valid = train_data[-5000:] # 5k images for validation\n",
        "X_train = np.array([i[0] for i in train]).reshape(-1,image_size,image_size,3)\n",
        "y_train = [i[1] for i in train]\n",
        "y_train = to_categorical(y_train)\n",
        "print(X_train.shape, y_train.shape)\n",
        "\n",
        "X_valid = np.array([i[0] for i in valid]).reshape(-1,image_size,image_size,3)\n",
        "y_valid = [i[1] for i in valid]\n",
        "y_valid = to_categorical(y_valid) # to one-hot encoding\n",
        "\n",
        "num_classes = y_valid.shape[1] # number of categories\n",
        "\n",
        "model = VGG16(weights=None, input_shape=(image_size,image_size,3), classes=num_classes) # train VGG16 model from scratch\n",
        "model.compile(Adam(lr=lr), \"categorical_crossentropy\", metrics=[\"accuracy\"]) # \"adam\"\n",
        "model.summary()\n",
        "\n",
        "# fit the model, it's going take a long time if not run on GPU\n",
        "model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=20, batch_size=256, verbose=2)\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X_valid, y_valid, verbose=0)\n",
        "print(\"Accuracy: {} \\n Error: {}\".format(scores[1], 100-scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TS6AlIz3sCnS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "\n",
        "intermediate_layer_model = Model(inputs=model.input, outputs=model.get_layer('block1_conv2').output)\n",
        "intermediate_output = intermediate_layer_model.predict(X_train)\n",
        "print(model.input.shape, intermediate_output.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETJ7ufGEsCnU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "intermediate_layer_model = Model(inputs=model.input, outputs=model.get_layer('block1_conv2').output)\n",
        "intermediate_output = intermediate_layer_model.predict(X_train)\n",
        "fig = plt.figure(figsize=(10,10))\n",
        "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05) \n",
        "plt.gray()\n",
        "i = 3\n",
        "for c in range(64):\n",
        "    plt.subplot(8, 8, c+1), plt.imshow(intermediate_output[i,:,:,c]), plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObAYC_2SsCnW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "intermediate_layer_model = Model(inputs=model.input, outputs=model.get_layer('block2_conv2').output)\n",
        "intermediate_output = intermediate_layer_model.predict(X_train)\n",
        "print(model.input.shape, intermediate_output.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kF48O6EsCnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(10,10))\n",
        "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05) \n",
        "plt.gray()\n",
        "i = 3\n",
        "for c in range(128):\n",
        "    plt.subplot(13, 10, c+1), plt.imshow(intermediate_output[i,:,:,c]), plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PLGICrhsCnb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "intermediate_layer_model = Model(inputs=model.input, outputs=model.get_layer('block3_conv3').output)\n",
        "intermediate_output = intermediate_layer_model.predict(X_train)\n",
        "print(model.input.shape, intermediate_output.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mny2PetPsCne",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(7,7))\n",
        "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05) \n",
        "plt.gray()\n",
        "i = 3\n",
        "for c in range(256):\n",
        "    plt.subplot(16, 16, c+1), plt.imshow(intermediate_output[i,:,:,c]), plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilAuqXUisCnh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = create_test_data()\n",
        "len(test_data) # only took a subset of the test data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvIrzkH2sCnj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = np.array([i for i in test_data]).reshape(-1,image_size,image_size,3)\n",
        "probs = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C32GuIMUsCnm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "probs = np.round(probs,2)\n",
        "plt.figure(figsize=(20,20))\n",
        "for i in range(100):\n",
        "    plt.subplot(10,10,i+1), plt.imshow(X_test[i,:,:,::-1]), plt.axis('off')\n",
        "    plt.title(\"{}, prob={:0.2f}\".format('cat' if probs[i][1] < 0.5 else 'dog', max(probs[i][0],probs[i][1])))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}