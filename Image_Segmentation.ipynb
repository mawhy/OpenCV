{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Image Segmentation",
      "provenance": [],
      "collapsed_sections": [
        "9OEIsWaAyyu9",
        "AJKYx7xayyvA"
      ],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mawhy/OpenCV/blob/master/Image_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOdGrxsFyyuc",
        "colab_type": "text"
      },
      "source": [
        "# Image Processing CookBook\n",
        "## Image Segmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqlDpoDQBo3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/PacktPublishing/Python-Image-Processing-Cookbook.git\n",
        "%cp -av \"/content/Python-Image-Processing-Cookbook/Chapter 06/images/\" \"/content/\"\n",
        "%cp -av \"/content/Python-Image-Processing-Cookbook/Chapter 06/models/\" \"/content/\"\n",
        "%rm -rf \"/content/Python-Image-Processing-Cookbook\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMCzF2Nq0WuN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install mahotas"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58M1iT4-yyud",
        "colab_type": "text"
      },
      "source": [
        "### Segmentation by Thresholding with Otsu and Riddler-Calvard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOUKyV6Kyyue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import mahotas as mh\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "image = mh.imread('images/netaji.png')\n",
        "thresh_otsu, thresh_rc = mh.otsu(image), mh.rc(image)\n",
        "print(thresh_otsu, thresh_rc)\n",
        "binary_otsu, binary_rc = image > thresh_otsu, image > thresh_rc\n",
        "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(20, 15))\n",
        "axes = axes.ravel()\n",
        "axes[0].imshow(image, cmap=plt.cm.gray)\n",
        "axes[0].set_title('Original', size=20), axes[0].axis('off')\n",
        "axes[1].hist(image.ravel(), bins=256, density=True)\n",
        "axes[1].set_title('Histogram', size=20)\n",
        "axes[1].axvline(thresh_otsu, label='otsu', color='green', lw=3), axes[1].axvline(thresh_rc, label='rc', color='red', lw=2)\n",
        "axes[1].legend(loc='upper left', prop={'size': 20}), axes[1].grid()\n",
        "axes[2].imshow(binary_otsu, cmap=plt.cm.gray)\n",
        "axes[2].set_title('Thresholded (Otsu)', size=20), axes[2].axis('off')\n",
        "axes[3].imshow(binary_rc, cmap=plt.cm.gray)\n",
        "axes[3].set_title('Thresholded (Riddler-Calvard)', size=20), axes[3].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQ1AUanVyyuh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage.io import imread\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.filters import try_all_threshold\n",
        "image = rgb2gray(imread('images/board.png'))\n",
        "plt.rcParams.update({'axes.titlesize':20})\n",
        "fig, ax = try_all_threshold(image, figsize=(20, 60), verbose=False)\n",
        "fig.subplots_adjust(0,0,1,0.95,0.01,0.06)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1UBTYniyyuk",
        "colab_type": "text"
      },
      "source": [
        "### Skin Color Detection and Segmentation with Gaussian Mixture Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90uqc0xByyul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://archive.ics.uci.edu/ml/datasets/skin+segmentation\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.mixture import GaussianMixture\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "df = pd.read_csv('images/Skin_NonSkin.txt', header=None, delim_whitespace=True)\n",
        "df.columns = ['B', 'G', 'R', 'skin']\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wJRCFwQyyun",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g = sns.factorplot(data=pd.melt(df, id_vars='skin'), x='variable', y='value', \\\n",
        "                   hue='variable', col='skin', kind='box', palette=sns.color_palette(\"hls\", 3)[::-1])\n",
        "plt.show()\n",
        "\n",
        "#Y = .299*r + .587*g + .114*b\n",
        "df['Cb'] = np.round(128 -.168736*df.R -.331364*df.G + .5*df.B).astype(int)\n",
        "df['Cr'] = np.round(128 +.5*df.R - .418688*df.G - .081312*df.B).astype(int)\n",
        "\n",
        "df.drop(['B','G','R'], axis=1, inplace=True)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiqsKTDKyyup",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.groupby('skin').count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FC-3wu1vyyus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g = sns.factorplot(data=pd.melt(df, id_vars='skin'), x='variable', y='value', \\\n",
        "                   hue='variable', col='skin', kind='box')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhNKyRAAyyuv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "skin_data = df[df.skin==1].drop(['skin'], axis=1).to_numpy()\n",
        "not_skin_data = df[df.skin==2].drop(['skin'], axis=1).to_numpy()\n",
        "skin_gmm = GaussianMixture(n_components=4, covariance_type='full').fit(skin_data)\n",
        "not_skin_gmm = GaussianMixture(n_components=4, covariance_type='full').fit(not_skin_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eA7TvpA5yyux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "skin_gmm.means_, skin_gmm.covariances_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooD4CxM5yyuz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "not_skin_gmm.means_, not_skin_gmm.covariances_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUTCbVEoyyu1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "colors = ['navy', 'turquoise', 'darkorange', 'gold']\n",
        "\n",
        "def draw_ellipses(gmm, ax):\n",
        "    for n, color in enumerate(colors):\n",
        "        covariances = gmm.covariances_[n][:2, :2]\n",
        "        v, w = np.linalg.eigh(covariances)\n",
        "        u = w[0] / np.linalg.norm(w[0])\n",
        "        angle = np.arctan2(u[1], u[0])\n",
        "        angle = 180 * angle / np.pi  # convert to degrees\n",
        "        v = 2. * np.sqrt(2.) * np.sqrt(v)\n",
        "        ell = mpl.patches.Ellipse(gmm.means_[n, :2], v[0], v[1],\n",
        "                                  180 + angle, color=color)\n",
        "        ell.set_clip_box(ax.bbox)\n",
        "        ell.set_alpha(0.5)\n",
        "        ax.add_artist(ell)\n",
        "        ax.set_aspect('equal', 'datalim')\n",
        "\n",
        "def plot_gmm(gmm, data, i, title):\n",
        "    h = plt.subplot(1, 2, i)\n",
        "    draw_ellipses(gmm, h)\n",
        "    plt.scatter(data[:, 0], data[:, 1], s=0.8, color='k')\n",
        "    plt.title(title)\n",
        "\n",
        "plt.figure(figsize=(15,8))\n",
        "plot_gmm(skin_gmm, skin_data, 1, 'Skin GMM')\n",
        "plot_gmm(not_skin_gmm, not_skin_data, 2, 'Not Skin GMM')\n",
        "plt.show()    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUUEQyrCyyu4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage.io import imread\n",
        "from skimage.color import rgb2ycbcr, gray2rgb\n",
        "image = imread('images/skin.png')\n",
        "proc_image = np.reshape(rgb2ycbcr(image), (-1, 3))\n",
        "skin_score = skin_gmm.score_samples(proc_image[...,1:])\n",
        "not_skin_score = not_skin_gmm.score_samples(proc_image[...,1:])\n",
        "result = skin_score > not_skin_score\n",
        "result = result.reshape(image.shape[0], image.shape[1])\n",
        "result = np.bitwise_and(gray2rgb(255*result.astype(np.uint8)), image)\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.subplot(121), plt.imshow(image), plt.axis('off'), plt.title('Original', size=20)\n",
        "plt.subplot(122), plt.imshow(result), plt.axis('off'), plt.title('Skin Detected and Segmented with GMM', size=20)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gF7dlW3Tyyu6",
        "colab_type": "text"
      },
      "source": [
        "### Medical Image Segmentation with GMM-EM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNYB-vteEuTz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/curiale/Medical-Image-Analysis-IPython-Tutorials.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImwQfXaPFJCq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cp -av \"/content/Medical-Image-Analysis-IPython-Tutorials/tutorial_3/data/atlas_slicez90.nii.gz\" \"/content/images\" "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJyGRRMa1ekj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install SimpleITK"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "oAtAKP4Tyyu7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://github.com/curiale/Medical-Image-Analysis-IPython-Tutorials\n",
        "import SimpleITK as sitk\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "#import matplotlib.mlab as mlab\n",
        "import scipy.stats as scs\n",
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "# Atlas image (high-quality image - obtained by registering and averaging inter-patient T1 brain images)\n",
        "\n",
        "# Read the brain slice image\n",
        "max_int_val = 512;\n",
        "image = sitk.ReadImage(\"images/atlas_slicez90.nii.gz\", sitk.sitkFloat32)\n",
        "image = sitk.RescaleIntensity(image,0.0,max_int_val)\n",
        "image_data = sitk.GetArrayFromImage(image);\n",
        "\n",
        "# Compute the parameters for the Gaussian Mixture model\n",
        "np.random.seed(1)\n",
        "g = GaussianMixture(n_components=4, covariance_type='diag', tol=0.01, max_iter=100, \n",
        "                n_init=1, init_params='kmeans')\n",
        "\n",
        "# Estimate model parameters with the expectation-maximization algorithm.\n",
        "g.fit(image_data[0].flatten().reshape(-1, 1)) \n",
        "\n",
        "# pdf of each gaussian model\n",
        "def plot_pdf_models(x, g):\n",
        "    we = g.weights_\n",
        "    mu = g.means_\n",
        "    si = np.sqrt(g.covariances_)\n",
        "    for ind in range(0,we.shape[0]): \n",
        "        plt.plot(x,we[ind]*scs.norm.pdf(x, mu[ind], si[ind]),linewidth=4)\n",
        "\n",
        "# Class probability distribution function\n",
        "x = np.linspace(0,max_int_val,500)\n",
        "plt.figure(figsize=(16, 5), dpi=100)\n",
        "plot_pdf_models(x,g)\n",
        "plt.hist(image_data.flatten(), bins=int(max_int_val/6), range=(0, max_int_val), density=True)\n",
        "plt.title('Class specific probability distribution functions',fontsize=20)\n",
        "plt.show()\n",
        "\n",
        "# Single components (class posterioe)\n",
        "plt.figure(figsize=(16, 3), dpi=100)\n",
        "print(x.shape, g.predict_proba(x.reshape(-1,1)).shape)\n",
        "plt.plot(x,g.predict_proba(x.reshape(-1,1)), linewidth=4)\n",
        "plt.title('Class posterior probability under each Gaussian in the model',fontsize=20)\n",
        "plt.show()\n",
        "\n",
        "# Compute label image\n",
        "label_data = g.predict(image_data[0].flatten().reshape(-1, 1)) #.flatten()) \n",
        "label_data = label_data.reshape(image_data[0].shape)\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.subplot(121), plt.imshow(image_data[0], cmap='gray'), plt.axis('off'), plt.title('Original image', size=20)\n",
        "plt.subplot(122), plt.imshow(label_data, cmap='jet'), plt.axis('off'), plt.title('Segmented image', size=20)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OEIsWaAyyu9",
        "colab_type": "text"
      },
      "source": [
        "### Tumor Segmentation with Deep Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kOz6p0Uyyu9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://github.com/polo8214/Brain-tumor-segmentation-using-deep-learning/\n",
        "# https://drive.google.com/file/d/1hE9It0ZOOeIuSFvt6GdiR_0cq9inWdTy/view\n",
        "# weights-full-best.h5\n",
        "import keras\n",
        "print(keras.__version__)\n",
        "from keras.models import model_from_json\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "from skimage.color import rgb2gray, gray2rgb\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "import matplotlib.patches as mpatches\n",
        "# pip3 install pydot-ng\n",
        "import pydot_ng as pydot\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "keras.utils.vis_utils.pydot = pydot #import pydotplus as pydot\n",
        "\n",
        "loaded_model_json = open('models/model.json', 'r').read()\n",
        "model = model_from_json(loaded_model_json)\n",
        "model.load_weights('models/weights-full-best.h5')\n",
        "plot_model(model, to_file='images/model_plot.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "#using Flair and T2 as input for full tumor segmentation\n",
        "x = np.zeros((1,2,240,240),np.float32)\n",
        "Flair = resize((rgb2gray(imread('images/Flair.png')).astype('float32')), (240,240))\n",
        "T2 = resize((rgb2gray(imread('images/T2.png'))).astype('float32'), (240,240))\n",
        "ground_truth = resize(rgb2gray(imread('images/ground_truth.png')), (240,240))\n",
        "\n",
        "T2 = (T2-T2.mean()) / T2.std()\n",
        "Flair = (Flair-Flair.mean()) / Flair.std()\n",
        "\n",
        "x[:,:1,:,:] = np.reshape(Flair, (1,1,240,240))\n",
        "x[:,1:,:,:] = np.reshape(T2, (1,1,240,240))\n",
        "\n",
        "pred_full = model.predict(x)\n",
        "pred_full = np.reshape(pred_full, (240,240))\n",
        "tumor_overlay = 0.2*gray2rgb(T2) + 0.4*np.array([0.25,1,0.25])*gray2rgb(pred_full) + 0.4*np.array([1,0.25,0.25])*gray2rgb(ground_truth)\n",
        "\n",
        "plt.figure(figsize=(19,20))\n",
        "plt.gray()\n",
        "plt.subplots_adjust(0,0,1,0.95,0.01,0.05)\n",
        "plt.subplot(221), plt.title('MR T2', size=25), plt.axis('off'), plt.imshow(T2)\n",
        "plt.subplot(222), plt.title('MR Flair', size=25), plt.axis('off'), plt.imshow(Flair)\n",
        "plt.subplot(223), plt.title('MR Tumor Ground Truth', size=25), plt.axis('off'), plt.imshow(ground_truth)\n",
        "plt.subplot(224), plt.title('Tumor Prediction', size=25), plt.axis('off'), plt.imshow(tumor_overlay)\n",
        "colors, labels = ['#A76161', '#FFFFB2'], ['GT', 'Pred']\n",
        "patches = [ mpatches.Patch(color=colors[i], label=labels[i]) for i in range(len(colors)) ]\n",
        "# put those patched as legend-handles into the legend\n",
        "plt.legend(handles=patches, bbox_to_anchor=(1.01, 1), loc=2, borderaxespad=0, prop={'size':25}, frameon=True, shadow=True)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJKYx7xayyvA",
        "colab_type": "text"
      },
      "source": [
        "### Watershed Segmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iP0kP_CDyyvA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import SimpleITK as sitk\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "img = sitk.ReadImage('images/fib_sem_bacillus_subtilis_slice_118.png', sitk.sitkFloat32)\n",
        "f = sitk.RescaleIntensityImageFilter()\n",
        "img = f.Execute(img, 0, 255)\n",
        "plt.figure(figsize=(20,26))\n",
        "plt.gray()\n",
        "plt.subplots_adjust(0,0,1,0.95,0.05,0.05), plt.axis('off')\n",
        "plt.subplot(421), plt.imshow(sitk.GetArrayFromImage(img)), plt.title('Original image', size=20)\n",
        "plt.subplot(422), plt.hist(sitk.GetArrayViewFromImage(img).flatten(), bins=100), plt.title('histogram of pixel values', size=20)\n",
        "thresh_value = 120\n",
        "thresh_img = img>thresh_value\n",
        "plt.subplot(423), plt.imshow(sitk.GetArrayFromImage(sitk.LabelOverlay(img, thresh_img))/255), plt.title('Binary Segmentation', size=20), plt.axis('off')\n",
        "cleaned_thresh_img = sitk.BinaryOpeningByReconstruction(thresh_img, [10, 10, 10])\n",
        "cleaned_thresh_img = sitk.BinaryClosingByReconstruction(cleaned_thresh_img, [10, 10, 10])\n",
        "#from collections import Counter\n",
        "#print(Counter(sitk.GetArrayFromImage(cleaned_thresh_img).flatten()))\n",
        "plt.subplot(424), plt.imshow(sitk.GetArrayFromImage(cleaned_thresh_img)), plt.title('Cleaned Binary Segmentation', size=20), plt.axis('off')\n",
        "dist_img = sitk.SignedMaurerDistanceMap(cleaned_thresh_img != 0, insideIsPositive=False, squaredDistance=False, useImageSpacing=False)\n",
        "radius = 10\n",
        "# Seeds have a distance of \"radius\" or more to the object boundary, they are uniquely labelled.\n",
        "seeds = sitk.ConnectedComponent(dist_img < -radius)\n",
        "# Relabel the seed objects using consecutive object labels while removing all objects with less than 15 pixels.\n",
        "seeds = sitk.RelabelComponent(seeds, minimumObjectSize=15)\n",
        "# Run the watershed segmentation using the distance map and seeds.\n",
        "ws = sitk.MorphologicalWatershedFromMarkers(dist_img, seeds, markWatershedLine=True)\n",
        "ws = sitk.Mask( ws, sitk.Cast(cleaned_thresh_img, ws.GetPixelID()))\n",
        "img = sitk.Cast(img, sitk.sitkUInt8)\n",
        "#print(img.GetPixelIDTypeAsString(), seeds.GetPixelIDTypeAsString())\n",
        "plt.subplot(425), plt.imshow(sitk.GetArrayFromImage(dist_img)), plt.title('Segmentation Distance', size=20), plt.axis('off')\n",
        "plt.subplot(426), plt.imshow(sitk.GetArrayFromImage(sitk.LabelOverlay(img, seeds))), plt.title('Watershed Seeds', size=20), plt.axis('off')\n",
        "plt.subplot(427), plt.imshow(sitk.GetArrayFromImage(sitk.LabelOverlay(img, ws))), plt.title('Binary Watershed Labeling', size=20), plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "8qw2GQ4SyyvC",
        "colab_type": "text"
      },
      "source": [
        "### Image segmentation with Self Organizing Maps (SOM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W68Q-1jq6HNG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install minisom\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39Xt0IDyyyvD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from minisom import MiniSom\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def segment_with_SOM(image, nx, ny, sigma=1., n=500):\n",
        "    pixels = np.reshape(image, (image.shape[0]*image.shape[1], 3))\n",
        "    # SOM initialization and training\n",
        "    print('training...')\n",
        "    som = MiniSom(x=nx, y=ny, input_len=3, sigma=sigma, learning_rate=0.2)  # nxxny final colors\n",
        "    som.random_weights_init(pixels)\n",
        "    starting_weights = som.get_weights().copy()  # saving the starting weights\n",
        "    som.train_random(pixels, n)\n",
        "    print('quantization...')\n",
        "    qnt = som.quantization(pixels)  # quantize each pixels of the image\n",
        "    print('building new image...')\n",
        "    clustered = np.zeros(image.shape)\n",
        "    for i, q in enumerate(qnt):  # place the quantized values into a new image\n",
        "        clustered[np.unravel_index(i, dims=(image.shape[0], image.shape[1]))] = q\n",
        "    print('done.')\n",
        "    final_weights = som.get_weights()\n",
        "    return clustered, starting_weights, final_weights\n",
        "\n",
        "from skimage import img_as_float\n",
        "image = img_as_float(plt.imread('images/apples.png'))\n",
        "\n",
        "clustered, starting_weights, final_weights = segment_with_SOM(image, 1, 2, .1)\n",
        "colors = np.unique(clustered.reshape(-1,3), axis=0)\n",
        "clustered_binary = np.zeros_like(clustered)\n",
        "clustered_binary[np.where((clustered[...,0]==colors[1][0]) & \\\n",
        "                 (clustered[...,1]==colors[1][1]) & \\\n",
        "                 (clustered[...,2]==colors[1][2]))] = 1.\n",
        "\n",
        "plt.figure(figsize=(20, 15))\n",
        "plt.subplot(321), plt.title('original', size=20), plt.axis('off'), plt.imshow(image)\n",
        "plt.subplot(322), plt.title('segmented', size=20), plt.axis('off'), plt.imshow(clustered)\n",
        "plt.subplot(323), plt.title('initial colors', size=20), plt.axis('off'), plt.imshow(starting_weights, interpolation='none')\n",
        "plt.subplot(324), plt.title('learned colors', size=20), plt.axis('off'), plt.imshow(final_weights, interpolation='none')\n",
        "plt.subplot(325), plt.title('segmented (binary)', size=20), plt.axis('off'), plt.imshow(clustered_binary)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "clustered, starting_weights, final_weights = segment_with_SOM(image, 5, 5)\n",
        "plt.figure(figsize=(20, 10))\n",
        "plt.subplot(221), plt.title('original', size=20), plt.axis('off'), plt.imshow(image)\n",
        "plt.subplot(222), plt.title('segmented (color-quantized)', size=20), plt.axis('off'), plt.imshow(clustered)\n",
        "plt.subplot(223), plt.title('initial colors', size=20), plt.axis('off'), plt.imshow(starting_weights, interpolation='none')\n",
        "plt.subplot(224), plt.title('learned colors', size=20), plt.axis('off'), plt.imshow(final_weights, interpolation='none')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0M0xJp9yyvF",
        "colab_type": "text"
      },
      "source": [
        "### Clustering digits images with SOM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdeMoovtyyvF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from minisom import MiniSom\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pylab import pcolor\n",
        "from collections import defaultdict\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import scale\n",
        "\n",
        "digits = datasets.load_digits(n_class=10)\n",
        "data = digits.data  # matrix where each row is a vector that represent a digit.\n",
        "data = scale(data)\n",
        "num = digits.target  # num[i] is the digit represented by data[i]\n",
        "\n",
        "som = MiniSom(30, 30, 64, sigma=4, learning_rate=0.5, neighborhood_function='triangle')\n",
        "som.pca_weights_init(data)\n",
        "print(\"Training...\")\n",
        "som.train_random(data, 5000)  # random training\n",
        "print(\"\\n...ready!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pE78sbLuyyvI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(15, 12))\n",
        "pcolor(som.distance_map().T, cmap='coolwarm')\n",
        "plt.colorbar()\n",
        "wmap = defaultdict(list)\n",
        "im = 0\n",
        "for x, t in zip(data, num):  # scatterplot\n",
        "    w = som.winner(x)\n",
        "    wmap[w].append(im)\n",
        "    plt. text(w[0]+.5,  w[1]+.5,  str(t),\n",
        "              color=plt.cm.Dark2(t / 10.), fontdict={'weight': 'bold',  'size': 11})\n",
        "    im = im + 1\n",
        "plt.axis([0, som.get_weights().shape[0], 0,  som.get_weights().shape[1]])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOR4zXMiyyvK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(wmap[23,15])\n",
        "# [581, 598, 1361] # 3 digits assigned to node (23,15)\n",
        "plt.gray()\n",
        "for index in wmap[23,15]:\n",
        "    plt.figure(figsize=(1,1))\n",
        "    plt.imshow(np.reshape(digits.images[index], (8,-1)))\n",
        "    plt.title(digits.target[index])\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "0WTk1zOXyyvM",
        "colab_type": "text"
      },
      "source": [
        "### Deep Image Instance Segmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJRW3MHSYMqf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://www.learnopencv.com/deep-learning-based-object-detection-and-instance-segmentation-using-mask-r-cnn-in-opencv-python-c/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8E-nUqX6X1Jf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://download.tensorflow.org/models/object_detection/mask_rcnn_inception_v2_coco_2018_01_28.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOtAfbgrYVsO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -zxvf mask_rcnn_inception_v2_coco_2018_01_28.tar.gz\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SJoHeW8YBVF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cp \"/content/mask_rcnn_inception_v2_coco_2018_01_28/frozen_inference_graph.pb\" \"/content/models\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wkOObKwyyvM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the necessary packages\n",
        "import numpy as np\n",
        "import colorsys\n",
        "import time\n",
        "import cv2\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "print(cv2.__version__)\n",
        "# 4.1.0\n",
        "\n",
        "def random_colors(N, bright=True):\n",
        "    brightness = 1.0 if bright else 0.7\n",
        "    hsv = [(i / N, 1, brightness) for i in range(N)]\n",
        "    colors = list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv))\n",
        "    random.shuffle(colors)\n",
        "    return 256*np.array(colors)\n",
        "\n",
        "\n",
        "model_path = 'models'\n",
        "conf = 0.5\n",
        "thresh = 0.3\n",
        "\n",
        "# load the COCO class labels our Mask R-CNN was trained on\n",
        "labels_path = os.path.sep.join([model_path, \"object_detection_classes_coco.txt\"])\n",
        "labels = open(labels_path).read().strip().split(\"\\n\")\n",
        "\n",
        "# derive the paths to the Mask R-CNN weights and model configuration\n",
        "weights_path = os.path.sep.join([model_path, \"frozen_inference_graph.pb\"])\n",
        "config_path = os.path.sep.join([model_path, \"mask_rcnn_inception_v2_coco_2018_01_28.pbtxt\"])\n",
        "\n",
        "print(weights_path, config_path)\n",
        "\n",
        "# load our Mask R-CNN trained on the COCO dataset (90 classes)\n",
        "# from disk\n",
        "print(\"[INFO] loading Mask R-CNN from disk...\")\n",
        "net = cv2.dnn.readNetFromTensorflow(weights_path, config_path)\n",
        "\n",
        "image = cv2.imread('images/pets.png')\n",
        "original = image.copy()\n",
        "\n",
        "blob = cv2.dnn.blobFromImage(image, swapRB=True, crop=False)\n",
        "net.setInput(blob)\n",
        "(boxes, masks) = net.forward([\"detection_out_final\",  \"detection_masks\"])\n",
        "\n",
        "num_classes = masks.shape[1]\n",
        "num_detections = boxes.shape[2]\n",
        "print('# instances: {}'.format(num_detections))\n",
        "colors = random_colors(num_detections)\n",
        "print(\"# classes: {}\".format(num_classes))\n",
        "\n",
        "\n",
        "h = image.shape[0]\n",
        "w = image.shape[1]\n",
        "\n",
        "for i in range(num_detections):\n",
        "    \n",
        "    box = boxes[0, 0, i]\n",
        "    mask = masks[i]\n",
        "    score = box[2]\n",
        "    \n",
        "    if score > conf:\n",
        "        \n",
        "        class_id = int(box[1])\n",
        "        print(class_id, score)\n",
        "\n",
        "        left = int(w * box[3])\n",
        "        top = int(h * box[4])\n",
        "        right = int(w * box[5])\n",
        "        bottom = int(h * box[6])\n",
        "\n",
        "        left = max(0, min(left, w - 1))\n",
        "        top = max(0, min(top, h - 1))\n",
        "        right = max(0, min(right, w - 1))\n",
        "        bottom = max(0, min(bottom, h - 1))\n",
        "\n",
        "        # Extract the mask for the object\n",
        "        class_mask = mask[class_id]\n",
        "\n",
        "        # colorize and show the mask on the image\n",
        "        label = labels[class_id]\n",
        "    \n",
        "        # Resize the mask, threshold, color and apply it on the image\n",
        "        class_mask = cv2.resize(class_mask, (right - left + 1, bottom - top + 1))\n",
        "        mask = (class_mask > thresh)\n",
        "        roi = image[top:bottom+1, left:right+1][mask]\n",
        "\n",
        "        color_index = np.random.randint(0, len(colors)-1)\n",
        "        color = np.array(colors[color_index])\n",
        "\n",
        "        image[top:bottom+1, left:right+1][mask] = (0.4*color + 0.6 * roi).astype(np.uint8)\n",
        "\n",
        "        # Draw the contours on the image\n",
        "        mask = mask.astype(np.uint8)\n",
        "        contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        cv2.drawContours(image[top:bottom+1, left:right+1], contours, -1, color, 3, cv2.LINE_8, hierarchy, 100)\n",
        "        \n",
        "        label_size, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
        "        top = max(top, label_size[1])\n",
        "        cv2.putText(image, label, ((left + right)//2, top), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0,0,0), 2)\n",
        "\n",
        "\n",
        "cv2.imwrite('images/instance_seg_out.png', image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnR2vhKnyyvO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(20,8))\n",
        "plt.subplot(121), plt.imshow(cv2.cvtColor(original, cv2.COLOR_BGR2RGB)), plt.axis('off'), plt.title('Original', size=20)\n",
        "plt.subplot(122), plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB)), plt.axis('off'), plt.title('Instance segmentation (Mask_RCNN)', size=20)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "AKEEPw9dyyvQ",
        "colab_type": "text"
      },
      "source": [
        "### Semantic Segmentation with DeepLab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alfzJc2-yyvR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66H_9z1CezmM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install tfgraphviz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PP2LCt21fwai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://download.tensorflow.org/models/deeplabv3_pascal_trainval_2018_01_04.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvMYDzYIgCLY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -zxvf deeplabv3_pascal_trainval_2018_01_04.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gR8hJbHDgTvP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir model2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5vaagbEgdtm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cp \"/content/deeplabv3_pascal_trainval/frozen_inference_graph.pb\" \"/content/model2\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGb7JgHVyyvT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/model_zoo.md\n",
        "# http://download.tensorflow.org/models/deeplabv3_pascal_trainval_2018_01_04.tar.gz\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf\n",
        "from tensorflow.io.gfile import GFile\n",
        "#io.gfile\n",
        "#from tensorflow.gfile import GFile\n",
        "import tfgraphviz as tfg\n",
        "import os\n",
        "\n",
        "def run_semantic_segmentation(image, model_path):\n",
        "\n",
        "    input_tensor_name = 'ImageTensor:0'\n",
        "    output_tensor_name = 'SemanticPredictions:0'\n",
        "    input_size = 513\n",
        "\n",
        "    graph = tf.Graph()\n",
        "\n",
        "    graph_def = None\n",
        "    with GFile(model_path, 'rb') as f:\n",
        "        graph_def = tf.GraphDef()\n",
        "        graph_def.ParseFromString(f.read())\n",
        "\n",
        "    if graph_def is None:\n",
        "      raise RuntimeError('Cannot find inference graph in tar archive.')\n",
        "\n",
        "    with graph.as_default():\n",
        "      tf.import_graph_def(graph_def, name='')\n",
        "    \n",
        "    sess = tf.Session(graph=graph)\n",
        "\n",
        "    width, height = image.size\n",
        "    resize_ratio = 1.0 * input_size / max(width, height)\n",
        "    target_size = (int(resize_ratio * width), int(resize_ratio * height))\n",
        "    resized_image = image.convert('RGB').resize(target_size, Image.ANTIALIAS)\n",
        "    batch_seg_map = sess.run(\n",
        "        output_tensor_name,\n",
        "        feed_dict={input_tensor_name: [np.asarray(resized_image)]})\n",
        "    seg_map = batch_seg_map[0]\n",
        "    \n",
        "    return resized_image, seg_map, graph\n",
        "\n",
        "\n",
        "def create_pascal_label_colormap():\n",
        "  colormap = np.zeros((256, 3), dtype=int)\n",
        "  ind = np.arange(256, dtype=int)\n",
        "  for shift in reversed(range(8)):\n",
        "    for channel in range(3):\n",
        "      colormap[:, channel] |= ((ind >> channel) & 1) << shift\n",
        "    ind >>= 3\n",
        "  return colormap\n",
        "\n",
        "\n",
        "def label_to_color_image(label):\n",
        "  if label.ndim != 2:\n",
        "    raise ValueError('Expect 2-D input label')\n",
        "  colormap = create_pascal_label_colormap()\n",
        "  if np.max(label) >= len(colormap):\n",
        "    raise ValueError('label value too large.')\n",
        "  return colormap[label]\n",
        "\n",
        "\n",
        "def visualize_segmentation(image, seg_map):\n",
        "  plt.figure(figsize=(20, 15))\n",
        "  plt.subplots_adjust(left=0, right=1, bottom=0, top=0.95, wspace=0.05, hspace=0.05)\n",
        "  plt.subplot(221), plt.imshow(image), plt.axis('off'), plt.title('input image', size=20)\n",
        "  plt.subplot(222)\n",
        "  seg_image = label_to_color_image(seg_map).astype(np.uint8)\n",
        "  plt.imshow(seg_image), plt.axis('off'), plt.title('segmentation map', size=20)\n",
        "  plt.subplot(223), plt.imshow(image), plt.imshow(seg_image, alpha=0.7), plt.axis('off'), plt.title('segmentation overlay', size=20)\n",
        "  unique_labels = np.unique(seg_map)\n",
        "  ax = plt.subplot(224)\n",
        "  plt.imshow(full_color_map[unique_labels].astype(np.uint8), interpolation='nearest')\n",
        "  ax.yaxis.tick_right(), plt.yticks(range(len(unique_labels)), label_names[unique_labels]), plt.xticks([], [])\n",
        "  ax.tick_params(width=0.0, labelsize=20), plt.grid('off')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "label_names = np.asarray([\n",
        "    'background', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus',\n",
        "    'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike',\n",
        "    'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tv'\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jIEUa-AyyvU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "full_label_map = np.arange(len(label_names)).reshape(len(label_names), 1)\n",
        "full_color_map = label_to_color_image(full_label_map)\n",
        "image, seg_map, graph = run_semantic_segmentation(Image.open('images/pets.png'), 'model2/frozen_inference_graph.pb')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ophwiWEdyyvX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfg.board(graph)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JplGJEoIyyvZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visualize_segmentation(image, seg_map)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MakpJUcdyyvb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image, seg_map, graph = run_semantic_segmentation(Image.open('images/road.png'), 'model2/frozen_inference_graph.pb')\n",
        "visualize_segmentation(image, seg_map)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57nHDhogyyvd",
        "colab_type": "text"
      },
      "source": [
        "### Semantic Segmentation with FCN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIGA6f8limdD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://dl.caffe.berkeleyvision.org/fcn8s-heavy-pascal.caffemodel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uz6D2LQUi7Sj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cp \"/content/fcn8s-heavy-pascal.caffemodel\" \"/content/models\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeB0lrsgyyvd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# http://dl.caffe.berkeleyvision.org/fcn8s-heavy-pascal.caffemodel\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "import imutils\n",
        "import time\n",
        "import cv2\n",
        "print(cv2.__version__)\n",
        "\n",
        "# load the class label names\n",
        "lines = open('models/pascal-classes.txt').read().strip().split(\"\\n\")\n",
        "classes, colors = [], []\n",
        "for line in lines:\n",
        "    words = line.split(' ')\n",
        "    classes.append(words[0])\n",
        "    colors.append(list(map(int, words[1:]))) \n",
        "colors = np.array(colors, dtype=\"uint8\")\n",
        "#print(classes)\n",
        "\n",
        "# initialize the legend visualization\n",
        "legend = np.zeros(((len(classes) * 25) + 25, 300, 3), dtype=\"uint8\")\n",
        "\n",
        "# loop over the class names + colors\n",
        "for (i, (className, color)) in enumerate(zip(classes, colors)):\n",
        "     # draw the class name + color on the legend\n",
        "     color = [int(c) for c in color]\n",
        "     cv2.putText(legend, className, (5, (i * 25) + 17), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
        "     cv2.rectangle(legend, (100, (i * 25)), (300, (i * 25) + 25), tuple(color), -1)\n",
        "\n",
        "# load our serialized model from disk\n",
        "print(\"[INFO] loading model...\")\n",
        "model = cv2.dnn.readNetFromCaffe('models/fcn8s-heavy-pascal.prototxt',\n",
        "                                 'models/fcn8s-heavy-pascal.caffemodel')\n",
        "\n",
        "# load the input image, resize it, and construct a blob from it,\n",
        "# but keeping mind mind that the original input image dimensions\n",
        "start = time.time()\n",
        "image = cv2.imread('images/cycling.png')\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "image = imutils.resize(image, width=500)\n",
        "\n",
        "# perform a forward pass using the segmentation model\n",
        "blob = cv2.dnn.blobFromImage(image, 1, (image.shape[1],image.shape[0]))\n",
        "model.setInput(blob)\n",
        "output = model.forward()\n",
        "end = time.time()\n",
        "\n",
        "# show the amount of time inference took\n",
        "print(\"[INFO] inference took {:.4f} seconds\".format(end - start))\n",
        "\n",
        "# infer the total number of classes along with the spatial dimensions\n",
        "# of the mask image via the shape of the output array\n",
        "(num_classes, height, width) = output.shape[1:4]\n",
        "\n",
        "# our output class ID map will be num_classes x height x width in\n",
        "# size, so we take the argmax to find the class label with the\n",
        "# largest probability for each and every (x, y)-coordinate in the\n",
        "# image\n",
        "labels = output[0].argmax(0)\n",
        "\n",
        "# given the class ID map, we can map each of the class IDs to its\n",
        "# corresponding color\n",
        "mask = colors[labels]\n",
        "\n",
        "# resize the mask and class map such that its dimensions match the\n",
        "# original size of the input image (we're not using the class map\n",
        "# here for anything else but this is how you would resize it just in\n",
        "# case you wanted to extract specific pixels/classes)\n",
        "mask = cv2.resize(mask, (image.shape[1], image.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
        "labels = cv2.resize(labels, (image.shape[1], image.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "# perform a weighted combination of the input image with the mask to\n",
        "# form an output visualization\n",
        "output = ((0.4 * image) + (0.6 * mask)).astype(\"uint8\")\n",
        "legend = imutils.resize(legend,  height=output.shape[0])\n",
        "\n",
        "plt.figure(figsize=(20,30))\n",
        "plt.subplots_adjust(left=0, right=1, bottom=0, top=0.95, wspace=0.05, hspace=0.05)\n",
        "plt.subplot(221), plt.imshow(image), plt.axis('off'), plt.title('Original Image', size=30)\n",
        "plt.subplot(222), plt.imshow(mask), plt.axis('off'), plt.title('Segmentation map', size=30)\n",
        "plt.subplot(223), plt.imshow(output), plt.axis('off'), plt.title('Image with Segmentaion overlay', size=30)\n",
        "plt.subplot(224), plt.imshow(legend), plt.axis('off'), plt.title('legends', size=30)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mGaeWqByyvf",
        "colab_type": "text"
      },
      "source": [
        "### Semantic Segmentation with XCeption Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IV67K7kslBkU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://download.tensorflow.org/models/deeplabv3_cityscapes_train_2018_02_06.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2-enFDZlQsV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -zxvf deeplabv3_cityscapes_train_2018_02_06.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KU9Zg-ooleTT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir model3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFh5nvQWlmei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cp \"/content/deeplabv3_cityscapes_train/frozen_inference_graph.pb\" \"/content/model3\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_H0TKHH3yyvg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "from matplotlib import gridspec\n",
        "import tensorflow as tf\n",
        "from tensorflow.io.gfile import GFile\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "def label_to_color_image(label):\n",
        "    \n",
        "    if label.ndim != 2:\n",
        "        raise ValueError('Expect 2-D input label')\n",
        "\n",
        "    colormap = np.array([\n",
        "        [128,  64, 128],\n",
        "        [244,  35, 232],\n",
        "        [ 70,  70,  70],\n",
        "        [102, 102, 156],\n",
        "        [190, 153, 153],\n",
        "        [153, 153, 153],\n",
        "        [250, 170,  30],\n",
        "        [220, 220,   0],\n",
        "        [107, 142,  35],\n",
        "        [152, 251, 152],\n",
        "        [ 70, 130, 180],\n",
        "        [220,  20,  60],\n",
        "        [255,   0,   0],\n",
        "        [  0,   0, 142],\n",
        "        [  0,   0,  70],\n",
        "        [  0,  60, 100],\n",
        "        [  0,  80, 100],\n",
        "        [  0,   0, 230],\n",
        "        [119,  11,  32],\n",
        "        [  0,   0,   0]], dtype=np.uint8)\n",
        "\n",
        "    if np.max(label) >= len(colormap):\n",
        "        raise ValueError('label value too large.')\n",
        "\n",
        "    return colormap[label]\n",
        "\n",
        "def visualize_segmentation(image, seg_map):\n",
        "  plt.figure(figsize=(20, 15))\n",
        "  plt.subplots_adjust(left=0, right=1, bottom=0, top=0.95, wspace=0.05, hspace=0.05)\n",
        "  plt.subplot(221), plt.imshow(image), plt.axis('off'), plt.title('input image', size=20)\n",
        "  plt.subplot(222)\n",
        "  seg_image = label_to_color_image(seg_map).astype(np.uint8)\n",
        "  plt.imshow(seg_image), plt.axis('off'), plt.title('segmentation map', size=20)\n",
        "  plt.subplot(223), plt.imshow(image), plt.imshow(seg_image, alpha=0.7), plt.axis('off'), plt.title('segmentation overlay', size=20)\n",
        "  unique_labels = np.unique(seg_map)\n",
        "  ax = plt.subplot(224)\n",
        "  plt.imshow(full_color_map[unique_labels].astype(np.uint8), interpolation='nearest')\n",
        "  ax.yaxis.tick_right(), plt.yticks(range(len(unique_labels)), label_names[unique_labels]), plt.xticks([], [])\n",
        "  ax.tick_params(width=0.0, labelsize=20), plt.grid('off')\n",
        "  plt.show()\n",
        "\n",
        "label_names = np.asarray([\n",
        "    'road', 'sidewalk', 'building', 'wall', 'fence', 'pole', 'traffic light',\n",
        "    'traffic sign', 'vegetation', 'terrain', 'sky', 'person', 'rider', 'car', 'truck',\n",
        "    'bus', 'train', 'motorcycle', 'bicycle', 'void'])\n",
        "\n",
        "full_label_map = np.arange(len(label_names)).reshape(len(label_names), 1)\n",
        "full_color_map = label_to_color_image(full_label_map)\n",
        "\n",
        "def run_semantic_segmentation(image, model_path):\n",
        "    graph = tf.Graph()\n",
        "    graph_def = None\n",
        "    with GFile(model_path, 'rb') as f:\n",
        "        #graph_def = tf.GraphDef()\n",
        "        graph_def = tf.compat.v1.GraphDef()\n",
        "        graph_def.ParseFromString(f.read())\n",
        "    if graph_def is None:\n",
        "        raise RuntimeError('Cannot find inference graph in tar archive.')\n",
        "    with graph.as_default():\n",
        "        tf.import_graph_def(graph_def, name='')\n",
        "    sess = tf.Session(graph=graph)\n",
        "    width, height = image.size\n",
        "    target_size = (2049,1025)  # size of Cityscapes images\n",
        "    resized_image = image.convert('RGB').resize(target_size, Image.ANTIALIAS)\n",
        "    batch_seg_map = sess.run('SemanticPredictions:0',\n",
        "            feed_dict={'ImageTensor:0': [np.asarray(resized_image)]})\n",
        "    seg_map = batch_seg_map[0]  # expected batch size = 1\n",
        "    if len(seg_map.shape) == 2:\n",
        "        seg_map = np.expand_dims(seg_map,-1)  # need an extra dimension for cv.resize\n",
        "    seg_map = cv2.resize(seg_map, (width,height), interpolation=cv2.INTER_NEAREST)\n",
        "    return seg_map\n",
        "\n",
        "#mobilenet: 'http://download.tensorflow.org/models/deeplabv3_mnv2_cityscapes_train_2018_02_05.tar.gz'\n",
        "#xception: 'http://download.tensorflow.org/models/deeplabv3_cityscapes_train_2018_02_06.tar.gz'\n",
        "\n",
        "model = 'model3/frozen_inference_graph.pb'\n",
        "image = 'images/road.png'\n",
        "image = Image.open(image)\n",
        "seg_map = run_semantic_segmentation(image, model)\n",
        "visualize_segmentation(image, seg_map)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VguMKnjCliRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfzymM3qyyvi",
        "colab_type": "text"
      },
      "source": [
        "### RandomWalk Segmentation with scikit-image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYUlfxteyyvi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://www.isro.gov.in/pslv-c25-mars-orbiter-mission/pictures-mars-colour-camera-mcc-onboard-india%E2%80%99s-mars-orbiter\n",
        "# https://www.isro.gov.in/image-galleries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "from skimage.segmentation import random_walker\n",
        "from skimage import img_as_float\n",
        "from skimage.exposure import rescale_intensity\n",
        "from skimage.io import imread\n",
        "from skimage.color import rgb2gray\n",
        "\n",
        "def colorbar(mappable):\n",
        "    ax = mappable.axes\n",
        "    fig = ax.figure\n",
        "    divider = make_axes_locatable(ax)\n",
        "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "    return fig.colorbar(mappable, cax=cax)\n",
        "\n",
        "img = imread('images/earth_by_MCC.png')\n",
        "#img = rgb2gray(img)\n",
        "mask = imread('images/earth_by_MCC_mask.png')\n",
        "markers = np.zeros(img.shape[:2],np.uint8)\n",
        "markers[(mask[...,0] >= 200)&(mask[...,1] <= 20)&(mask[...,2] <= 20)] = 1\n",
        "markers[(mask[...,0] <= 20)&(mask[...,1] >= 200)&(mask[...,2] <= 20)] = 2\n",
        "#print(np.unique(markers))\n",
        "\n",
        "# Run random walker algorithm\n",
        "labels = random_walker(img, markers, beta=9, mode='bf', multichannel=True)\n",
        "#print(np.unique(labels))\n",
        "labels2 = random_walker(img, markers, beta=9, mode='bf', multichannel=True, return_full_prob = True)\n",
        "#print(labels2.shape)\n",
        "\n",
        "# Plot results\n",
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(20, 18), sharex=True, sharey=False)\n",
        "fig.subplots_adjust(0,0,1,0.975,0.01,0.05)\n",
        "ax1.imshow(mask, interpolation='nearest'), ax1.axis('off')\n",
        "ax1.set_title('Original Image with Markers', size=25)\n",
        "ax2.imshow(img, interpolation='nearest'), ax2.contour(labels, linewidths=5, colors='r'), ax2.axis('off')\n",
        "ax2.set_title('Segmentation Contour', size=25)\n",
        "ax3.imshow(labels, cmap='gray', interpolation='nearest'), ax3.axis('off')\n",
        "ax3.set_title('Segmentation', size=25)\n",
        "prob = ax4.imshow(labels2[1,...], cmap='inferno', interpolation='nearest')\n",
        "ax4.axis('off'), ax4.set_title('Segmentation Probabilities', size=25)\n",
        "colorbar(prob)\n",
        "#fig.colorbar(prob, ax=ax4, orientation=\"horizontal\", pad=0.01)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2mtg9Ocyyvk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = imread('images/CT_bones.png')\n",
        "#img = rgb2gray(img)\n",
        "mask = imread('images/CT_bones_mask.png')\n",
        "markers = np.zeros(img.shape[:2],np.uint8)\n",
        "markers[(mask[...,0] == 255)&(mask[...,1] == 0)&(mask[...,2] == 0)] = 3\n",
        "markers[(mask[...,0] == 0)&(mask[...,1] == 255)&(mask[...,2] == 0)] = 2\n",
        "markers[(mask[...,0] == 0)&(mask[...,1] == 0)&(mask[...,2] == 255)] = 1\n",
        "#print(np.unique(markers))\n",
        "\n",
        "# Run random walker algorithm\n",
        "labels = random_walker(img, markers, beta=9, mode='bf', multichannel=True)\n",
        "#print(np.unique(labels))\n",
        "labels2 = random_walker(img, markers, beta=9, mode='bf', multichannel=True, return_full_prob = True)\n",
        "#print(labels2.shape)\n",
        "# Plot results\n",
        "from skimage.color import gray2rgb\n",
        "fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(18, 20), sharex=True, sharey=False)\n",
        "fig.subplots_adjust(0,0,1,0.975,0.01,0.05)\n",
        "ax1.imshow(img, interpolation='nearest'), ax1.axis('off')\n",
        "ax1.set_title('Original Image', size=25)\n",
        "ax2.imshow(mask, interpolation='nearest'), ax2.axis('off')\n",
        "ax2.set_title('Original Image with Markers', size=25)\n",
        "ax3.imshow(img, interpolation='nearest'), ax3.contour(labels, linewidths=5, colors='r'), ax3.axis('off')\n",
        "ax3.set_title('Segmentation Contour', size=25)\n",
        "labels = gray2rgb(labels) #labels[...,np.newaxis]\n",
        "labels[labels[...,0]==1] = [128,128,255]\n",
        "labels[labels[...,0]==2] = [128,255,128]\n",
        "labels[labels[...,0]==3] = [255,128,128]\n",
        "ax4.imshow((0.6*labels + 0.4*img).astype(np.uint8), cmap='jet', interpolation='nearest'), ax4.axis('off')\n",
        "ax4.set_title('Segmentation', size=25)\n",
        "prob = ax5.imshow(labels2[2,...], cmap='jet', interpolation='nearest')\n",
        "ax5.axis('off'), ax5.set_title('Segmentation Probabilities', size=25)\n",
        "colorbar(prob)\n",
        "prob = ax6.imshow(labels2[1,...], cmap='jet', interpolation='nearest')\n",
        "ax6.axis('off'), ax6.set_title('Segmentation Probabilities', size=25)\n",
        "colorbar(prob)\n",
        "#fig.colorbar(prob, ax=ax4, orientation=\"horizontal\", pad=0.01)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Jq9hDlyyyvm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}