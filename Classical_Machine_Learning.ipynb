{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "Classical Machine Learning",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mawhy/OpenCV/blob/master/Classical_Machine_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6t-pzcfUBYj",
        "colab_type": "text"
      },
      "source": [
        "# Hands-on Image Processing with Python\n",
        "## Classical Machine Learning Methods in Image Processing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGHHBhBfUBYk",
        "colab_type": "text"
      },
      "source": [
        "### Dimension reduction and visualization with PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ck4xaC-qUBYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "import matplotlib.pylab as pylab\n",
        "from sklearn.datasets import load_digits \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "digits = load_digits() \n",
        "#print(digits.keys())\n",
        "print(digits.data.shape)\n",
        "j = 1\n",
        "np.random.seed(1)\n",
        "fig = plt.figure(figsize=(3,3)) \n",
        "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05) \n",
        "for i in np.random.choice(digits.data.shape[0], 25):\n",
        "    plt.subplot(5,5,j), plt.imshow(np.reshape(digits.data[i,:], (8,8)), cmap='binary'), plt.axis('off')\n",
        "    j += 1\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "L-TfOqn0UBYr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pca_digits=PCA(2)\n",
        "digits.data_proj = pca_digits.fit_transform(digits.data) \n",
        "print(np.sum(pca_digits.explained_variance_ratio_))\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.scatter(digits.data_proj[:, 0], digits.data_proj[:, 1], lw=0.25, c=digits.target, edgecolor='k',  s=100, cmap=plt.cm.get_cmap('cubehelix', 10))\n",
        "plt.xlabel('PC1', size=20), plt.ylabel('PC2', size=20), plt.title('2D Projection of handwritten digits with PCA', size=25)\n",
        "plt.colorbar(ticks=range(10), label='digit value')\n",
        "plt.clim(-0.5, 9.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fr-OHdVYUBYv",
        "colab_type": "text"
      },
      "source": [
        "### Eigenfaces with PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4upxXYVUBYw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import fetch_olivetti_faces \n",
        "faces = fetch_olivetti_faces().data\n",
        "print(faces.shape) # there are 400 faces each of them is of 64x64=4096 pixels\n",
        "fig = plt.figure(figsize=(5,5)) \n",
        "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05) \n",
        "# plot 25 random faces\n",
        "j = 1\n",
        "np.random.seed(0)\n",
        "for i in np.random.choice(range(faces.shape[0]), 25): \n",
        "    ax = fig.add_subplot(5, 5, j, xticks=[], yticks=[]) \n",
        "    ax.imshow(np.reshape(faces[i,:],(64,64)), cmap=plt.cm.bone, interpolation='nearest') \n",
        "    j += 1\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tROGjo5kUBY0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "n_comp =64\n",
        "pipeline = Pipeline([('scaling', StandardScaler()), ('pca', PCA(n_components=n_comp))])\n",
        "faces_proj = pipeline.fit_transform(faces)\n",
        "print(faces_proj.shape)\n",
        "# (400, 64)\n",
        "mean_face = np.reshape(pipeline.named_steps['scaling'].mean_, (64,64))\n",
        "sd_face = np.reshape(np.sqrt(pipeline.named_steps['scaling'].var_), (64,64))\n",
        "pylab.figure(figsize=(8, 6))\n",
        "pylab.plot(np.cumsum(pipeline.named_steps['pca'].explained_variance_ratio_), linewidth=2)\n",
        "pylab.grid(), pylab.axis('tight'), pylab.xlabel('n_components'), pylab.ylabel('cumulative explained_variance_ratio_')\n",
        "pylab.show()\n",
        "pylab.figure(figsize=(10,5))\n",
        "pylab.subplot(121), pylab.imshow(mean_face, cmap=pylab.cm.bone), pylab.axis('off'), pylab.title('Mean face')\n",
        "pylab.subplot(122), pylab.imshow(sd_face, cmap=pylab.cm.bone), pylab.axis('off'), pylab.title('SD face')\n",
        "pylab.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTzMI8ysUBY5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(5,2)) \n",
        "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05) \n",
        "# plot the first 10 eigenfaces\n",
        "for i in range(10): \n",
        "    ax = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[]) \n",
        "    ax.imshow(np.reshape(pipeline.named_steps['pca'].components_[i,:], (64,64)), cmap=plt.cm.bone, interpolation='nearest')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHgLNjEmUBY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# face reconstruction\n",
        "faces_inv_proj = pipeline.named_steps['pca'].inverse_transform(faces_proj) \n",
        "#reshaping as 400 images of 64x64 dimension \n",
        "fig = plt.figure(figsize=(5,5)) \n",
        "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05) \n",
        "# plot the faces, each image is 64 by 64 dimension but 8x8 pixels \n",
        "j = 1\n",
        "np.random.seed(0)\n",
        "for i in np.random.choice(range(faces.shape[0]), 25): \n",
        "    ax = fig.add_subplot(5, 5, j, xticks=[], yticks=[]) \n",
        "    ax.imshow(mean_face + sd_face*np.reshape(faces_inv_proj,(400,64,64)) [i,:], cmap=plt.cm.bone, interpolation='nearest')\n",
        "    j += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRfrDCiuUBZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(faces_proj[0,:].shape)\n",
        "#print(pipeline.named_steps['pca'].components_.shape)\n",
        "orig_face = np.reshape(faces[0,:], (64,64))\n",
        "reconst_face = np.reshape(faces_proj[0,:]@pipeline.named_steps['pca'].components_, (64,64))\n",
        "reconst_face = mean_face + sd_face*reconst_face\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(121), plt.imshow(orig_face, cmap=plt.cm.bone, interpolation='nearest'), plt.axis('off'), plt.title('original', size=20)\n",
        "plt.subplot(122), plt.imshow(reconst_face, cmap=plt.cm.bone, interpolation='nearest'), plt.axis('off'), plt.title('reconstructed', size=20)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ggi8UMMUBZG",
        "colab_type": "text"
      },
      "source": [
        "### K-means clustering for image segmentation with color quantization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-O9JFLoUBZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import pairwise_distances_argmin\n",
        "from skimage.io import imread\n",
        "from sklearn.utils import shuffle\n",
        "from skimage import img_as_float\n",
        "from time import time\n",
        "\n",
        "pepper = imread(\"../images2/pepper.jpg\")\n",
        "\n",
        "# Display the original image\n",
        "plt.figure(1), plt.clf()\n",
        "ax = plt.axes([0, 0, 1, 1])\n",
        "plt.axis('off'), plt.title('Original image (%d colors)' %(len(np.unique(pepper)))), plt.imshow(pepper)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnzev5UpUBZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_colors = 64\n",
        "\n",
        "# Convert to floats instead of the default 8 bits integer coding. Dividing by\n",
        "# 255 is important so that plt.imshow behaves works well on float data (need to\n",
        "# be in the range [0-1])\n",
        "pepper = np.array(pepper, dtype=np.float64) / 255\n",
        "\n",
        "# Load Image and transform to a 2D numpy array.\n",
        "w, h, d = original_shape = tuple(pepper.shape)\n",
        "assert d == 3\n",
        "image_array = np.reshape(pepper, (w * h, d))\n",
        "\n",
        "def recreate_image(codebook, labels, w, h):\n",
        "    \"\"\"Recreate the (compressed) image from the code book & labels\"\"\"\n",
        "    d = codebook.shape[1]\n",
        "    image = np.zeros((w, h, d))\n",
        "    label_idx = 0\n",
        "    for i in range(w):\n",
        "        for j in range(h):\n",
        "            image[i][j] = codebook[labels[label_idx]]\n",
        "            label_idx += 1\n",
        "    return image\n",
        "\n",
        "# Display all results, alongside original image\n",
        "plt.figure(1)\n",
        "plt.clf()\n",
        "ax = plt.axes([0, 0, 1, 1])\n",
        "plt.axis('off')\n",
        "plt.title('Original image (96,615 colors)')\n",
        "plt.imshow(pepper)\n",
        "\n",
        "plt.figure(2, figsize=(10,10))\n",
        "plt.clf()\n",
        "i = 1\n",
        "for k in [64, 32, 16, 4]:\n",
        "    t0 = time()\n",
        "    plt.subplot(2,2,i)\n",
        "    plt.axis('off')\n",
        "    image_array_sample = shuffle(image_array, random_state=0)[:1000]\n",
        "    kmeans = KMeans(n_clusters=k, random_state=0).fit(image_array_sample)\n",
        "    print(\"done in %0.3fs.\" % (time() - t0))\n",
        "    # Get labels for all points\n",
        "    print(\"Predicting color indices on the full image (k-means)\")\n",
        "    t0 = time()\n",
        "    labels = kmeans.predict(image_array)\n",
        "    print(\"done in %0.3fs.\" % (time() - t0))\n",
        "    plt.title('Quantized image (' + str(k) + ' colors, K-Means)')\n",
        "    plt.imshow(recreate_image(kmeans.cluster_centers_, labels, w, h))\n",
        "    i += 1\n",
        "plt.show()\n",
        "\n",
        "        \n",
        "plt.figure(3, figsize=(10,10))\n",
        "plt.clf()\n",
        "i = 1\n",
        "for k in [64, 32, 16, 4]:\n",
        "    t0 = time()\n",
        "    plt.subplot(2,2,i)\n",
        "    plt.axis('off')\n",
        "    codebook_random = shuffle(image_array, random_state=0)[:k + 1]\n",
        "    print(\"Predicting color indices on the full image (random)\")\n",
        "    t0 = time()\n",
        "    labels_random = pairwise_distances_argmin(codebook_random,\n",
        "                                              image_array,\n",
        "                                              axis=0)\n",
        "    print(\"done in %0.3fs.\" % (time() - t0))    \n",
        "    plt.title('Quantized image (' + str(k) + ' colors, Random)')\n",
        "    plt.imshow(recreate_image(codebook_random, labels_random, w, h))\n",
        "    i += 1\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyv-3cS2UBZO",
        "colab_type": "text"
      },
      "source": [
        "### Spectral clustering for image segmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSh7ZPOhUBZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import cluster\n",
        "from skimage.io import imread\n",
        "from skimage.color import rgb2gray\n",
        "#from scipy.misc import imresize\n",
        "from skimage.transform import resize\n",
        "import matplotlib.pylab as pylab\n",
        "im = resize(imread('../images2/me14.jpg'), (100,100,3))\n",
        "img = rgb2gray(im)\n",
        "k = 2 # binary segmentation, with 2 output clusters / segments\n",
        "X = np.reshape(im, (-1, im.shape[-1]))\n",
        "two_means = cluster.MiniBatchKMeans(n_clusters=k, random_state=10)\n",
        "two_means.fit(X)\n",
        "y_pred = two_means.predict(X)\n",
        "labels = np.reshape(y_pred, im.shape[:2])\n",
        "pylab.figure(figsize=(20,20))\n",
        "pylab.subplot(221), pylab.imshow(np.reshape(y_pred, im.shape[:2])), pylab.title('k-means segmentation (k=2)', size=30)\n",
        "pylab.subplot(222), pylab.imshow(im), pylab.contour(labels == 0, colors='red'), pylab.axis('off')\n",
        "pylab.title('k-means contour (k=2)', size=30)\n",
        "spectral = cluster.SpectralClustering(n_clusters=k, eigen_solver='arpack', affinity=\"nearest_neighbors\", n_neighbors=100, random_state=10)\n",
        "spectral.fit(X) \n",
        "y_pred = spectral.labels_.astype(np.int)\n",
        "labels = np.reshape(y_pred, im.shape[:2])\n",
        "pylab.subplot(223), pylab.imshow(np.reshape(y_pred, im.shape[:2])), pylab.title('spctral segmentation (k=2)', size=30)\n",
        "pylab.subplot(224), pylab.imshow(im), pylab.contour(labels == 0, colors='red'), pylab.axis('off'), pylab.title('spectral contour (k=2)', size=30), pylab.tight_layout()\n",
        "pylab.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df1RG7rzUBZS",
        "colab_type": "text"
      },
      "source": [
        "### Classifying MNIST with k-nearest neighbors (KNN) classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yg0EfM_YUBZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt \n",
        "import gzip, os, sys\n",
        "import numpy as np\n",
        "from scipy.stats import multivariate_normal\n",
        "\n",
        "if sys.version_info[0] == 2:\n",
        "    from urllib import urlretrieve\n",
        "else:\n",
        "    from urllib.request import urlretrieve\n",
        "    \n",
        "# Function that downloads a specified MNIST data file from Yann Le Cun's website\n",
        "def download(filename, source='http://yann.lecun.com/exdb/mnist/'):\n",
        "    print(\"Downloading %s\" % filename)\n",
        "    urlretrieve(source + filename, filename)\n",
        "\n",
        "# Invokes download() if necessary, then reads in images\n",
        "def load_mnist_images(filename):\n",
        "    if not os.path.exists(filename):\n",
        "        download(filename)\n",
        "    with gzip.open(filename, 'rb') as f:\n",
        "        data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
        "    data = data.reshape(-1,784)\n",
        "    return data\n",
        "\n",
        "def load_mnist_labels(filename):\n",
        "    if not os.path.exists(filename):\n",
        "        download(filename)\n",
        "    with gzip.open(filename, 'rb') as f:\n",
        "        data = np.frombuffer(f.read(), np.uint8, offset=8)\n",
        "    return data\n",
        "\n",
        "## Load the training set\n",
        "#path = 'C:\\Courses\\Edx\\Current\\USCD ML\\Week3\\\\'\n",
        "train_data = load_mnist_images('train-images-idx3-ubyte.gz')\n",
        "train_labels = load_mnist_labels('train-labels-idx1-ubyte.gz')\n",
        "\n",
        "## Load the testing set\n",
        "test_data = load_mnist_images('t10k-images-idx3-ubyte.gz')\n",
        "test_labels = load_mnist_labels('t10k-labels-idx1-ubyte.gz')\n",
        "\n",
        "## Define a function that displays a digit given its vector representation\n",
        "def show_digit(x, label):\n",
        "    plt.axis('off')\n",
        "    plt.imshow(x.reshape((28,28)), cmap=plt.cm.gray)\n",
        "    plt.title('Label ' + str(label))\n",
        "    #plt.show()\n",
        "    #return\n",
        "\n",
        "## Define a function that takes an index into a particular data set (\"train\" or \"test\") and displays that image.\n",
        "def vis_image(index, dataset=\"train\"):\n",
        "    if(dataset==\"train\"): \n",
        "        label = train_labels[index]\n",
        "        show_digit(train_data[index,], label)\n",
        "    else:\n",
        "        label = test_labels[index]\n",
        "        show_digit(test_data[index,], label)\n",
        "    #print(\"Label \" + str(label))\n",
        "    plt.show()\n",
        "    return\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5, 5, i+1)\n",
        "    #show_digit(train_data[i,], train_labels[i])\n",
        "    show_digit(test_data[i,], test_labels[i])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1p6d40RUBZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# za długo liczy\n",
        "import time\n",
        "from sklearn.neighbors import BallTree\n",
        "## Build nearest neighbor structure on training data\n",
        "t_before = time.time()\n",
        "ball_tree = BallTree(train_data)\n",
        "t_after = time.time()\n",
        "## Compute training time\n",
        "t_training = t_after - t_before\n",
        "print(\"Time to build data structure (seconds): \", t_training)\n",
        "## Get nearest neighbor predictions on testing data\n",
        "t_before = time.time()\n",
        "test_neighbors = np.squeeze(ball_tree.query(test_data, k=1, return_distance=False))\n",
        "test_predictions = train_labels[test_neighbors]\n",
        "t_after = time.time()\n",
        "## Compute testing time\n",
        "t_testing = t_after - t_before\n",
        "print(\"Time to classify test set (seconds): \", t_testing)\n",
        "# evaluate the classifier\n",
        "t_accuracy = sum(test_predictions == test_labels) / float(len(test_labels))\n",
        "t_accuracy\n",
        "# 0.96909999999999996\n",
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "from sklearn import metrics\n",
        "cm = metrics.confusion_matrix(test_labels,test_predictions)\n",
        "df_cm = pd.DataFrame(cm, range(10), range(10))\n",
        "sn.set(font_scale=1.2)# for label size\n",
        "sn.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}, fmt=\"g\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LubehYHXUBZc",
        "colab_type": "text"
      },
      "source": [
        "### Classifying MNIST with Bayes classifier (Gaussian generative model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3omH2R3vUBZc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def display_char(image):\n",
        "    plt.imshow(np.reshape(image, (28,28)), cmap=plt.cm.gray)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "def fit_generative_model(x,y):\n",
        "    k = 10  # labels 0,1,...,k-1\n",
        "    d = (x.shape)[1]  # number of features\n",
        "    mu = np.zeros((k,d))\n",
        "    sigma = np.zeros((k,d,d))\n",
        "    pi = np.zeros(k)\n",
        "    c = 3500 #10000 #1000 #100 #10 #0.1 #1e9\n",
        "    for label in range(k):\n",
        "        indices = (y == label)\n",
        "        pi[label] = sum(indices) / float(len(y))\n",
        "        mu[label] = np.mean(x[indices,:], axis=0)\n",
        "        sigma[label] = np.cov(x[indices,:], rowvar=0, bias=1) + c*np.eye(d)\n",
        "    return mu, sigma, pi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19jQG-gAUBZg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mu, sigma, pi = fit_generative_model(train_data, train_labels)\n",
        "display_char(mu[0])\n",
        "display_char(mu[1])\n",
        "display_char(mu[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wM6RbyvnUBZk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute log Pr(label|image) for each [test image,label] pair.\n",
        "k = 10\n",
        "score = np.zeros((len(test_labels),k))\n",
        "for label in range(0,k):\n",
        "    rv = multivariate_normal(mean=mu[label], cov=sigma[label])\n",
        "    for i in range(0,len(test_labels)):\n",
        "       score[i,label] = np.log(pi[label]) + rv.logpdf(test_data[i,:])\n",
        "test_predictions = np.argmax(score, axis=1)\n",
        "# Finally, tally up score\n",
        "errors = np.sum(test_predictions != test_labels)\n",
        "print(\"The generative model makes \" + str(errors) + \" errors out of 10000\")\n",
        "t_accuracy = sum(test_predictions == test_labels) / float(len(test_labels))\n",
        "t_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8I28qM0UBZo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_data.shape)\n",
        "print(test_data.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wCoSTfoUBZs",
        "colab_type": "text"
      },
      "source": [
        "### Claasfying MNIST with SVM classifier - za długo liczy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIAnBYfTUBZt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# za długo liczy\n",
        "from sklearn.svm import SVC\n",
        "C = 1\n",
        "#for C in [.01,.1,1.,10.,100.]:\n",
        "clf = SVC(C=C, kernel='poly', degree=2)\n",
        "clf.fit(train_data,train_labels)\n",
        "print(C, clf.score(test_data,test_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsPFxUCLUBZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "from sklearn import metrics\n",
        "test_predictions = clf.predict(test_data)\n",
        "cm=metrics.confusion_matrix(test_labels,test_predictions)\n",
        "df_cm = pd.DataFrame(cm, range(10), range(10))\n",
        "#plt.figure(figsize = (10,7))\n",
        "sn.set(font_scale=1.2)#for label size\n",
        "sn.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}, fmt=\"g\") #, cmap='viridis')# font size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mY5QdVbUBZz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrong_indices = test_predictions != test_labels\n",
        "wrong_digits, wrong_preds, correct_labs = test_data[wrong_indices], test_predictions[wrong_indices], test_labels[wrong_indices] \n",
        "print(len(wrong_pred))\n",
        "plt.title('predicted: ' + str(wrong_preds[1]) + ', actual: ' + str(correct_labs[1]))\n",
        "display_char(wrong_digits[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tw-LLUZSUBZ2",
        "colab_type": "text"
      },
      "source": [
        "### Finding the most important Haar-like features for face classification with the random forest ensemble classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y42CDK-GUBZ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from time import time\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from dask import delayed\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "from skimage.data import lfw_subset\n",
        "from skimage.transform import integral_image\n",
        "from skimage.feature import haar_like_feature\n",
        "from skimage.feature import haar_like_feature_coord\n",
        "from skimage.feature import draw_haar_like_feature\n",
        "\n",
        "@delayed\n",
        "def extract_feature_image(img, feature_type, feature_coord=None):\n",
        "    \"\"\"Extract the haar feature for the current image\"\"\"\n",
        "    ii = integral_image(img)\n",
        "    return haar_like_feature(ii, 0, 0, ii.shape[0], ii.shape[1],\n",
        "                             feature_type=feature_type,\n",
        "                             feature_coord=feature_coord)\n",
        "\n",
        "images = lfw_subset()\n",
        "print(images.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p05xt07HUBZ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(5,5))\n",
        "fig.subplots_adjust(left=0, right=0.9, bottom=0, top=0.9, hspace=0.05, wspace=0.05) \n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1), plt.imshow(images[i,:,:], cmap='bone'), plt.axis('off')\n",
        "plt.suptitle('Faces')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A27KcudnUBZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(5,5))\n",
        "fig.subplots_adjust(left=0, right=0.9, bottom=0, top=0.9, hspace=0.05, wspace=0.05) \n",
        "for i in range(100,125):\n",
        "    plt.subplot(5,5,i-99), plt.imshow(images[i,:,:], cmap='bone'), plt.axis('off')\n",
        "plt.suptitle('Non-Faces')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgs-XfKvUBaB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For speed, only extract the two first types of features\n",
        "feature_types = ['type-2-x', 'type-2-y']\n",
        "\n",
        "# Build a computation graph using dask. This allows using multiple CPUs for\n",
        "# the computation step\n",
        "X = delayed(extract_feature_image(img, feature_types)\n",
        "            for img in images)\n",
        "# Compute the result using the \"processes\" dask backend\n",
        "t_start = time()\n",
        "X = np.array(X.compute(scheduler='processes'))\n",
        "time_full_feature_comp = time() - t_start\n",
        "y = np.array([1] * 100 + [0] * 100)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=150,\n",
        "                                                    random_state=0,\n",
        "                                                    stratify=y)\n",
        "print(time_full_feature_comp)\n",
        "print(X.shape, X_train.shape, y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEgW8BefUBaH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "# Extract all possible features to be able to select the most salient.\n",
        "feature_coord, feature_type = \\\n",
        "        haar_like_feature_coord(width=images.shape[2], height=images.shape[1],\n",
        "                                feature_type=feature_types)\n",
        "    \n",
        "# Train a random forest classifier and check performance\n",
        "clf = RandomForestClassifier(n_estimators=1000, max_depth=None,\n",
        "                             max_features=100, n_jobs=-1, random_state=0)\n",
        "t_start = time()\n",
        "clf.fit(X_train, y_train)\n",
        "time_full_train = time() - t_start\n",
        "auc_full_features = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\n",
        "print(auc_full_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seOeREvqUBaO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sort features in order of importance, plot six most significant\n",
        "idx_sorted = np.argsort(clf.feature_importances_)[::-1]\n",
        "\n",
        "fig, axes = plt.subplots(5, 5, figsize=(10,10))\n",
        "for idx, ax in enumerate(axes.ravel()):\n",
        "    image = images[1]\n",
        "    image = draw_haar_like_feature(image, 0, 0,\n",
        "                                   images.shape[2],\n",
        "                                   images.shape[1],\n",
        "                                   [feature_coord[idx_sorted[idx]]])\n",
        "    ax.imshow(image)\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "\n",
        "fig.suptitle('The most important features', size=30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCuklREoUBaR",
        "colab_type": "text"
      },
      "source": [
        "### Detecting objects with SVM using HOG features "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-WwmTmPUBaS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pylab as plt \n",
        "\n",
        "# read in test image (from Microsoft COCO database)\n",
        "img = cv2.imread(\"../images2/me16.jpg\")\n",
        "\n",
        "# create HOG descriptor using default people (pedestrian) detector\n",
        "hog = cv2.HOGDescriptor()\n",
        "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
        "\n",
        "# run detection, using a spatial stride of 4 pixels (horizontal and verticle), a scale stride of 1.02, and zero grouping of\n",
        "# rectangles (to demonstrate that HOG will detect at potentially multiple places in the scale pyramid)\n",
        "#img = cv2.resize(img, (0,0), fx=0.5, fy=0.5) \n",
        "#(foundBoundingBoxes, weights) = hog.detectMultiScale(img, winStride=(4, 4), padding=(8, 8), scale=2, finalThreshold=0, useMeanshiftGrouping=True)\n",
        "(foundBoundingBoxes, weights) = hog.detectMultiScale(img, winStride=(4, 4), padding=(8, 8), scale=1.02, finalThreshold=0, useMeanshiftGrouping=False)\n",
        "\n",
        "print(len(foundBoundingBoxes))\n",
        "# we're going to copy the original test image to draw bounding boxes on it for now, as we'll use it again later\n",
        "imgWithRawBboxes = img.copy()\n",
        "for (hx, hy, hw, hh) in foundBoundingBoxes:\n",
        "        cv2.rectangle(imgWithRawBboxes, (hx, hy), (hx + hw, hy + hh), (0, 0, 255), 1)\n",
        "        \n",
        "#plt.figure(figsize=(14, 10), dpi=80)\n",
        "plt.figure(figsize=(10, 8))#, dpi=80)\n",
        "imgWithRawBboxes = cv2.cvtColor(imgWithRawBboxes, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "plt.imshow(imgWithRawBboxes, aspect='auto'), plt.axis('off'), plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXoNAlfFUBaV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imutils.object_detection import non_max_suppression\n",
        "\n",
        "# convert our bounding boxes from format (x1, y1, w, h) to (x1, y1, x2, y2)\n",
        "rects = np.array([[x, y, x + w, y + h] for (x, y, w, h) in foundBoundingBoxes])\n",
        "\n",
        "# run non-max suppression on these based on an overlay op 65%\n",
        "nmsBoundingBoxes = non_max_suppression(rects, probs=None, overlapThresh=0.65)\n",
        "\n",
        "print (\"Before suppression, we had {} bounding boxes, after suppression we have {}\".format(len(rects), len(nmsBoundingBoxes)))\n",
        "\n",
        "# draw the final bounding boxes\n",
        "for (xA, yA, xB, yB) in nmsBoundingBoxes:\n",
        "    cv2.rectangle(img, (xA, yA), (xB, yB), (0, 255, 0), 2)\n",
        "\n",
        "# and show our work\n",
        "plt.figure(figsize=(10, 8)) #, dpi=80)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(img, aspect='auto') \n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lP2QIcQSUBaY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}