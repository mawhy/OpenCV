{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "colab": {
      "name": "Extracting Image Features and Descriptors",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mawhy/OpenCV/blob/master/Extracting_Image_Features_and_Descriptors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIBnIEulSffh",
        "colab_type": "text"
      },
      "source": [
        "# Hands-on Image Processing with Python\n",
        "## Extracting Image Features and Descriptors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNwdiwnSSffi",
        "colab_type": "text"
      },
      "source": [
        "### Author: Sandipan Dey"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNKPqap4S5DT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/PacktPublishing/Hands-On-Image-Processing-with-Python.git\n",
        "%cp -av \"/content/Hands-On-Image-Processing-with-Python/images/\" \"/\"\n",
        "%rm -rf \"/content/Hands-On-Image-Processing-with-Python\"\n",
        "%cp -av \"/images/temple.JPG\" \"/images/temple.jpg\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbzGAwQQSffi",
        "colab_type": "text"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrIuLFk_Sffj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "% matplotlib inline\n",
        "from matplotlib import pylab as pylab\n",
        "from skimage.io import imread\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.feature import corner_harris, corner_subpix, corner_peaks\n",
        "from skimage.transform import warp, SimilarityTransform, AffineTransform, resize\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage import data\n",
        "from skimage.util import img_as_float\n",
        "from skimage.exposure import rescale_intensity\n",
        "from skimage.measure import ransac"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCdEwNi8Sffm",
        "colab_type": "text"
      },
      "source": [
        "### Harris Corner Detector With scikit-image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcL9vAg_Sffn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = imread('../images/chess_football.png') # RGB image\n",
        "image_gray = rgb2gray(image)\n",
        "coordinates = corner_harris(image_gray, k =0.001)\n",
        "image[coordinates>0.01*coordinates.max()]=[255,0,0,255]\n",
        "pylab.figure(figsize=(20,10))\n",
        "pylab.imshow(image), pylab.axis('off'), pylab.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbWoZzIpSffq",
        "colab_type": "text"
      },
      "source": [
        "### With sub-pixel accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WvMhEEdSffr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = imread('../images/pyramids2.jpg')\n",
        "image_gray = rgb2gray(image)\n",
        "coordinates = corner_harris(image_gray, k =0.001)\n",
        "coordinates[coordinates > 0.03*coordinates.max()] = 255 # threshold for an optimal value, depends on the image\n",
        "corner_coordinates = corner_peaks(coordinates)\n",
        "coordinates_subpix = corner_subpix(image_gray, corner_coordinates, window_size=11)\n",
        "pylab.figure(figsize=(20,20))\n",
        "pylab.subplot(211), pylab.imshow(coordinates, cmap='inferno')\n",
        "pylab.plot(coordinates_subpix[:, 1], coordinates_subpix[:, 0], 'r.', markersize=5, label='subpixel')\n",
        "pylab.legend(prop={'size': 20}), pylab.axis('off')\n",
        "pylab.subplot(212), pylab.imshow(image, interpolation='nearest')\n",
        "pylab.plot(corner_coordinates[:, 1], corner_coordinates[:, 0], 'bo', markersize=5)\n",
        "pylab.plot(coordinates_subpix[:, 1], coordinates_subpix[:, 0], 'r+', markersize=10), pylab.axis('off')\n",
        "pylab.tight_layout(), pylab.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOCWS5qsSfft",
        "colab_type": "text"
      },
      "source": [
        "### Robust image matching using the RANSAC algorithm and Harris Corner features "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVH6pceySffu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temple = rgb2gray(img_as_float(imread('../images/temple.jpg')))\n",
        "image_original = np.zeros(list(temple.shape) + [3])\n",
        "image_original[..., 0] = temple\n",
        "gradient_row, gradient_col = (np.mgrid[0:image_original.shape[0], 0:image_original.shape[1]] / float(image_original.shape[0]))\n",
        "image_original[..., 1] = gradient_row\n",
        "image_original[..., 2] = gradient_col\n",
        "image_original = rescale_intensity(image_original)\n",
        "image_original_gray = rgb2gray(image_original)\n",
        "affine_trans = AffineTransform(scale=(0.8, 0.9), rotation=0.1, translation=(120, -20))\n",
        "image_warped = warp(image_original, affine_trans .inverse, output_shape=image_original.shape)\n",
        "image_warped_gray = rgb2gray(image_warped)\n",
        "coordinates = corner_harris(image_original_gray)\n",
        "coordinates[coordinates > 0.01*coordinates.max()] = 1\n",
        "coordinates_original = corner_peaks(coordinates, threshold_rel=0.0001, min_distance=5)\n",
        "coordinates = corner_harris(image_warped_gray)\n",
        "coordinates[coordinates > 0.01*coordinates.max()] = 1\n",
        "coordinates_warped = corner_peaks(coordinates, threshold_rel=0.0001, min_distance=5)\n",
        "coordinates_original_subpix = corner_subpix(image_original_gray, coordinates_original, window_size=9)\n",
        "coordinates_warped_subpix = corner_subpix(image_warped_gray, coordinates_warped, window_size=9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9tJu4FpSffw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gaussian_weights(window_ext, sigma=1):\n",
        "    y, x = np.mgrid[-window_ext:window_ext+1, -window_ext:window_ext+1]\n",
        "    g_w = np.zeros(y.shape, dtype = np.double)\n",
        "    g_w[:] = np.exp(-0.5 * (x**2 / sigma**2 + y**2 / sigma**2))\n",
        "    g_w /= 2 * np.pi * sigma * sigma\n",
        "    return g_w"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAjZP7RgSffz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def match_corner(coordinates, window_ext=3):\n",
        "    row, col = np.round(coordinates).astype(np.intp)\n",
        "    window_original = image_original[row-window_ext:row+window_ext+1, col-window_ext:col+window_ext+1, :]\n",
        "    weights = gaussian_weights(window_ext, 3)\n",
        "    weights = np.dstack((weights, weights, weights))\n",
        "    SSDs = []\n",
        "    for coord_row, coord_col in coordinates_warped:\n",
        "        window_warped = image_warped[coord_row-window_ext:coord_row+window_ext+1,\n",
        "        coord_col-window_ext:coord_col+window_ext+1, :]\n",
        "        if window_original.shape == window_warped.shape:\n",
        "            SSD = np.sum(weights * (window_original - window_warped)**2)\n",
        "            SSDs.append(SSD)\n",
        "    min_idx = np.argmin(SSDs) if len(SSDs) > 0 else -1\n",
        "    return coordinates_warped_subpix[min_idx] if min_idx >= 0 else [None]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZjcDsOWSff2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage.feature import (match_descriptors, corner_peaks, corner_harris, plot_matches, BRIEF)\n",
        "source, destination = [], []\n",
        "for coordinates in coordinates_original_subpix:\n",
        "    coordinates1 = match_corner(coordinates)\n",
        "    if any(coordinates1) and len(coordinates1) > 0 and not all(np.isnan(coordinates1)):\n",
        "        source.append(coordinates)\n",
        "        destination.append(coordinates1)\n",
        "source = np.array(source)\n",
        "destination = np.array(destination)\n",
        "model = AffineTransform()\n",
        "model.estimate(source, destination)\n",
        "model_robust, inliers = ransac((source, destination), AffineTransform, min_samples=3, residual_threshold=2, max_trials=100)\n",
        "outliers = inliers == False\n",
        "print(affine_trans.scale, affine_trans.translation, affine_trans.rotation)\n",
        "print(model.scale, model.translation, model.rotation)\n",
        "print(model_robust.scale, model_robust.translation, model_robust.rotation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2KcXhabSff4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, axes = pylab.subplots(nrows=2, ncols=1, figsize=(20,15))\n",
        "pylab.gray()\n",
        "inlier_idxs = np.nonzero(inliers)[0]\n",
        "plot_matches(axes[0], image_original_gray, image_warped_gray, source, destination, np.column_stack((inlier_idxs, inlier_idxs)),matches_color='b')\n",
        "axes[0].axis('off'), axes[0].set_title('Correct correspondences', size=20)\n",
        "outlier_idxs = np.nonzero(outliers)[0]\n",
        "plot_matches(axes[1], image_original_gray, image_warped_gray, source, destination, np.column_stack((outlier_idxs, outlier_idxs)), matches_color='r')\n",
        "axes[1].axis('off'), axes[1].set_title('Faulty correspondences', size=20)\n",
        "fig.tight_layout(), pylab.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjQckzMASff6",
        "colab_type": "text"
      },
      "source": [
        "### Blob detectors with LoG, DoG and DoH"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEoEGXXeSff6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import sqrt\n",
        "from skimage.feature import blob_dog, blob_log, blob_doh\n",
        "im = imread('../images/butterfly.png')\n",
        "im_gray = rgb2gray(im)\n",
        "log_blobs = blob_log(im_gray, max_sigma=30, num_sigma=10, threshold=.1)\n",
        "log_blobs[:, 2] = sqrt(2) * log_blobs[:, 2] # Compute radius in the 3rd column\n",
        "dog_blobs = blob_dog(im_gray, max_sigma=30, threshold=0.1)\n",
        "dog_blobs[:, 2] = sqrt(2) * dog_blobs[:, 2]\n",
        "doh_blobs = blob_doh(im_gray, max_sigma=30, threshold=0.005)\n",
        "list_blobs = [log_blobs, dog_blobs, doh_blobs]\n",
        "colors, titles = ['yellow', 'lime', 'red'], ['Laplacian of Gaussian', 'Difference of Gaussian', 'Determinant of Hessian']\n",
        "sequence = zip(list_blobs, colors, titles)\n",
        "fig, axes = pylab.subplots(2, 2, figsize=(20, 20), sharex=True, sharey=True)\n",
        "axes = axes.ravel()\n",
        "axes[0].imshow(im, interpolation='nearest')\n",
        "axes[0].set_title('original image', size=30), axes[0].set_axis_off()\n",
        "for idx, (blobs, color, title) in enumerate(sequence):\n",
        "    axes[idx+1].imshow(im, interpolation='nearest')\n",
        "    axes[idx+1].set_title('Blobs with ' + title, size=30)\n",
        "    for blob in blobs:\n",
        "        y, x, row = blob\n",
        "        col = pylab.Circle((x, y), row, color=color, linewidth=2, fill=False)\n",
        "        axes[idx+1].add_patch(col), axes[idx+1].set_axis_off()\n",
        "pylab.tight_layout(), pylab.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnIKSUAdSff9",
        "colab_type": "text"
      },
      "source": [
        "### Compute HOG descriptors with scikit-image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0DlxTq_Sff-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage.feature import hog\n",
        "from skimage import exposure\n",
        "image = rgb2gray(imread('../images/cameraman.jpg'))\n",
        "fd, hog_image = hog(image, orientations=8, pixels_per_cell=(16, 16),\n",
        "cells_per_block=(1, 1), visualize=True)\n",
        "print(image.shape, len(fd))\n",
        "# ((256L, 256L), 2048)\n",
        "fig, (axes1, axes2) = pylab.subplots(1, 2, figsize=(15, 10), sharex=True, sharey=True)\n",
        "axes1.axis('off'), axes1.imshow(image, cmap=pylab.cm.gray), axes1.set_title('Input image')\n",
        "hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n",
        "axes2.axis('off'), axes2.imshow(hog_image_rescaled, cmap=pylab.cm.gray),\n",
        "axes2.set_title('Histogram of Oriented Gradients')\n",
        "pylab.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKlO35-tSfgA",
        "colab_type": "text"
      },
      "source": [
        "### Scale-invariant feature transform (SIFT)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwyK2ZXwU8IR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make sure the opencv version is 3.3.0 with \n",
        "!pip install opencv-python==3.3.0.10 opencv-contrib-python==3.3.0.10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "If_aCS44VVej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "% matplotlib inline\n",
        "from matplotlib import pylab as pylab\n",
        "from skimage.io import imread\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.feature import corner_harris, corner_subpix, corner_peaks\n",
        "from skimage.transform import warp, SimilarityTransform, AffineTransform, resize\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage import data\n",
        "from skimage.util import img_as_float\n",
        "from skimage.exposure import rescale_intensity\n",
        "from skimage.measure import ransac"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeAqwklySfgB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "print(cv2.__version__)\n",
        "# 3.3.0\n",
        "img = cv2.imread('../images/monalisa.jpg')\n",
        "gray= cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "sift = cv2.xfeatures2d.SIFT_create()\n",
        "kp = sift.detect(gray,None) # detect SIFT keypoints\n",
        "img = cv2.drawKeypoints(img,kp, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
        "cv2.imwrite('../images/me5_keypoints.jpg',img)\n",
        "kp, des = sift.detectAndCompute(gray,None) # compute the SIFT descriptor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DWyyWcXSfgD",
        "colab_type": "text"
      },
      "source": [
        "### Matching images with BRIEF binary descriptors with scikit-image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x66H6ljtSfgD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage import transform as transform\n",
        "from skimage.feature import (match_descriptors, corner_peaks, corner_harris, plot_matches, BRIEF)\n",
        "img1 = rgb2gray(imread('../images/lena.jpg')) #data.astronaut())\n",
        "affine_trans = transform.AffineTransform(scale=(1.2, 1.2), translation=(0,-100))\n",
        "img2 = transform.warp(img1, affine_trans)\n",
        "img3 = transform.rotate(img1, 25)\n",
        "coords1, coords2, coords3 = corner_harris(img1), corner_harris(img2), corner_harris(img3)\n",
        "coords1[coords1 > 0.01*coords1.max()] = 1\n",
        "coords2[coords2 > 0.01*coords2.max()] = 1\n",
        "coords3[coords3 > 0.01*coords3.max()] = 1\n",
        "keypoints1 = corner_peaks(coords1, min_distance=5)\n",
        "keypoints2 = corner_peaks(coords2, min_distance=5)\n",
        "keypoints3 = corner_peaks(coords3, min_distance=5)\n",
        "extractor = BRIEF()\n",
        "extractor.extract(img1, keypoints1)\n",
        "keypoints1, descriptors1 = keypoints1[extractor.mask], extractor.descriptors\n",
        "extractor.extract(img2, keypoints2)\n",
        "keypoints2, descriptors2 = keypoints2[extractor.mask], extractor.descriptors\n",
        "extractor.extract(img3, keypoints3)\n",
        "keypoints3, descriptors3 = keypoints3[extractor.mask], extractor.descriptors\n",
        "matches12 = match_descriptors(descriptors1, descriptors2, cross_check=True)\n",
        "matches13 = match_descriptors(descriptors1, descriptors3, cross_check=True)\n",
        "fig, axes = pylab.subplots(nrows=2, ncols=1, figsize=(20,20))\n",
        "pylab.gray(), plot_matches(axes[0], img1, img2, keypoints1, keypoints2, matches12)\n",
        "axes[0].axis('off'), axes[0].set_title(\"Original Image vs. Transformed Image\")\n",
        "plot_matches(axes[1], img1, img3, keypoints1, keypoints3, matches13)\n",
        "axes[1].axis('off'), axes[1].set_title(\"Original Image vs. Transformed Image\"), pylab.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2-VsNvpSfgF",
        "colab_type": "text"
      },
      "source": [
        "### Matching with ORB feature detector and binary descriptor using scikit-image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVEy4qRDSfgG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage import transform as transform\n",
        "from skimage.feature import (match_descriptors, ORB, plot_matches)\n",
        "img1 = rgb2gray(imread('../images/me5.jpg'))\n",
        "img2 = transform.rotate(img1, 180)\n",
        "affine_trans = transform.AffineTransform(scale=(1.3, 1.1), rotation=0.5, translation=(0, -200))\n",
        "img3 = transform.warp(img1, affine_trans)\n",
        "img4 = transform.resize(rgb2gray(imread('../images/me6.jpg')), img1.shape, anti_aliasing=True)\n",
        "descriptor_extractor = ORB(n_keypoints=200)\n",
        "descriptor_extractor.detect_and_extract(img1)\n",
        "keypoints1, descriptors1 = descriptor_extractor.keypoints, descriptor_extractor.descriptors\n",
        "descriptor_extractor.detect_and_extract(img2)\n",
        "keypoints2, descriptors2 = descriptor_extractor.keypoints, descriptor_extractor.descriptors\n",
        "descriptor_extractor.detect_and_extract(img3)\n",
        "keypoints3, descriptors3 = descriptor_extractor.keypoints, descriptor_extractor.descriptors\n",
        "descriptor_extractor.detect_and_extract(img4)\n",
        "keypoints4, descriptors4 = descriptor_extractor.keypoints, descriptor_extractor.descriptors\n",
        "matches12 = match_descriptors(descriptors1, descriptors2, cross_check=True)\n",
        "matches13 = match_descriptors(descriptors1, descriptors3, cross_check=True)\n",
        "matches14 = match_descriptors(descriptors1, descriptors4, cross_check=True)\n",
        "fig, axes = pylab.subplots(nrows=3, ncols=1, figsize=(20,25))\n",
        "pylab.gray()\n",
        "plot_matches(axes[0], img1, img2, keypoints1, keypoints2, matches12)\n",
        "axes[0].axis('off'), axes[0].set_title(\"Original Image vs. Transformed Image\", size=20)\n",
        "plot_matches(axes[1], img1, img3, keypoints1, keypoints3, matches13)\n",
        "axes[1].axis('off'), axes[1].set_title(\"Original Image vs. Transformed Image\", size=20)\n",
        "plot_matches(axes[2], img1, img4, keypoints1, keypoints4, matches14)\n",
        "axes[2].axis('off'), axes[2].set_title(\"Image1 vs. Image2\", size=20)\n",
        "pylab.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9ZcDLsuSfgI",
        "colab_type": "text"
      },
      "source": [
        "### Matching with ORB features using Brute-Force matching with python-opencv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7mpYioXSfgJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img1 = cv2.imread('../images/books.png',0) # queryImage\n",
        "img2 = cv2.imread('../images/book.png',0) # trainImage\n",
        "# Create a ORB detector object\n",
        "orb = cv2.ORB_create()\n",
        "# find the keypoints and descriptors\n",
        "kp1, des1 = orb.detectAndCompute(img1,None)\n",
        "kp2, des2 = orb.detectAndCompute(img2,None)\n",
        "# create a BFMatcher object\n",
        "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
        "# Match descriptors.\n",
        "matches = bf.match(des1, des2)\n",
        "# Sort them in the order of their distance.\n",
        "matches = sorted(matches, key = lambda x:x.distance)\n",
        "# Draw first 20 matches.\n",
        "img3 = cv2.drawMatches(img1,kp1,img2,kp2,matches[:20], None, flags=2)\n",
        "pylab.figure(figsize=(20,10)), pylab.imshow(img3), pylab.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vD5Sc51gSfgL",
        "colab_type": "text"
      },
      "source": [
        "### Brute-force matching with SIFT descriptors and ratio test with OpenCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKep9jzLSfgM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make sure the opencv version is 3.3.0 with pip install opencv-python==3.3.0.10 opencv-contrib-python==3.3.0.10\n",
        "import cv2\n",
        "print(cv2.__version__)\n",
        "# 3.3.0\n",
        "img1 = cv2.imread('../images/books.png',0) # queryImage\n",
        "img2 = cv2.imread('../images/book.png',0) # trainImage\n",
        "# Create a SIFT detector object\n",
        "sift = cv2.xfeatures2d.SIFT_create()\n",
        "# find the keypoints and descriptors with SIFT\n",
        "kp1, des1 = sift.detectAndCompute(img1,None)\n",
        "kp2, des2 = sift.detectAndCompute(img2,None)\n",
        "bf = cv2.BFMatcher()\n",
        "matches = bf.knnMatch(des1, des2, k=2)\n",
        "# Apply ratio test\n",
        "good_matches = []\n",
        "for m1, m2 in matches:\n",
        "    if m1.distance < 0.75*m2.distance:\n",
        "        good_matches.append([m1])\n",
        "img3 = cv2.drawMatchesKnn(img1, kp1, img2, kp2,good_matches, None, flags=2)\n",
        "pylab.figure(figsize=(20,10)), pylab.imshow(img3), pylab.axis('off'), pylab.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqtYCQ_iSfgO",
        "colab_type": "text"
      },
      "source": [
        "### Haar-like feature descriptor with scikit-image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1tuviBwSfgO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage.feature import haar_like_feature_coord\n",
        "from skimage.feature import draw_haar_like_feature\n",
        "images = [np.zeros((2, 2)), np.zeros((2, 2)), np.zeros((3, 3)),\n",
        "np.zeros((3, 3)), np.zeros((2, 2))]\n",
        "feature_types = ['type-2-x', 'type-2-y', 'type-3-x', 'type-3-y', 'type-4']\n",
        "fig, axes = pylab.subplots(3, 2, figsize=(5,7))\n",
        "for axes, img, feat_t in zip(np.ravel(axes), images, feature_types):\n",
        "    coordinates, _ = haar_like_feature_coord(img.shape[0], img.shape[1], feat_t)\n",
        "    haar_feature = draw_haar_like_feature(img, 0, 0, img.shape[0],img.shape[1], coordinates, max_n_features=1, random_state=0, color_positive_block=(1.0, 0.0, 0.0), color_negative_block=(0.0, 0.0, 1.0), alpha=0.8)\n",
        "    axes.imshow(haar_feature), axes.set_title(feat_t), axes.set_axis_off()\n",
        "#fig.suptitle('Different Haar-like feature descriptors')\n",
        "pylab.axis('off'), pylab.tight_layout(), pylab.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mz8qwBeDSfgR",
        "colab_type": "text"
      },
      "source": [
        "### Face/eye detection with OpenCV using pre-trained classifiers with Haar-cascade features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cKd9qOnWxgJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://raw.githubusercontent.com/npinto/opencv/master/data/haarcascades/haarcascade_eye_tree_eyeglasses.xml\n",
        "!wget https://raw.githubusercontent.com/npinto/opencv/master/data/haarcascades/haarcascade_eye.xml\n",
        "!wget https://raw.githubusercontent.com/npinto/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMRILEf0SfgR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opencv_haar_path = '' #'C:/opencv/data/haarcascades/' # provide proper opencv installation path\n",
        "face_cascade = cv2.CascadeClassifier(opencv_haar_path + 'haarcascade_frontalface_default.xml')\n",
        "eye_cascade = cv2.CascadeClassifier(opencv_haar_path + 'haarcascade_eye.xml')\n",
        "#eye_cascade = cv2.CascadeClassifier(opencv_haar_path + 'haarcascade_eye_tree_eyeglasses.xml') # eye with glasses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lvlu9qSySfgT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "from skimage.io import imread, imshow, show\n",
        "img = cv2.imread('../images/lena.jpg')\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "faces = face_cascade.detectMultiScale(gray, 1.2, 5) # scaleFactor=1.2, minNbr=5\n",
        "print(len(faces)) # number of faces detected\n",
        "for (x,y,w,h) in faces:\n",
        "    img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
        "    roi_gray = gray[y:y+h, x:x+w]\n",
        "    roi_color = img[y:y+h, x:x+w]\n",
        "    eyes = eye_cascade.detectMultiScale(roi_gray)\n",
        "    print(eyes) # location of eyes detected\n",
        "    for (ex,ey,ew,eh) in eyes:\n",
        "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
        "        cv2.imwrite('../images/lena_face_detected.jpg', img)\n",
        "\n",
        "im = Image.open(\"../images/lena_face_detected.jpg\") # the original small clock image\n",
        "pylab.imshow(im), \n",
        "pylab.figure(figsize=(20,10))\n",
        "pylab.imshow(img), pylab.axis('off'), pylab.show()        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uf5wAe95SfgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}