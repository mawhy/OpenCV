{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "Image Enhancement",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mawhy/OpenCV/blob/master/Image_Enhancement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NP9EWCPfaXvx",
        "colab_type": "text"
      },
      "source": [
        "# Image Processing CookBook\n",
        "## Image Enhancement \n",
        "### Please run on GPU\n",
        "\n",
        "Image Enhancement, is where you will learn how to use different Python libraries\n",
        "(NumPy, SciPy, scikit-image, OpenCV, PyWavelet, and MedPy) to denoise images (using\n",
        "linear/nonlinear filters, Fast Fourier transform (FFT), and autoencoders). You'll learn how\n",
        "to implement image enhancement techniques such as histogram equalization/matching,\n",
        "sketching/cartoonizing, pyramid blending/gradient blending, and edge detection with zero\n",
        "crossing.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMKFMhBMag4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/PacktPublishing/Python-Image-Processing-Cookbook.git\n",
        "%cp -av \"/content/Python-Image-Processing-Cookbook/Chapter 02/images/\" \"/content/\"\n",
        "%cp -av \"/content/Python-Image-Processing-Cookbook/Chapter 02/models/\" \"/content/\"\n",
        "%rm -rf \"/content/Python-Image-Processing-Cookbook\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6AMUsSEaXvy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "from skimage.exposure import cumulative_distribution\n",
        "from skimage.io import imread\n",
        "from skimage.color import rgb2gray\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "\n",
        "def hist_matching(c, c_t, im):\n",
        "    b = np.interp(c, c_t, np.arange(256))   # find closest matches to b_t\n",
        "    pix_repl = {i:b[i] for i in range(256)} # dictionary to replace the pixels\n",
        "    mp = np.arange(0,256)\n",
        "    for (k, v) in pix_repl.items():\n",
        "        mp[k] = v\n",
        "    s = im.shape\n",
        "    im = np.reshape(mp[im.ravel()], im.shape)\n",
        "    im = np.reshape(im, s)\n",
        "    return im\n",
        "\n",
        "def cdf(im):\n",
        "    c, b = cumulative_distribution(im)\n",
        "    #print(b)\n",
        "    for i in range(b[0]):\n",
        "        c = np.insert(c, 0, 0)\n",
        "    for i in range(b[-1]+1, 256):\n",
        "        c = np.append(c, 1)\n",
        "    return c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxayXCjNaXv2",
        "colab_type": "text"
      },
      "source": [
        "### Histogram Matching"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-b_hHE41aXv2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "from skimage.exposure import cumulative_distribution\n",
        "from skimage.io import imread\n",
        "from skimage.color import rgb2gray\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "\n",
        "def hist_matching(c, c_t, im):\n",
        "    b = np.interp(c, c_t, np.arange(256))   # find closest matches to b_t\n",
        "    pix_repl = {i:b[i] for i in range(256)} # dictionary to replace the pixels\n",
        "    mp = np.arange(0,256)\n",
        "    for (k, v) in pix_repl.items():\n",
        "        mp[k] = v\n",
        "    s = im.shape\n",
        "    im = np.reshape(mp[im.ravel()], im.shape)\n",
        "    im = np.reshape(im, s)\n",
        "    return im\n",
        "\n",
        "def cdf(im):\n",
        "    c, b = cumulative_distribution(im)\n",
        "    #print(b)\n",
        "    for i in range(b[0]):\n",
        "        c = np.insert(c, 0, 0)\n",
        "    for i in range(b[-1]+1, 256):\n",
        "        c = np.append(c, 1)\n",
        "    return c\n",
        "\n",
        "im = imread('images/goddess.png').astype(np.uint8)\n",
        "im_t = imread('images/leaves.png')\n",
        "print(np.max(im), np.max(im_t))\n",
        "\n",
        "im1 = np.zeros(im.shape).astype(np.uint8)\n",
        "for i in range(3):\n",
        "    c = cdf(im[...,i])\n",
        "    c_t = cdf(im_t[...,i])\n",
        "    im1[...,i] = hist_matching(c, c_t, im[...,i])\n",
        "\n",
        "plt.figure(figsize=(20,17))\n",
        "plt.subplots_adjust(left=0, top=0.95, right=1, bottom=0, wspace=0.05, hspace=0.05)\n",
        "plt.subplot(221), plt.imshow(im), plt.axis('off'), plt.title('Input Image', size=25)\n",
        "plt.subplot(222), plt.imshow(im_t), plt.axis('off'), plt.title('Template Image', size=25)\n",
        "plt.subplot(223), plt.imshow(im1[...,:3]), plt.axis('off'), plt.title('Output Image', size=25)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIx_x44QaXv5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage.io import imread\n",
        "im = imread('images/rocks.png').astype(np.uint8)\n",
        "im_t = imread('images/sun.png')\n",
        "print(np.max(im), np.max(im_t))\n",
        "\n",
        "im1 = np.zeros(im.shape).astype(np.uint8)\n",
        "for i in range(3):\n",
        "    c = cdf(im[...,i])\n",
        "    c_t = cdf(im_t[...,i])\n",
        "    im1[...,i] = hist_matching(c, c_t, im[...,i])\n",
        "\n",
        "plt.figure(figsize=(20,15))\n",
        "plt.subplots_adjust(left=0, top=0.95, right=1, bottom=0, wspace=0.05, hspace=0.05)\n",
        "plt.subplot(221), plt.imshow(im), plt.axis('off'), plt.title('Input Image', size=25)\n",
        "plt.subplot(222), plt.imshow(im_t), plt.axis('off'), plt.title('Template Image', size=25)\n",
        "plt.subplot(223), plt.imshow(im1[...,:3]), plt.axis('off'), plt.title('Output Image', size=25)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoR1w0PAaXv7",
        "colab_type": "text"
      },
      "source": [
        "### Edge Detection with Canny, LOG / Zero-Crossing and Wavelets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGhMh9qx-KjG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install SimpleITK"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2B6ehhlaXv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import SimpleITK as sitk\n",
        "\n",
        "image = sitk.ReadImage('images/cameraman.png',sitk.sitkInt8) # 8-bit cameraman grayscale image\n",
        "image = sitk.Cast(image, sitk.sitkFloat64)\n",
        "\n",
        "# Compute the Canny filter for two values of sigma\n",
        "edges1 = sitk.CannyEdgeDetection(image, lowerThreshold=5, upperThreshold=10, variance=[1, 1])\n",
        "edges2 = sitk.CannyEdgeDetection(image, lowerThreshold=5, upperThreshold=10, variance=[3, 3])\n",
        "\n",
        "# Convert to numpy array for display\n",
        "image = sitk.GetArrayFromImage(image)\n",
        "edges1 = sitk.GetArrayFromImage(edges1)\n",
        "edges2 = sitk.GetArrayFromImage(edges2)\n",
        "\n",
        "# display results\n",
        "fig = plt.figure(figsize=(20, 6))\n",
        "\n",
        "plt.subplot(131), plt.imshow(image.astype(np.uint8), cmap=plt.cm.gray), plt.axis('off'), plt.title('Input image', fontsize=20)\n",
        "plt.subplot(132), plt.imshow(edges1, cmap=plt.cm.gray), plt.axis('off'), plt.title('Canny filter, $\\sigma=1$', fontsize=20)\n",
        "plt.subplot(133), plt.imshow(edges2, cmap=plt.cm.gray), plt.axis('off'), plt.title('Canny filter, $\\sigma=3$', fontsize=20)\n",
        "\n",
        "fig.tight_layout()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRm0uCh3aXv-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from scipy import ndimage, misc\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.color import rgb2gray\n",
        "\n",
        "def any_neighbor_zero(img, i, j):\n",
        "    for k in range(-1,2):\n",
        "      for l in range(-1,2):\n",
        "         if img[i+k, j+k] == 0:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def zero_crossing(img):\n",
        "  img[img > 0] = 1\n",
        "  img[img < 0] = 0\n",
        "  out_img = np.zeros(img.shape)\n",
        "  for i in range(1,img.shape[0]-1):\n",
        "    for j in range(1,img.shape[1]-1):\n",
        "      if img[i,j] > 0 and any_neighbor_zero(img, i, j):\n",
        "        out_img[i,j] = 255\n",
        "  return out_img\n",
        "\n",
        "img = rgb2gray(imread('images/tiger.png'))\n",
        "\n",
        "print(np.max(img))\n",
        "fig = plt.figure(figsize=(25,15))\n",
        "plt.gray() # show the filtered result in grayscale\n",
        "for sigma in range(2,10, 2):\n",
        "    plt.subplot(2,2,sigma/2)\n",
        "    result = ndimage.gaussian_laplace(img, sigma=sigma)\n",
        "    result = zero_crossing(result)\n",
        "    plt.imshow(result)\n",
        "    plt.axis('off')\n",
        "    plt.title('LoG with zero-crossing, sigma=' + str(sigma), size=30)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQd043GMaXwA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#% matplotlib inline\n",
        "import pywt\n",
        "from skimage.io import imread\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.filters import threshold_otsu\n",
        "import matplotlib.pylab as plt\n",
        "# Load image\n",
        "original = rgb2gray(imread('images/ed-deir.png'))\n",
        "#original = pywt.data.camera()\n",
        "# Wavelet transform of image, and plot approximation and details\n",
        "titles = ['Approximation', ' Horizontal detail', 'Vertical detail', 'Diagonal detail']\n",
        "coeffs2 = pywt.dwt2(original, 'haar')\n",
        "LL, (LH, HL, HH) = coeffs2\n",
        "fig = plt.figure(figsize=(15, 12))\n",
        "for i, a in enumerate([LL, LH, HL, HH]):\n",
        "    ax = fig.add_subplot(2, 2, i + 1)\n",
        "    a = abs(a)\n",
        "    #a = np.clip(a, 0, 1)\n",
        "    if i > 0:\n",
        "        th = threshold_otsu(a)\n",
        "        a[a > th] = 1\n",
        "        a[a <= th] = 0\n",
        "    ax.imshow(a, interpolation=\"nearest\", cmap=plt.cm.gray)\n",
        "    ax.set_title(titles[i], fontsize=20)\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0FCRptJaXwD",
        "colab_type": "text"
      },
      "source": [
        "### Edge Detection with Anisotropic Diffusion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UV5Hjvfw_sJw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install medpy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcTdz1pDaXwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from medpy.filter.smoothing import anisotropic_diffusion\n",
        "from skimage.util import random_noise\n",
        "import matplotlib.pylab as plt\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.io import imread\n",
        "import numpy as np\n",
        "\n",
        "img = rgb2gray(imread('images/colosseum.png'))\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.gray()\n",
        "plt.subplots_adjust(0,0,1,1,0.05,0.05)\n",
        "plt.subplot(121), plt.imshow(img), plt.axis('off'), plt.title('Original', size=20)\n",
        "diff_out = anisotropic_diffusion(img, niter=50, kappa=20, option=1)\n",
        "plt.subplot(122), plt.imshow(np.clip(diff_out-img,0,1)), plt.axis('off')\n",
        "plt.title(r'Edges with Anisotropic Diffusion (Perona Malik, $\\kappa=20$)', size=20)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEK8-i3_aXwG",
        "colab_type": "text"
      },
      "source": [
        "### Image Denoising with Denoising Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUqZy0QfaXwH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install torch===1.4.0 torchvision===0.5.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "! pip install torch\n",
        "! pip install torchviz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCQAys1DaXwJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision, matplotlib, sklearn, numpy as np\n",
        "print(np.__version__, torch.__version__, matplotlib.__version__, sklearn.__version__) #torchvision.__version__, "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7Cu9EWpXkoX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "#! pip install torchviz\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image\n",
        "from torchviz import make_dot\n",
        "\n",
        "from sklearn.datasets import fetch_lfw_people\n",
        "\n",
        "print(torch.cuda.current_device())\n",
        "print(torch.cuda.device(0))\n",
        "print(torch.cuda.device_count())\n",
        "print(torch.cuda.get_device_name(0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XSwedonaXwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "#! pip install torchviz\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image\n",
        "from torchviz import make_dot\n",
        "\n",
        "from sklearn.datasets import fetch_lfw_people\n",
        "\n",
        "print(torch.cuda.current_device())\n",
        "print(torch.cuda.device(0))\n",
        "print(torch.cuda.device_count())\n",
        "print(torch.cuda.get_device_name(0))\n",
        "\n",
        "def to_img(x):\n",
        "    x = x.view(x.size(0), 1, 50, 37)\n",
        "    return x\n",
        "\n",
        "num_epochs = 100 #100\n",
        "batch_size = 8 # 16\n",
        "learning_rate = 1e-3\n",
        "cuda = True \n",
        "\n",
        "\n",
        "def add_noise(img):\n",
        "    noise = torch.randn(img.size()) * 0.2\n",
        "    noisy_img = img + noise\n",
        "    return noisy_img\n",
        "\n",
        "\n",
        "def plot_sample_img(img, name):\n",
        "    img = img.view(1, 50, 37)\n",
        "    save_image(img, './sample_{}.png'.format(name))\n",
        "\n",
        "\n",
        "def min_max_normalization(tensor, min_value, max_value):\n",
        "    min_tensor = tensor.min()\n",
        "    tensor = (tensor - min_tensor)\n",
        "    max_tensor = tensor.max()\n",
        "    tensor = tensor / max_tensor\n",
        "    tensor = tensor * (max_value - min_value) + min_value\n",
        "    return tensor\n",
        "\n",
        "\n",
        "def tensor_round(tensor):\n",
        "    return torch.round(tensor)\n",
        "\n",
        "\n",
        "img_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda tensor:min_max_normalization(tensor, 0, 1)),\n",
        "    transforms.Lambda(lambda tensor:tensor_round(tensor))\n",
        "])\n",
        "\n",
        "dataset = fetch_lfw_people(min_faces_per_person=70, resize=0.4).images / 255\n",
        "print(dataset.shape)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "class autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(50 * 37, 512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(True))\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(128, 512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(512, 50 * 37),\n",
        "            nn.Sigmoid())\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "model = autoencoder()\n",
        "if cuda:\n",
        "    model = model.cuda()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(\n",
        "    model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    for data in dataloader:\n",
        "        img = data\n",
        "        img = img.view(img.size(0), -1)\n",
        "        noisy_img = add_noise(img)\n",
        "        noisy_img = Variable(noisy_img)\n",
        "        if cuda:\n",
        "            noisy_img = noisy_img.cuda()\n",
        "        img = Variable(img)\n",
        "        if cuda:\n",
        "            img = img.cuda()\n",
        "        # ===================forward=====================\n",
        "        output = model(noisy_img)\n",
        "        loss = criterion(output, img)\n",
        "        MSE_loss = nn.MSELoss()(output, img)\n",
        "        # ===================backward====================\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    # ===================log========================\n",
        "    print('epoch [{}/{}], loss:{:.4f}, MSE_loss:{:.4f}'\n",
        "          .format(epoch, num_epochs, loss.data.item(), MSE_loss.data.item()))\n",
        "    if epoch % 10 == 0:\n",
        "        x = to_img(img.cpu().data)\n",
        "        x_hat = to_img(output.cpu().data)\n",
        "        x_noisy = to_img(noisy_img.cpu().data)\n",
        "        weights = to_img(model.encoder[0].weight.cpu().data)\n",
        "        plt.figure(figsize=(20,20))\n",
        "        plt.gray()\n",
        "        for i in range(8):\n",
        "            plt.subplot(8,8,i+1), plt.imshow(x.data.numpy()[i,0,...]), plt.axis('off')\n",
        "        for i in range(8):\n",
        "            plt.subplot(8,8,i+9), plt.imshow(x_noisy.data.numpy()[i,0,...]), plt.axis('off')\n",
        "        for i in range(8):\n",
        "            plt.subplot(8,8,i+17), plt.imshow(x_hat.data.numpy()[i,0,...]), plt.axis('off')\n",
        "        indices = np.random.choice(512, 40)\n",
        "        for i in range(40):\n",
        "            plt.subplot(8,8,i+25), plt.imshow(weights.data.numpy()[indices[i],0,...]), plt.axis('off')\n",
        "        plt.suptitle('Original (Row 1), Noisy input (Row 2), DAE output (Row 3) images \\n and some features (Rows 4-8) learnt by the DAE in Epoch {}'.format(epoch), size=30)\n",
        "        plt.show()\n",
        "        print(weights.shape)\n",
        "\n",
        "torch.save(model.state_dict(), 'sim_dautoencoder.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOTmjTflaXwN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0efvYNU0aXwQ",
        "colab_type": "text"
      },
      "source": [
        "### Image Denoising with Principal Component Analysis (PCA), Discrete Fourier / Wavelet Tranform (FFT, DWT)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxcgEpb1aXwQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from numpy.random import RandomState\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_olivetti_faces\n",
        "from sklearn import decomposition\n",
        "from skimage.util import random_noise\n",
        "from skimage import img_as_float\n",
        "from time import time\n",
        "import scipy.fftpack as fp\n",
        "import pywt\n",
        "\n",
        "n_components = 50 # 256\n",
        "image_shape = (64, 64)\n",
        "rng = RandomState(0)\n",
        "\n",
        "dataset = fetch_olivetti_faces(shuffle=True, random_state=rng)\n",
        "original = img_as_float(dataset.data)\n",
        "faces = original.copy()\n",
        "print(faces.shape)\n",
        "\n",
        "n_samples, n_features = faces.shape\n",
        "#mean_face = faces.mean(axis=0)\n",
        "#faces = faces - mean_face\n",
        "faces = random_noise(faces, var=0.005)\n",
        "\n",
        "estimator = decomposition.PCA(n_components=n_components, svd_solver='randomized', whiten=True)\n",
        "print(\"Extracting the top %d PCs...\" % (n_components))\n",
        "t0 = time()\n",
        "faces_recons = estimator.inverse_transform(estimator.fit_transform(faces)) #.T #+ mean_face #.T\n",
        "train_time = (time() - t0)\n",
        "print(\"done in %0.3fs\" % train_time)\n",
        "\n",
        "indices = np.random.choice(n_samples, 5, replace=False)\n",
        "plt.figure(figsize=(20,4))\n",
        "for i in range(len(indices)):\n",
        "    plt.subplot(1,5,i+1), plt.imshow(np.reshape(original[indices[i],:], image_shape)), plt.axis('off')\n",
        "plt.suptitle('Original', size=25)\n",
        "plt.show()\n",
        "\n",
        "#faces = faces + mean_face\n",
        "plt.figure(figsize=(20,4))\n",
        "for i in range(len(indices)):\n",
        "    plt.subplot(1,5,i+1), plt.imshow(np.reshape(faces[indices[i],:], image_shape)), plt.axis('off')\n",
        "plt.suptitle('Noisy', size=25)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(20,4))\n",
        "for i in range(len(indices)):\n",
        "    plt.subplot(1,5,i+1), plt.imshow(np.reshape(faces_recons[indices[i],:], image_shape)), plt.axis('off')\n",
        "plt.suptitle('PCA reconstruction with {} components (eigenfaces)'.format(n_components), size=25)\n",
        "plt.show()\n",
        "\n",
        "n_components = 30 \n",
        "plt.figure(figsize=(20,4))\n",
        "for i in range(len(indices)):\n",
        "    freq = fp.fftshift(fp.fft2((np.reshape(faces[indices[i],:], image_shape)).astype(float)))\n",
        "    freq[:freq.shape[0]//2 - n_components//2,:] = freq[freq.shape[0]//2 + n_components//2:,:] = 0\n",
        "    freq[:, :freq.shape[1]//2 - n_components//2] = freq[:, freq.shape[1]//2 + n_components//2:] = 0\n",
        "    plt.subplot(1,5,i+1), plt.imshow(fp.ifft2(fp.ifftshift(freq)).real), plt.axis('off')\n",
        "plt.suptitle('FFT LPF reconstruction with {} basis vectors'.format(n_components), size=25)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(20,4))\n",
        "wavelet = pywt.Wavelet('haar')\n",
        "for i in range(len(indices)):\n",
        "    wavelet_coeffs = pywt.wavedec2((np.reshape(faces[indices[i],:], image_shape)).astype(float), wavelet)\n",
        "    plt.subplot(1,5,i+1), plt.imshow(pywt.waverec2(wavelet_coeffs[:-1], wavelet)), plt.axis('off')\n",
        "plt.suptitle('Wavelet reconstruction with {} subbands'.format(len(wavelet_coeffs)-1), size=25)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLLKBGscaXwS",
        "colab_type": "text"
      },
      "source": [
        "### Gradient Blending"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7fASPvyaXwT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "print(cv2.__version__) # make sure the major version of OpenCV is 3\n",
        "# 3.4.2\n",
        "import numpy as np\n",
        "# read source and destination images\n",
        "src = cv2.imread(\"images/liberty.png\")\n",
        "dst = cv2.imread(\"images/victoria.png\")\n",
        "# read the mask image\n",
        "src_mask = cv2.imread(\"images/cmask.png\")\n",
        "print(src.shape, dst.shape, src_mask.shape)\n",
        "# (480, 360, 3) (576, 768, 3) (480, 360, 3)\n",
        "# this is where the CENTER of the airplane will be placed\n",
        "center = (275,250) \n",
        "# clone seamlessly.\n",
        "output = cv2.seamlessClone(src, dst, src_mask, center, cv2.MIXED_CLONE)\n",
        "# save result\n",
        "cv2.imwrite(\"images/liberty_victoria.png\", output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTYBl2RtaXwV",
        "colab_type": "text"
      },
      "source": [
        "![](images/gradient_out.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "e_5p8OeAaXwW",
        "colab_type": "text"
      },
      "source": [
        "### Improving Image Contrast"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ke1yUUPNaXwW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "from skimage.io import imread\n",
        "from skimage.exposure import equalize_hist, equalize_adapthist\n",
        "\n",
        "def plot_image(image, title):\n",
        "    plt.imshow(image)\n",
        "    plt.title(title, size=20)\n",
        "    plt.axis('off')\n",
        "    \n",
        "def plot_hist(img):\n",
        "    colors = ['r', 'g', 'b']\n",
        "    cdf = np.zeros((256,3))\n",
        "    for i in range(3):\n",
        "        hist, bins = np.histogram(img[...,i].flatten(),256,[0,256], density=True)\n",
        "        cdf[...,i] = hist.cumsum()\n",
        "        cdf_normalized = cdf[...,i] * hist.max() / cdf.max()\n",
        "        plt.plot(cdf_normalized, color = colors[i], label='cdf ({})'.format(colors[i]))\n",
        "        #plt.hist(img[...,i].flatten(),256,[0,256], color = colors[i], density=True)\n",
        "        binWidth = bins[1] - bins[0]\n",
        "        plt.bar(bins[:-1], hist*binWidth, binWidth, label='hist ({})'.format(colors[i]))\n",
        "        plt.xlim([0,256])\n",
        "    plt.legend(loc = 'upper left')\n",
        "    return cdf\n",
        "\n",
        "img = imread('images/train.png')\n",
        "#print(np.max(img))\n",
        "\n",
        "plt.figure(figsize=(20,40))\n",
        "#plt.gray()\n",
        "\n",
        "plt.subplot(421), plot_image(img, 'Original Image')\n",
        "plt.subplot(422) \n",
        "cdf = plot_hist(img)\n",
        "\n",
        "img2 = np.copy(img)\n",
        "for i in range(3):\n",
        "    cdf_m = np.ma.masked_equal(cdf[...,i],0)\n",
        "    cdf_m = (cdf_m - cdf_m.min())*255/(cdf_m.max()-cdf_m.min())\n",
        "    #cdf_m = 255 * cdf / cdf[-1] # normalize\n",
        "    cdf2 = np.ma.filled(cdf_m,0).astype('uint8')\n",
        "    img2[...,i] = cdf2[img[...,i]]\n",
        "\n",
        "plt.subplot(423), plot_image(img2, 'Hist. Equalized')\n",
        "plt.subplot(424), plot_hist(img2)\n",
        "\n",
        "equ = (255*equalize_hist(img)).astype(np.uint8)\n",
        "plt.subplot(425), plot_image(equ, 'Hist. Equalized (scikit-image)')\n",
        "plt.subplot(426), plot_hist(equ)\n",
        "\n",
        "\n",
        "equ = (255*equalize_adapthist(img)).astype(np.uint8)\n",
        "plt.subplot(427), plot_image(equ, 'Adaptive Hist. Equalized (scikit-image)')\n",
        "plt.subplot(428), plot_hist(equ)\n",
        "\n",
        "plt.savefig('images/hist_out.png', bbox_in='tight', pad_in=0)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sdae5p2waXwY",
        "colab_type": "text"
      },
      "source": [
        "### Image Denoising with Anisotropic Diffusion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJA9qANWaXwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from medpy.filter.smoothing import anisotropic_diffusion\n",
        "from skimage.util import random_noise\n",
        "import matplotlib.pylab as plt\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.io import imread\n",
        "import numpy as np\n",
        "\n",
        "img = rgb2gray(imread('images/cameraman.png'))\n",
        "noisy = random_noise(img, var=0.01)\n",
        "noisy = np.clip(noisy, 0, 1)\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.gray()\n",
        "plt.subplots_adjust(0,0,1,1,0.05,0.05)\n",
        "plt.subplot(221), plt.imshow(img), plt.axis('off'), plt.title('Original', size=20)\n",
        "plt.subplot(222), plt.imshow(noisy), plt.axis('off'), plt.title('Noisy', size=20)\n",
        "diff_out = anisotropic_diffusion(noisy, niter=20, kappa=20, option=1)\n",
        "plt.subplot(223), plt.imshow(diff_out), plt.axis('off'), plt.title(r'Anisotropic Diffusion (Perona Malik eq 1, iter=20, $\\kappa=20$)', size=18)\n",
        "diff_out = anisotropic_diffusion(noisy, niter=50, kappa=100, option=2)\n",
        "plt.subplot(224), plt.imshow(diff_out), plt.axis('off'), plt.title(r'Anisotropic Diffusion (Perona Malik eq 2, iter=50, $\\kappa=50$)', size=18)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1Ot5v5taXwc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}