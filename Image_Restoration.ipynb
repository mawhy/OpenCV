{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Image Restoration",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mawhy/OpenCV/blob/master/Image_Restoration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Rel8AHnmEfB",
        "colab_type": "text"
      },
      "source": [
        "# Image Processing CookBook\n",
        "## Image Restoration\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVq7rjbTPXOJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/PacktPublishing/Python-Image-Processing-Cookbook.git\n",
        "%cp -av \"/content/Python-Image-Processing-Cookbook/Chapter 03/images/\" \"/content/\"\n",
        "%cp -av \"/content/Python-Image-Processing-Cookbook/Chapter 03/models/\" \"/content/\"\n",
        "%rm -rf \"/content/Python-Image-Processing-Cookbook\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2cANgyzmEfC",
        "colab_type": "text"
      },
      "source": [
        "### Wiener Filter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OD8FTRv9mEfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "from skimage import color, data, restoration\n",
        "import scipy.fftpack as fp\n",
        "from skimage.measure import compare_psnr\n",
        "from skimage.io import imread\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
        "\n",
        "def convolve2d(im, psf, k):\n",
        "    M, N = im.shape\n",
        "    freq = fp.fft2(im)\n",
        "    psf = np.pad(psf, (((M-k)//2,(M-k)//2+1), ((N-k)//2,(N-k)//2+1)), mode='constant') # assumption: min(M,N) > k > 0, k odd\n",
        "    freq_kernel = fp.fft2(fp.ifftshift(psf))\n",
        "    return np.abs(fp.ifft2(freq*freq_kernel))\n",
        "\n",
        "def plot_freq_filter(F, title, size=20):\n",
        "    plt.imshow(20*np.log10( 0.01 + np.abs(fp.fftshift(F))), cmap='coolwarm'), plt.title(title, size=size), plt.colorbar()\n",
        "\n",
        "def plot_freq_spec_3d(freq):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.gca(projection='3d')\n",
        "    Y = np.arange(-freq.shape[0]//2,freq.shape[0]-freq.shape[0]//2)\n",
        "    X = np.arange(-freq.shape[1]//2,freq.shape[1]-freq.shape[1]//2)\n",
        "    X, Y = np.meshgrid(X, Y)\n",
        "    Z = (20*np.log10( 0.01 + fp.fftshift(freq))).real\n",
        "    surf = ax.plot_surface(X, Y, Z, cmap=plt.cm.coolwarm,\n",
        "                           linewidth=0, antialiased=True)\n",
        "    ax.zaxis.set_major_locator(LinearLocator(10))\n",
        "    ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
        "    plt.show()\n",
        "\n",
        "im = color.rgb2gray(imread('images/earth_from_sky.png'))\n",
        "k = 5\n",
        "psf = np.ones((k, k)) / k**2\n",
        "im1 = convolve2d(im, psf, k)\n",
        "im1 += 0.3 * im.std() * np.random.standard_normal(im.shape)\n",
        "im2, _ = restoration.unsupervised_wiener(im1, psf)\n",
        "im3 = restoration.wiener(im1, psf, balance=0.25)\n",
        "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(20, 12), sharex=True, sharey=True)\n",
        "plt.gray()\n",
        "axes[0,0].imshow(im), axes[0,0].axis('off'), axes[0,0].set_title('Original image', size=20)\n",
        "axes[0,1].imshow(im1), axes[0,1].axis('off'), axes[0,1].set_title('Noisy blurred image: PSNR={:.3f}'.format(compare_psnr(im, im1)), size=20)\n",
        "axes[1,0].imshow(im2), axes[1,0].axis('off'), axes[1,0].set_title('Self tuned Wiener restoration: PSNR={:.3f}'.format(compare_psnr(im, im2)), size=20)\n",
        "axes[1,1].imshow(im2), axes[1,1].axis('off'), axes[1,1].set_title('Wiener restoration: PSNR={:.3f}'.format(compare_psnr(im, im3)), size=20)\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ad-g_vYomEfH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_freq_spec_3d(fp.fft2(im))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I71GxiA_mEfK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_freq_spec_3d(fp.fft2(im1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BHPcBeBmEfN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_freq_spec_3d(fp.fft2(im2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmfqxOrJmEfP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_freq_spec_3d(fp.fft2(im3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijSeWrncmEfS",
        "colab_type": "text"
      },
      "source": [
        "### Constrained Least Squares (CLS) Filter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmEIiKtHmEfS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import scipy.fftpack as fp\n",
        "from skimage.io import imread\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.restoration import wiener, unsupervised_wiener\n",
        "from skimage.measure import compare_psnr\n",
        "import matplotlib.pylab as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib.ticker import FormatStrFormatter\n",
        "\n",
        "def pseudo_inverse_filter(y, h, epsilon):\n",
        "    '''\n",
        "    Hinv(u,v) = 1/H(u,v)   if |H(u,v)| > epsilon\n",
        "                0          otherwise\n",
        "    '''\n",
        "    Hf = fp.fft2(fp.ifftshift(h))\n",
        "    M, N = Hf.shape\n",
        "    Hf[(np.abs(Hf)<epsilon)] = 0\n",
        "    indices = np.where((np.abs(Hf)>=epsilon))\n",
        "    Hf[indices] = np.ones((M,N))[indices] / Hf[indices]\n",
        "    Yf = fp.fft2(y)\n",
        "    I = Yf*Hf \n",
        "    im = np.abs(fp.ifft2(I))\n",
        "    return (im, Hf)\n",
        "\n",
        "def cls_filter(y,h,c,lambd):\n",
        "    Hf = fp.fft2(fp.ifftshift(h))\n",
        "    Cf = fp.fft2(fp.ifftshift(c))\n",
        "    Hf = np.conj(Hf) / (Hf*np.conj(Hf) + lambd*Cf*np.conj(Cf))\n",
        "    #Hf = np.abs(Hf)**2 / (np.abs(Hf)**2 + lambd*np.abs(Cf)**2)\n",
        "    Yf = fp.fft2(y)\n",
        "    I = Yf*Hf \n",
        "    im = np.abs(fp.ifft2(I))\n",
        "    return (im, Hf) \n",
        "\n",
        "# Input and display the binary image\n",
        "x = rgb2gray(imread('images/building.png'))\n",
        "print(x.shape)\n",
        "M, N = x.shape\n",
        "print(np.max(x))\n",
        "\n",
        "plt.figure(figsize=(15,30))\n",
        "\n",
        "plt.subplot(431), plt.imshow(x, cmap='gray'), plt.axis('off'), plt.title('Original', size=15)\n",
        "\n",
        "# Blur the image, corrupt the image using WGN and display it\n",
        "# h is the blurring filter, and sigma is the noise std\n",
        "h = np.ones((4,4))/16\n",
        "h = np.pad(h, [(M//2-2, M//2-2), (N//2-2, N//2-2)], mode='constant')\n",
        "sigma = 0.075\n",
        "Xf = fp.fft2(x)\n",
        "Hf = fp.fft2(fp.ifftshift(h))\n",
        "\n",
        "plt.subplot(432), plt.imshow(20*np.log10( 0.01 + np.abs(fp.fftshift(Hf))), cmap='coolwarm'), plt.title('Blur Kernel (FFT)', size=15), plt.colorbar()\n",
        "\n",
        "Y = Hf*Xf\n",
        "y = fp.ifft2(Y).real + sigma*np.random.normal(size=(M,N))\n",
        "\n",
        "plt.subplot(433), plt.imshow(np.abs(y), cmap='gray'), plt.axis('off'), plt.title('Degraded (PSNR: {})'.format(np.round(compare_psnr(x, y),3)), size=15)\n",
        "\n",
        "# restoration using inverse filtering\n",
        "epsilon = 0.25\n",
        "pix, F_pseudo = pseudo_inverse_filter(y, h, epsilon)\n",
        "plt.subplot(434), plt.imshow(pix, cmap='gray'), plt.axis('off'), plt.title('Restored (Pseudo-Inverse)\\nPSNR: {}'.format(np.round(compare_psnr(x, pix),3)), size=15)\n",
        "plt.subplot(435), plot_freq_filter(F_pseudo, 'Pseudo-Inverse Kernel (FFT)', size=15)\n",
        "\n",
        "# restoration using wiener filtering\n",
        "wx = wiener(y, h, balance=0.25)\n",
        "plt.subplot(436), plt.imshow(wx, cmap='gray'), plt.axis('off'), plt.title('Restored (Wiener)\\nPSNR: {}'.format(np.round(compare_psnr(x, wx),3)), size=15)\n",
        "\n",
        "# restoration using unsupervised wiener filtering\n",
        "uwx, _ = unsupervised_wiener(y, h)\n",
        "plt.subplot(437), plt.imshow(uwx, cmap='gray'), plt.axis('off'), plt.title('Restored (Unsup.Wiener)\\nPSNR: {}'.format(np.round(compare_psnr(x, uwx),3)), size=15)\n",
        "\n",
        "# restoration using cls filtering\n",
        "c =  np.array([[0,1/4,0],[1/4,-1,1/4],[0,1/4,0]])\n",
        "c = np.pad(c, [(M//2-1, M//2-2), (N//2-2, N//2-1)], mode='constant')\n",
        "Cf = fp.fft2(fp.ifftshift(c))\n",
        "plt.subplot(438), plt.imshow(20*np.log10( 0.01 + np.abs(fp.fftshift(Cf))), cmap='coolwarm'), plt.title('CLS Constraint Kernel (FFT)', size=15), plt.colorbar()\n",
        "lambd = 20\n",
        "clx, F_restored = cls_filter(y, h, c, lambd)\n",
        "plt.subplot(439), plt.imshow(clx, cmap='gray'), plt.axis('off'), plt.title(r'Restored (CLS, $\\lambda=${}) PSNR: {}'.format(lambd, np.round(compare_psnr(x, clx),3)), size=13)\n",
        "plt.subplot(4,3,10), plot_freq_filter(F_restored, r'CLS Kernel (FFT), $\\lambda=${}'.format(lambd), size=15)\n",
        "lambd = 2\n",
        "clx, F_restored = cls_filter(y, h, c, lambd)\n",
        "plt.subplot(4,3,11), plt.imshow(clx, cmap='gray'), plt.axis('off'), plt.title(r'Restored (CLS, $\\lambda=${}) PSNR: {}'.format(lambd, np.round(compare_psnr(x, clx),3)), size=13)\n",
        "plt.subplot(4,3,12), plot_freq_filter(F_restored, r'CLS Kernel (FFT), $\\lambda=${}'.format(lambd), size=15)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjklVwnSmEfV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#freq_kernel = np.conj(Hf) / (Hf*np.conj(Hf) + alpha*Cf*np.conj(Cf))      \n",
        "plot_freq_spec_3d(F_restored)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6yBqEY7mEfY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_freq_spec_3d(fp.fft2(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4p0sp0nmEfa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_freq_spec_3d(fp.fft2(y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO_JTjhmmEfd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_freq_spec_3d(fp.fft2(clx))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Avif6k9ymEff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_freq_spec_3d(fp.fft2(uwx))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spcIKmU2mEfi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage.util import random_noise\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.io import imread\n",
        "im = rgb2gray(imread('images/book.png')) # street\n",
        "(M, N), k = im.shape, 81 # a 21 x 21 motion blurred kernel\n",
        "kernel = np.zeros((k, k))\n",
        "for i in range(k):\n",
        "    kernel[i, i] = 1\n",
        "kernel = kernel / k\n",
        "#print(kernel)\n",
        "print(im.shape, kernel.shape)\n",
        "im_blur = convolve2d(im, kernel, k) #, mode='same')\n",
        "im_blur = random_noise(im_blur, var=0.0025)\n",
        "\n",
        "from skimage.restoration import wiener, unsupervised_wiener\n",
        "\n",
        "def cls_filter(y,h,c,lambd):\n",
        "    Hf = fp.fft2(fp.ifftshift(h))\n",
        "    Cf = fp.fft2(fp.ifftshift(c))\n",
        "    Hf = np.conj(Hf) / (Hf*np.conj(Hf) + lambd*Cf*np.conj(Cf))\n",
        "    #Hf = np.abs(Hf)**2 / (np.abs(Hf)**2 + lambd*np.abs(Cf)**2)\n",
        "    Yf = fp.fft2(y)\n",
        "    I = Yf*Hf \n",
        "    im = np.abs(fp.ifft2(I))\n",
        "    return (im, Hf) \n",
        "\n",
        "x = im\n",
        "y = im_blur\n",
        "h = kernel\n",
        "\n",
        "h = np.pad(h, [(M//2-k//2, M//2-k//2-1), (N//2-k//2, N//2-k//2-1)], mode='constant')\n",
        "\n",
        "# restoration using wiener filtering\n",
        "wx = wiener(y, h, balance=0.1)\n",
        "# restoration using cls filtering\n",
        "c =  np.array([[0,1/4,0],[1/4,-1,1/4],[0,1/4,0]])\n",
        "c = np.pad(c, [(M//2-1, M//2-2), (N//2-2, N//2-1)], mode='constant')\n",
        "Cf = fp.fft2(fp.ifftshift(c))\n",
        "lambd = 7.5\n",
        "clx, F_restored = cls_filter(y, h, c, lambd)\n",
        "\n",
        "plt.figure(figsize=(15,20))\n",
        "plt.gray()\n",
        "plt.subplots_adjust(0,0,1,1,0.02,0.04)\n",
        "plt.subplot(221), plt.imshow(im), plt.axis('off'), plt.title('Original Image', size=20)\n",
        "plt.subplot(222), plt.imshow(im_blur), plt.axis('off'), plt.title('Degraded Image (with Motion-blur + Noise)\\nPSNR: {}'.format(np.round(compare_psnr(x, y),3)), size=20)\n",
        "plt.subplot(223), plt.imshow(wx), plt.axis('off'), plt.title('Restored Image (with Wiener) PSNR: {}'.format(np.round(compare_psnr(x, wx),3)), size=20)\n",
        "plt.subplot(224), plt.imshow(clx), plt.axis('off'), plt.title(r'Restored Image (with CLS, $\\lambda=${}) PSNR: {}'.format(lambd, np.round(compare_psnr(x, clx),3)), size=20)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "jZalOoDqmEfk",
        "colab_type": "text"
      },
      "source": [
        "### Noisy Image Restoration with Markov Random Field"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e633In5xmEfk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "% matplotlib inline\n",
        "import numpy as np\n",
        "from skimage.color import rgb2gray\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "def plot_image(im, title):\n",
        "  im = im.copy()\n",
        "  im[im==-1] = 0\n",
        "  im[im==1] = 255\n",
        "  plt.imshow(im), plt.axis('off'), plt.title(title, size=20)\n",
        "\n",
        "def plot_error(iters, errors):\n",
        "    plt.figure(figsize=(5,5))\n",
        "    plt.plot(iters, errors, 'r.-')\n",
        "    plt.xlabel('Iterations', size=20)\n",
        "    plt.ylabel('% of Mismatch pixels', size=20)\n",
        "    plt.title('% Mismatch of Original and Denoised Image', size=20)\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "def plot_images(orig_image, noisy_image, denoised_image):\n",
        "    plt.figure(figsize=(15,5))\n",
        "    plt.gray()\n",
        "    plt.subplot(131), plot_image(orig_image, 'original image')\n",
        "    plt.subplot(132), plot_image(noisy_image, 'noisy image')\n",
        "    plt.subplot(133), plot_image(denoised_image, 'denoised image with MRF')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "# preprocessing step\n",
        "def read_image_and_binarize(image_file, threshold=128):\n",
        "  im = (255*rgb2gray(plt.imread(image_file))).astype(int)\n",
        "  im[im < threshold] = -1\n",
        "  im[im >= threshold] = 1\n",
        "  return im\n",
        "\n",
        "def add_noise(im):\n",
        "  im_noisy = im.copy()\n",
        "  for i in range(im_noisy.shape[0]):\n",
        "    for j in range(im_noisy.shape[1]):\n",
        "      r = np.random.rand()\n",
        "      if r < 0.1:\n",
        "        im_noisy[i][j] = -im_noisy[i][j]\n",
        "  return im_noisy\n",
        "\n",
        "def compute_energy_helper(Y, i, j):\n",
        "  try:\n",
        "    return Y[i][j]\n",
        "  except IndexError:\n",
        "    return 0\n",
        "\n",
        "def compute_energy(X, Y, i, j, zeta, eta, Y_i_j):\n",
        "  energy = -eta * X[i][j] * Y_i_j #np.sum(X*Y) #\n",
        "  for (k, l) in [(-1,0),(1,0),(0,-1),(0,1)]:\n",
        "      energy -= zeta * Y_i_j * compute_energy_helper(Y, i+k, j+l)\n",
        "  return energy\n",
        "\n",
        "def denoise_image(O, X, zeta, eta):\n",
        "  m, n = np.shape(X)\n",
        "  Y = np.copy(X)\n",
        "  max_iter = 10*m*n\n",
        "  iters = []\n",
        "  errors = []\n",
        "  for iter in range(max_iter):\n",
        "    # randomly pick a location\n",
        "    i = np.random.randint(m)\n",
        "    j = np.random.randint(n)\n",
        "    # compute energies for Y_ij = +1 and -1\n",
        "    energy_neg = compute_energy(X, Y, i, j, zeta, eta, -1)\n",
        "    energy_pos = compute_energy(X, Y, i, j, zeta, eta, 1)\n",
        "    # assign Y_ij to the value with min energy\n",
        "    if energy_neg < energy_pos:\n",
        "      Y[i][j] = -1\n",
        "    else:\n",
        "      Y[i][j] = 1\n",
        "    if iter % 100000 == 0:\n",
        "        print ('Completed', iter, 'iterations out of', max_iter)\n",
        "        error = get_mismatched_percentage(O, Y)\n",
        "        iters.append(iter)\n",
        "        errors.append(error)\n",
        "  plot_error(iters, errors)\n",
        "  \n",
        "  return Y\n",
        "\n",
        "def get_mismatched_percentage(orig_image, denoised_image):\n",
        "  diff = (orig_image != denoised_image)\n",
        "  return (100.0 * np.sum(diff)) / np.size(orig_image)\n",
        "\n",
        "orig_image = read_image_and_binarize('images/cameraman.png')\n",
        "zeta = 1.5\n",
        "eta = 2\n",
        "\n",
        "# add noise\n",
        "noisy_image = add_noise(orig_image)\n",
        "\n",
        "# use ICM for denoising\n",
        "denoised_image = denoise_image(orig_image, noisy_image, zeta, eta)\n",
        "\n",
        "# print the percentage of mismatched pixels\n",
        "print ('Percentage of mismatched pixels: ', get_mismatched_percentage(orig_image, denoised_image))\n",
        "\n",
        "plot_images(orig_image, noisy_image, denoised_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nKTw0jfmEfn",
        "colab_type": "text"
      },
      "source": [
        "### Image Inpainting with opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RA8NgMl0mEfn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pylab as plt\n",
        "im = cv2.imread('images/cat.png') #, cv2.CV_8U\n",
        "mask = cv2.imread('images/cat_mask.png',0)\n",
        "_, mask = cv2.threshold(mask, 100, 255, cv2.THRESH_BINARY)\n",
        "src = cv2.bitwise_and(im, im, mask= mask)\n",
        "#print(mask.shape, im.shape)\n",
        "mask = cv2.bitwise_not(mask)\n",
        "dst1 = cv2.inpaint(src, mask, 5, cv2.INPAINT_NS)\n",
        "dst2 = cv2.inpaint(src, mask, 5, cv2.INPAINT_TELEA)\n",
        "plt.figure(figsize=(20,15))\n",
        "plt.gray()\n",
        "plt.subplot(231), plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB)), plt.axis('off'), plt.title('Original', size=20)\n",
        "plt.subplot(232), plt.imshow(mask), plt.axis('off'), plt.title('Mask', size=20)\n",
        "plt.subplot(233), plt.imshow(cv2.cvtColor(src, cv2.COLOR_BGR2RGB)), plt.axis('off'), plt.title('Tampered', size=20)\n",
        "plt.subplot(234), plt.imshow(cv2.cvtColor(dst1, cv2.COLOR_BGR2RGB)), plt.axis('off'), plt.title('Inpainted (NS)', size=20)\n",
        "plt.subplot(235), plt.imshow(cv2.cvtColor(dst2, cv2.COLOR_BGR2RGB)), plt.axis('off'), plt.title('Inpainted (TELEA)', size=20)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQdIpqEdmEfq",
        "colab_type": "text"
      },
      "source": [
        "### Image Inpainting with Convex Optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEmQf37p-rfp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pyunlocbox"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9OQmBjWmEfq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://www.cvxpy.org/examples/applications/tv_inpainting.html\n",
        "#https://pyunlocbox.readthedocs.io/en/stable/tutorials/reconstruction.html\n",
        "from skimage.io import imread\n",
        "from skimage.color import rgb2gray\n",
        "from pyunlocbox import functions, solvers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "im_original = rgb2gray(imread('images/cat.png'))\n",
        "np.random.seed(1)  # Reproducible results.\n",
        "mask = np.random.uniform(size=im_original.shape)\n",
        "mask = mask > 0.8\n",
        "g = lambda x: mask * x\n",
        "im_corrupted = g(im_original)\n",
        "\n",
        "f1 = functions.norm_tv(maxit=50, dim=2)\n",
        "tau = 100\n",
        "f2 = functions.norm_l2(y=im_corrupted, A=g, lambda_=tau) \n",
        "solver = solvers.forward_backward(step=0.5/tau)\n",
        "x0 = np.array(im_corrupted)  # Make a copy to preserve im_corrupted.\n",
        "ret = solvers.solve([f1, f2], x0, solver, maxit=100)\n",
        "\n",
        "fig, ax = plt.subplots(1, 3, figsize=(20, 10))\n",
        "ax[0].imshow(im_original, cmap='gray')\n",
        "ax[0].set_title(\"Original Image\", size=20)\n",
        "ax[0].axis('off')\n",
        "ax[1].imshow(im_corrupted, cmap='gray')\n",
        "ax[1].set_title(\"Corrupted Image (with 80% noise)\", size=20)\n",
        "ax[1].axis('off')\n",
        "ax[2].imshow(ret['sol'], cmap='gray')\n",
        "ax[2].set_title(\"Reconstructed Image\", size=20)\n",
        "ax[2].axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "uTN21Q7ymEfs",
        "colab_type": "text"
      },
      "source": [
        "### Image Completion with Inpainting (using Deep learning - pre-trained torch CompletionNet model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pB_-InuKx3QJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://hi.cs.waseda.ac.jp/~iizuka/data/completionnet_places2.t7"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_9QKI4dyd4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install torch==0.4.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAlru6RDy_8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install torchvision==0.4.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yJFjgaWmEft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://github.com/akmtn/pytorch-siggraph2017-inpainting\n",
        "\n",
        "# must be run with pytorch version 0.4.1\n",
        "# download the wheels from here: https://download.pytorch.org/whl/cpu/torch_stable.html\n",
        "# pip install torch-0.4.1-cp37-cp37m-win_amd64.whl # --force-reinstall\n",
        "# pip install \"torchvision-0.4.1+cpu-cp37-cp37m-win_amd64.whl\" # --force-reinstall\n",
        "import os\n",
        "import torch\n",
        "from torch.legacy import nn\n",
        "from torch.legacy.nn.Sequential import Sequential\n",
        "import cv2\n",
        "import numpy as np\n",
        "from torch.utils.serialization import load_lua\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "\n",
        "def tensor2image(src):\n",
        "    out = src.copy() * 255\n",
        "    out = out.transpose((1, 2, 0)).astype(np.uint8)\n",
        "    out = cv2.cvtColor(out, cv2.COLOR_RGB2BGR)\n",
        "    return out\n",
        "\n",
        "def image2tensor(src):\n",
        "    out = src.copy()\n",
        "    out = cv2.cvtColor(out, cv2.COLOR_BGR2RGB)\n",
        "    out = out.transpose((2,0,1)).astype(np.float64) / 255\n",
        "    return out\n",
        "\n",
        "image_path = 'images/zebra.png'\n",
        "mask_path = 'images/inpaint_mask.png'\n",
        "# download model from http://hi.cs.waseda.ac.jp/~iizuka/data/completionnet_places2.t7\n",
        "model_path = 'completionnet_places2.t7'\n",
        "gpu = torch.cuda.is_available()\n",
        "\n",
        "# load Completion Network\n",
        "data = load_lua(model_path,long_size=8)\n",
        "#data = torchfile.load(model_path, force_8bytes_long=True)\n",
        "model = data.model\n",
        "model.evaluate()\n",
        "\n",
        "# load data\n",
        "image = cv2.imread(image_path)\n",
        "image = cv2.resize(image, (4*(image.shape[0]//4), 4*(image.shape[1]//4)))\n",
        "I = torch.from_numpy(image2tensor(image)).float()\n",
        "\n",
        "mask = cv2.imread(mask_path)\n",
        "mask = cv2.resize(mask, (4*(mask.shape[0]//4), 4*(mask.shape[1]//4)))\n",
        "mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY) / 255\n",
        "mask[mask <= 0.5] = 0.0\n",
        "mask[mask > 0.5] = 1.0\n",
        "#print(input.shape, mask.shape)\n",
        "M = torch.from_numpy(mask).float()\n",
        "M = M.view(1, M.size(0), M.size(1))\n",
        "assert I.size(1) == M.size(1) and I.size(2) == M.size(2)\n",
        "\n",
        "for i in range(3):\n",
        "    I[i, :, :] = I[i, :, :] - data.mean[i]\n",
        "\n",
        "# create mask_3ch\n",
        "M3 = torch.cat((M, M, M), 0)\n",
        "\n",
        "im = I * (M3*(-1)+1)\n",
        "\n",
        "# set up input\n",
        "input = torch.cat((im, M), 0)\n",
        "input = input.view(1, input.size(0), input.size(1), input.size(2)).float()\n",
        "\n",
        "if gpu:\n",
        "    print('using GPU...')\n",
        "    model.cuda()\n",
        "    input = input.cuda()\n",
        "\n",
        "# evaluate\n",
        "res = model.forward(input)[0].cpu()\n",
        "\n",
        "# make out\n",
        "for i in range(3):\n",
        "    I[i, :, :] = I[i, :, :] + data.mean[i]\n",
        "\n",
        "out = res.float()*M3.float() + I.float()*(M3*(-1)+1).float()\n",
        "\n",
        "image[mask > 0.5] = 255\n",
        "plt.figure(figsize=(20,35))\n",
        "plt.subplots_adjust(left=0, right=1, top=0.9, bottom=0, wspace=0.05, hspace=0.05)\n",
        "plt.subplot(211), plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB)), plt.axis('off'), plt.title('Incomplete Image', size=20)\n",
        "plt.subplot(212), plt.imshow(cv2.cvtColor(tensor2image(out.numpy()), cv2.COLOR_BGR2RGB)), plt.axis('off'), plt.title('Completed Image (with CompletionNet)', size=20)\n",
        "#plt.savefig('inpainting_out.png', bbox_in='tight', pad_in=0)\n",
        "plt.show()\n",
        "\n",
        "print('Done')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "ckTFvVD3mEfw",
        "colab_type": "text"
      },
      "source": [
        "### Steganography and Steganalysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MG2ugptZ___x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install Stegano"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdJqaN2rmEfw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import stegano\n",
        "from PIL import Image, ImageChops\n",
        "from stegano import lsb, lsbset\n",
        "from stegano.steganalysis import statistics, parity\n",
        "import matplotlib.pylab as plt\n",
        "cover = Image.open('images/lena.png').convert('RGB')\n",
        "stego = lsb.hide(\"images/lena.png\", 10*\"Python Image Processing Cookbook - LSB data hiding with Stegano\").convert('RGB')\n",
        "stego.save(\"images/lena-secret.png\")\n",
        "print(lsb.reveal(\"images/lena-secret.png\"))\n",
        "parity_encoded_cover = parity.steganalyse(cover)\n",
        "parity_encoded_stego = parity.steganalyse(stego)\n",
        "_, cover_common = statistics.steganalyse(cover)\n",
        "_, stego_common = statistics.steganalyse(stego)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7FwfE6LmEfy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(30,20))\n",
        "plt.subplot(231), plt.imshow(cover), plt.axis('off'), plt.title('Cover Image', size=20)\n",
        "plt.subplot(232), plt.imshow(stego), plt.axis('off'), plt.title('Stego Image', size=20)\n",
        "plt.subplot(233), plt.imshow(ImageChops.difference(stego, cover)), plt.axis('off'), plt.title('Diff Image', size=20)\n",
        "plt.subplot(234), plt.imshow(parity_encoded_cover), plt.axis('off'), plt.title('Parity Encoded Cover Image', size=20)\n",
        "plt.subplot(235), plt.imshow(parity_encoded_stego), plt.axis('off'), plt.title('Parity Encoded Stego Image', size=20)\n",
        "plt.subplot(236), plt.imshow(ImageChops.difference(parity_encoded_stego, parity_encoded_cover)), plt.axis('off'), plt.title('Diff in Parity Encoded Images', size=20)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7ioTxFcmEf0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "def plot_freq(cover_common, stego_common):\n",
        "    pixel_freq = list(zip(*cover_common))\n",
        "    pixel = pixel_freq[0]\n",
        "    freq = pixel_freq[1]\n",
        "    df1 = pd.DataFrame({'Pixel':pixel, 'Freq':freq, 'Group':'Cover'})\n",
        "    pixel_freq = list(zip(*stego_common))\n",
        "    pixel = pixel_freq[0]\n",
        "    freq = pixel_freq[1]\n",
        "    df2 = pd.DataFrame({'Pixel':pixel, 'Freq':freq, 'Group':'Stego'})\n",
        "    df = pd.concat([df1, df2])\n",
        "    df.pivot(\"Pixel\", \"Group\", \"Freq\").plot(kind='bar').legend(bbox_to_anchor=(1.2, 0.5))\n",
        "    plt.xlabel('Pixel value')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.ylim((525, 735))\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "plot_freq(cover_common, stego_common)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9r-L005mEf2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cover_common"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIbp3yf0mEf4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stego_common"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8vOpPa-mEf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from stegano import lsbset\n",
        "from stegano.lsbset import generators\n",
        "\n",
        "cover = Image.open(\"images/lena.png\").convert('RGB')\n",
        "# Hide a secret with the Sieve of Eratosthenes\n",
        "secret_message = \"Python Image Processing Cookbook - LSB data hiding with Stegano lsbset!\"\n",
        "n = 1000\n",
        "stego = lsbset.hide(\"images/lena.png\",\n",
        "                                secret_message,\n",
        "                                generators.eratosthenes(),\n",
        "                                shift = n).convert('RGB')\n",
        "stego.save(\"images/stego.png\")\n",
        "print(stego.size, cover.size)\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.subplot(121)\n",
        "plt.imshow(ImageChops.difference(stego, cover), cmap='hot')\n",
        "plt.title('Difference of Stego and Cover Image', size=20)\n",
        "plt.subplot(122)\n",
        "plt.imshow(ImageChops.difference(parity.steganalyse(stego), parity.steganalyse(cover)), cmap='hot')\n",
        "plt.title('Steganalysis with Parity\\n(Locations of hidden message)', size=20)\n",
        "plt.show()\n",
        "\n",
        "try:\n",
        "    # Try to decode with another generator\n",
        "    message = lsbset.reveal(\"images/stego.png\", generators.fibonacci(), shift = n)\n",
        "except:\n",
        "    print('Could not decode with the generator provided!')\n",
        "    \n",
        "message = lsbset.reveal(\"images/stego.png\", generators.eratosthenes(), shift = n)\n",
        "message"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b24rGsrCmEf8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from stegano import exifHeader\n",
        "secret = exifHeader.hide(\"images/butterfly.jpg\", \"images/stego.png\", secret_message=5*\"Python Image Processing Cookbook - LSB data hiding with Stegano\")\n",
        "print(exifHeader.reveal(\"images/stego.png\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpxecH-mmEf-",
        "colab_type": "text"
      },
      "source": [
        "### Image Restoration with Dictionary Learning\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jt16SqtQmEf_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage.io import imread\n",
        "from skimage.color import rgb2gray\n",
        "from sklearn.decomposition import MiniBatchDictionaryLearning\n",
        "from sklearn.feature_extraction.image import extract_patches_2d\n",
        "from sklearn.feature_extraction.image import reconstruct_from_patches_2d\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "from time import time\n",
        "\n",
        "lena = rgb2gray(imread('images/lena.png'))\n",
        "#print(lena.shape, lena.dtype, np.max(lena))\n",
        "height, width = lena.shape\n",
        "\n",
        "# Distort the lower half of the image\n",
        "print('Distorting image...')\n",
        "distorted = lena.copy()\n",
        "distorted[height // 2:, :] += 0.085 * np.random.randn(height // 2, width)\n",
        "\n",
        "# Extract all reference patches from the upper half of the image\n",
        "print('Extracting reference patches...')\n",
        "t0 = time()\n",
        "patch_size = (7, 7)\n",
        "data = extract_patches_2d(distorted[height // 2:, :], patch_size)\n",
        "data = data.reshape(data.shape[0], -1)\n",
        "data -= np.mean(data, axis=0)\n",
        "data /= np.std(data, axis=0)\n",
        "print('done in %.2fs.' % (time() - t0))\n",
        "\n",
        "# #############################################################################\n",
        "# Learn the dictionary from reference patches\n",
        "\n",
        "print('Learning the dictionary...')\n",
        "t0 = time()\n",
        "dico = MiniBatchDictionaryLearning(n_components=256, alpha=1, n_iter=600)\n",
        "V = dico.fit(data).components_\n",
        "dt = time() - t0\n",
        "print('done in %.2fs.' % dt)\n",
        "\n",
        "plt.figure(figsize=(5, 5))\n",
        "for i, comp in enumerate(V):\n",
        "    plt.subplot(16, 16, i + 1)\n",
        "    plt.imshow(comp.reshape(patch_size), cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "    plt.axis('off')\n",
        "plt.suptitle('Dictionary learned from lena patches\\n' +\n",
        "             'Train time %.1fs on %d patches' % (dt, len(data)),\n",
        "             fontsize=20)\n",
        "plt.subplots_adjust(0.08, 0.02, 0.92, 0.85, 0.08, 0.23)\n",
        "\n",
        "\n",
        "# #############################################################################\n",
        "# Display the distorted image\n",
        "\n",
        "def show_with_diff(image, reference, title):\n",
        "    \"\"\"Helper function to display denoising\"\"\"\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(121), plt.title('Image')\n",
        "    plt.imshow(image, vmin=0, vmax=1, cmap=plt.cm.gray, interpolation='nearest')\n",
        "    plt.axis('off')\n",
        "    plt.subplot(122)\n",
        "    difference = image - reference\n",
        "    plt.title('Difference (norm: %.2f)' % np.sqrt(np.sum(difference ** 2)))\n",
        "    plt.imshow(difference, vmin=-0.5, vmax=0.5, cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "    plt.axis('off')\n",
        "    plt.suptitle(title, size=20)\n",
        "    plt.subplots_adjust(0.02, 0.02, 0.98, 0.79, 0.02, 0.2)\n",
        "    plt.show()\n",
        "\n",
        "show_with_diff(distorted, lena, 'Distorted image')\n",
        "\n",
        "# #############################################################################\n",
        "# Extract noisy patches and reconstruct them using the dictionary\n",
        "\n",
        "print('Extracting noisy patches... ')\n",
        "t0 = time()\n",
        "data = extract_patches_2d(distorted[height // 2:, :], patch_size)\n",
        "data = data.reshape(data.shape[0], -1)\n",
        "intercept = np.mean(data, axis=0)\n",
        "data -= intercept\n",
        "print('done in %.2fs.' % (time() - t0))\n",
        "\n",
        "print('Orthogonal Matching Pursuit\\n2 atoms' + '...')\n",
        "kwargs = {'transform_n_nonzero_coefs': 2}\n",
        "reconstruction = lena.copy()\n",
        "t0 = time()\n",
        "dico.set_params(transform_algorithm='omp', **kwargs)\n",
        "code = dico.transform(data)\n",
        "patches = np.dot(code, V)\n",
        "patches += intercept\n",
        "patches = patches.reshape(len(data), *patch_size)\n",
        "reconstruction[height // 2:, :] = reconstruct_from_patches_2d(patches, (height // 2, width))\n",
        "dt = time() - t0\n",
        "\n",
        "print('done in %.2fs.' % dt)\n",
        "show_with_diff(reconstruction, lena, 'Orthogonal Matching Pursuit\\n2 atoms (time: %.1fs)' % dt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phRL6A1kmEgC",
        "colab_type": "text"
      },
      "source": [
        "### Online Dictionary Learning "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTT9Ft2SmEgC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage.io import imread\n",
        "from skimage.color import rgb2gray\n",
        "from sklearn.decomposition import MiniBatchDictionaryLearning\n",
        "from sklearn.feature_extraction.image import extract_patches_2d\n",
        "from sklearn.feature_extraction.image import reconstruct_from_patches_2d\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "from time import time\n",
        "\n",
        "def show_with_diff2(image, reference, V, errors, title, epoch, batch):\n",
        "    \"\"\"Helper function to display denoising\"\"\"\n",
        "\n",
        "    difference = image - reference\n",
        "    \n",
        "    plt.figure(figsize=(5,5))\n",
        "    for i, comp in enumerate(V):\n",
        "        plt.subplot(16, 16, i + 1)\n",
        "        plt.imshow(comp.reshape(patch_size), cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "        plt.axis('off')\n",
        "    plt.suptitle('Dictionary learned from lena patches\\n' +\n",
        "                 'Train time %.1fs on %d patches' % (dt, len(data)),\n",
        "                 fontsize=20)\n",
        "    plt.subplots_adjust(0.08, 0.02, 0.92, 0.85, 0.08, 0.23)\n",
        "    plt.savefig('images/dict_{:d}_{:03d}.png'.format(epoch, batch))\n",
        "    plt.close()\n",
        "    \n",
        "    plt.figure(figsize=(20, 20))\n",
        "    plt.subplot(221), plt.title('Dictionary', size=20)\n",
        "    plt.imshow(imread('images/dict_{:d}_{:03d}.png'.format(epoch, batch)), cmap=plt.cm.gray, interpolation='nearest')\n",
        "    plt.axis('off')\n",
        "    \n",
        "    plt.subplot(222), plt.title('Reconstructed Image', size=20)\n",
        "    plt.imshow(image, vmin=0, vmax=1, cmap=plt.cm.gray, interpolation='nearest')\n",
        "    plt.axis('off')\n",
        "    \n",
        "    plt.subplot(223)\n",
        "    plt.title('Difference = Reconstructed - Original (norm: %.2f)' % error, size=20)\n",
        "    plt.imshow(difference, vmin=-0.5, vmax=0.5, cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "    plt.axis('off')\n",
        "    \n",
        "    print(len(errors))\n",
        "    plt.subplot(224), plt.title('Error (w.r.t Original)', size=20)\n",
        "    plt.plot(range(len(errors)), errors, 'r.-')\n",
        "    plt.xlabel('Batches (every 10)')\n",
        "    plt.ylabel('Norm of Difference')\n",
        "    plt.xticks(range(len(errors)+1))\n",
        "    \n",
        "    plt.suptitle(title, size=30)\n",
        "    plt.subplots_adjust(0.02, 0.02, 0.98, 0.9, 0.02, 0.2)\n",
        "    plt.savefig('images/out_{:d}_{:03d}.png'.format(epoch, batch))\n",
        "    plt.show()\n",
        "\n",
        "lena = rgb2gray(imread('images/lena.png'))\n",
        "#print(lena.shape, lena.dtype, np.max(lena))\n",
        "height, width = lena.shape\n",
        "\n",
        "# Distort the right half of the image\n",
        "print('Distorting image...')\n",
        "distorted = lena.copy()\n",
        "distorted[height // 2:, :] += 0.085 * np.random.randn(height // 2, width)\n",
        "\n",
        "# Extract all reference patches from the left half of the image\n",
        "print('Extracting reference patches...')\n",
        "t0 = time()\n",
        "patch_size = (7, 7)\n",
        "data = extract_patches_2d(distorted[height // 2:, :], patch_size)\n",
        "data = data.reshape(data.shape[0], -1)\n",
        "data -= np.mean(data, axis=0)\n",
        "data /= np.std(data, axis=0)\n",
        "print('done in %.2fs.' % (time() - t0))\n",
        "\n",
        "# #############################################################################\n",
        "# Learn the dictionary from reference patches\n",
        "\n",
        "print('Learning the dictionary...')\n",
        "batch_size = 128 #128 #32\n",
        "n_epochs = 2 #10 # 20\n",
        "n_batches = len(data) // batch_size\n",
        "print(n_batches) \n",
        "\n",
        "t0 = time()\n",
        "dico = MiniBatchDictionaryLearning(n_components=256, alpha=1, n_iter=1, batch_size=batch_size)\n",
        "print('Extracting noisy patches... ')\n",
        "noisy_data = extract_patches_2d(distorted[height // 2:, :], patch_size)\n",
        "noisy_data = noisy_data.reshape(noisy_data.shape[0], -1)\n",
        "intercept = np.mean(noisy_data, axis=0)\n",
        "noisy_data -= intercept\n",
        "print('done in %.2fs.' % (time() - t0))\n",
        "\n",
        "n_updates = 0\n",
        "errors = []\n",
        "for epoch in range(n_epochs):\n",
        "    for i in range(n_batches):\n",
        "        batch = data[i * batch_size: (i + 1) * batch_size]\n",
        "        dico.partial_fit(batch)\n",
        "        V = dico.components_\n",
        "        n_updates += 1\n",
        "        if n_updates % 10 == 0:\n",
        "            print('Orthogonal Matching Pursuit\\n2 atoms (batch size = 128), epoch={}, batch={}'.format(epoch+1, i+1))\n",
        "            kwargs = {'transform_n_nonzero_coefs': 2}\n",
        "            reconstruction = lena.copy()\n",
        "            t0 = time()\n",
        "            dico.set_params(transform_algorithm='omp', **kwargs)\n",
        "            code = dico.transform(noisy_data)\n",
        "            patches = np.dot(code, V)\n",
        "            patches += intercept\n",
        "            patches = patches.reshape(len(data), *patch_size)\n",
        "            reconstruction[height // 2:, :] = reconstruct_from_patches_2d(patches, (height // 2, width))\n",
        "            error = np.sqrt(np.sum((lena - reconstruction) ** 2))\n",
        "            errors.append(error)\n",
        "            print('error={}'.format(error))\n",
        "            dt = time() - t0\n",
        "            print('done in %.2fs.' % dt)\n",
        "            if n_updates % 100 == 0:\n",
        "                show_with_diff2(reconstruction, lena, V, errors,\n",
        "                   'Orthogonal Matching Pursuit with2 atoms {:.01f}s\\n Minibatch Dictionary Learning: epoch={}, batch={}'\n",
        "                    .format(dt, epoch+1, i+1), epoch+1, i+1)\n",
        "            \n",
        "dt = time() - t0\n",
        "print('done in %.2fs.' % dt)\n",
        "\n",
        "plt.figure(figsize=(5, 5))\n",
        "for i, comp in enumerate(V):\n",
        "    plt.subplot(16, 16, i + 1)\n",
        "    plt.imshow(comp.reshape(patch_size), cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "    plt.axis('off')\n",
        "plt.suptitle('Dictionary learned from lena patches\\n' +\n",
        "             'Train time %.1fs on %d patches' % (dt, len(data)),\n",
        "             fontsize=20)\n",
        "plt.subplots_adjust(0.08, 0.02, 0.92, 0.85, 0.08, 0.23)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "8BewWVW8mEgE",
        "colab_type": "text"
      },
      "source": [
        "### Image Compression with Wavelets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RVd9YyCmEgF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://mahotas.readthedocs.io/en/latest/wavelets.html\n",
        "import numpy as np\n",
        "import mahotas\n",
        "from mahotas.thresholding import soft_threshold\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "\n",
        "im = mahotas.imread('images/cameraman.png', as_grey=True)\n",
        "im = im.astype(np.uint8)\n",
        "print(im.shape)\n",
        "f = np.mean(im==0)\n",
        "print(\"Fraction of zeros in original image: {}\".format(f))\n",
        "\n",
        "im1 = im[::2,::2].copy()\n",
        "im1 = im1 / 8\n",
        "im1 = im1.astype(np.uint8)\n",
        "f1 = np.mean(im1==0)\n",
        "print(\"Fraction of zeros in original image (after division by 8): {}\".format(f1))\n",
        "\n",
        "# Transform using D8 Wavelet to obtain transformed image imw\n",
        "imw = mahotas.daubechies(mahotas.wavelet_center(im),'D8')\n",
        "# Discard low-order bits:\n",
        "imw /= 8\n",
        "imw = imw.astype(np.int8)\n",
        "mahotas.imsave('images/cameraman_D8.png', (imw - np.min(imw)).astype(np.uint8))\n",
        "f2 = np.mean(imw==0)\n",
        "print(\"Fraction of zeros in wavelet transform (after division by 8): {}\".format(f2))\n",
        "im2 = mahotas.wavelet_decenter(mahotas.idaubechies(imw, 'D8'), im.shape)\n",
        "im2 = (255 * (im2 - np.min(im2)) / (np.max(im2) - np.min(im2))).astype(np.uint8) # min-max normalization\n",
        "\n",
        "print(imw.shape)\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(imw), plt.axis('off'), plt.title('Wavelet Transform Output', size=20)\n",
        "plt.subplots_adjust(0,0,1,1,0.01,0.01)\n",
        "plt.show()\n",
        "\n",
        "imw = soft_threshold(imw, 12)\n",
        "f3 = np.mean(imw==0)\n",
        "print(\"Fraction of zeros in wavelet transform (after division by 8 & soft thresholding): {}\".format(f3))\n",
        "#imw = imw.astype(np.int8)\n",
        "im3 = mahotas.wavelet_decenter(mahotas.idaubechies(imw, 'D8'), im.shape)\n",
        "im3 = (255 * (im3 - np.min(im3)) / (np.max(im3) - np.min(im3))).astype(np.uint8) # min-max normalization\n",
        "\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.gray()\n",
        "# Show the data:\n",
        "plt.subplot(221), plt.imshow(im), plt.axis('off')\n",
        "plt.title('original image, zeros={}%'.format(np.round(100*f, 3)), size=20)\n",
        "plt.subplot(222), plt.imshow(im1), plt.axis('off')\n",
        "plt.title('image (div 8), zeros={}%'.format(np.round(100*f1, 3)), size=20)\n",
        "plt.subplot(223), plt.imshow(im2), plt.axis('off')\n",
        "plt.title('image with DWT (D8)\\n zeros in transform={}%'.format(np.round(100*f2, 3)), size=20)\n",
        "plt.subplot(224), plt.imshow(im3), plt.axis('off')\n",
        "plt.title('image with DWT (D8) + soft thresholding\\n zeros in transform={}%'.format(np.round(100*f3, 3)), size=20)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ef95tkTImEgH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install mahotas\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}