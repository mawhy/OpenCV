{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "Image Manipulation and Transformation",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mawhy/OpenCV/blob/master/Image_Manipulation_and_Transformation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eN8ClEb6gdM1",
        "colab_type": "text"
      },
      "source": [
        "# Image Processing CookBook\n",
        "## Image Manipulation and Transformation\n",
        "\n",
        "Image Manipulation and Transformation, is where you will learn how to use\n",
        "different Python libraries (NumPy, SciPy, scikit-image, OpenCV, and Matplotlib) for image\n",
        "manipulation and transformation. You will learn how to write Python code to do point\n",
        "transforms (log/gamma transform, Gotham filter, colorspace transformation, and increasing\n",
        "brightness/contrast) and geometric transforms (swirl transform, perspective transform, and\n",
        "homography).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBAv13qfg-at",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/PacktPublishing/Python-Image-Processing-Cookbook.git\n",
        "%cp -av \"/content/Python-Image-Processing-Cookbook/Chapter 01/images/\" \"/content/\"\n",
        "%cp -av \"/content/Python-Image-Processing-Cookbook/Chapter 01/models/\" \"/content/\"\n",
        "%rm -rf \"/content/Python-Image-Processing-Cookbook\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2-kUARTgdM2",
        "colab_type": "text"
      },
      "source": [
        "### Colorspace Transformation: from RGB to Lab colorspace"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZxvZVIxgdM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "from skimage import img_as_float\n",
        "from skimage.io import imread\n",
        "from skimage.color import rgb2lab, lab2rgb\n",
        "from skimage.util import invert\n",
        "from skimage.exposure import equalize_hist\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "im = imread('images/flowers.png')\n",
        "\n",
        "im1 = rgb2lab(im)\n",
        "im1[...,1] = im1[...,2] = 0\n",
        "im1 = lab2rgb(im1)\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.subplot(121), plt.imshow(im), plt.axis('off'), plt.title('Original image', size=20)\n",
        "plt.subplot(122), plt.imshow(im1), plt.axis('off'), plt.title('Gray scale image', size=20)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESUy7IuvgdM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(20,5))\n",
        "plt.subplot(131), plt.imshow(im), plt.axis('off'), plt.title('Original image', size=20)\n",
        "\n",
        "im1 = rgb2lab(im)\n",
        "im1[...,0] = im1[...,0] + 50 \n",
        "im1 = lab2rgb(im1)\n",
        "\n",
        "plt.subplot(132), plt.imshow(im1), plt.axis('off'), plt.title('Brighter image', size=20)\n",
        "\n",
        "im1 = rgb2lab(im)\n",
        "im1[...,0] = im1[...,0] - 50 \n",
        "im1 = lab2rgb(im1)\n",
        "\n",
        "plt.subplot(133), plt.imshow(im1), plt.axis('off'), plt.title('Darker image', size=20)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuJkIcWxgdM8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "im1 = rgb2lab(im)\n",
        "im1[...,0] = np.max(im1[...,0]) - im1[...,0]\n",
        "im1 = lab2rgb(im1)\n",
        "\n",
        "plt.figure(figsize=(20,6))\n",
        "plt.subplot(131), plt.imshow(im), plt.axis('off'), plt.title('Original image', size=20)\n",
        "plt.subplot(132), plt.imshow(im1), plt.axis('off'), plt.title('Inverted image (Lab)', size=20)\n",
        "plt.subplot(133), plt.imshow(invert(im)), plt.axis('off'), plt.title('Inverted image (RGB)', size=20)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvZprmldgdM-",
        "colab_type": "text"
      },
      "source": [
        "### Affine Transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yW51kGVpgdM_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from scipy import ndimage as ndi\n",
        "from skimage.io import imread\n",
        "from skimage.color import rgb2gray\n",
        "\n",
        "img = rgb2gray(imread('images/humming.png'))\n",
        "w, h = img.shape\n",
        "theta, lambda1 = np.pi/6, 0.5\n",
        "mat_identity = np.array([[1,0,0],[0,1,0],[0,0,1]])\n",
        "mat_reflect = np.array([[1,0,0],[0,-1,0],[0,0,1]]) @ np.array([[1,0,0],[0,1,-h],[0,0,1]])\n",
        "mat_scale = np.array([[0.75,0,0],[0,1.25,0],[0,0,1]])\n",
        "mat_rotate = np.array([[1,0,w/2],[0,1,h/2],[0,0,1]]) @ np.array([[np.cos(theta),np.sin(theta),0],[np.sin(theta),-np.cos(theta),0],[0,0,1]]) @ np.array([[1,0,-w/2],[0,1,-h/2],[0,0,1]])\n",
        "mat_shear = np.array([[1,lambda1,0],[lambda1,1,0],[0,0,1]])\n",
        "mat_all = mat_identity @ mat_reflect @ mat_scale @ mat_rotate @ mat_shear\n",
        "plt.figure(figsize=(20,10))\n",
        "img1 = ndi.affine_transform(img, mat_identity)\n",
        "plt.subplot(231), plt.imshow(img1), plt.axis('off'), plt.title('Original image', size=20)\n",
        "img1 = ndi.affine_transform(img1, mat_reflect) # offset=(0,h)\n",
        "plt.subplot(232), plt.imshow(img1), plt.axis('off'), plt.title('First reflect', size=20)\n",
        "img1 = ndi.affine_transform(img1, mat_scale)\n",
        "plt.subplot(233), plt.imshow(img1), plt.axis('off'), plt.title('Then scale', size=20) \n",
        "img1 = ndi.affine_transform(img1, mat_rotate)\n",
        "plt.subplot(234), plt.imshow(img1), plt.axis('off'), plt.title('Then rotate', size=20) \n",
        "img1 = ndi.affine_transform(img1, mat_shear)\n",
        "plt.subplot(235), plt.imshow(img1), plt.axis('off'), plt.title('Then shear', size=20) \n",
        "plt.subplot(236), plt.imshow(ndi.affine_transform(img, mat_all)), plt.axis('off'), plt.title('All at once', size=20) \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGy3k67HgdNB",
        "colab_type": "text"
      },
      "source": [
        "### Non-linear Transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRMfraUggdNC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage.io import imread\n",
        "from skimage.transform import warp, PolynomialTransform\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "def swirl(xy, x0, y0, R):\n",
        "    r = np.sqrt((xy[:,1]-x0)**2 + (xy[:,0]-y0)**2)\n",
        "    a = np.pi*r / R\n",
        "    xy[:, 1], xy[:, 0] = (xy[:, 1]-x0)*np.cos(a) + (xy[:, 0]-y0)*np.sin(a) + x0, -(xy[:, 1]-x0)*np.sin(a) + (xy[:, 0]-y0)*np.cos(a) + y0\n",
        "    return xy\n",
        "\n",
        "im = imread('images/lena.png')\n",
        "print(im.shape)\n",
        "im1 = warp(im, swirl, map_args={'x0':100, 'y0':100, 'R':250})\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.subplot(121), plt.imshow(im), plt.axis('off'), plt.title('Input image', size=20)\n",
        "plt.subplot(122), plt.imshow(im1), plt.axis('off'), plt.title('Output image', size=20)\n",
        "plt.show()\n",
        "\n",
        "#print(im.shape, im1.shape)\n",
        "t = PolynomialTransform()\n",
        "x, y = np.mgrid[:im.shape[0], :im.shape[1]]\n",
        "dst_indices = np.hstack((x.reshape(-1, 1), y.reshape(-1,1)))\n",
        "dst_indices = dst_indices[np.random.choice(dst_indices.shape[0], 500),:]\n",
        "src_indices = swirl(dst_indices, 100, 100, 250).astype(int)\n",
        "t.estimate(dst_indices, src_indices, 8)\n",
        "#print(src_indices)\n",
        "\n",
        "img_warped = warp(im1, t, order=3, mode='constant',cval=float('nan'))\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(img_warped), plt.axis('off')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5r_5jZlgdNE",
        "colab_type": "text"
      },
      "source": [
        "### Elastic Transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-9jzXV6gdNF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://gist.github.com/erniejunior/601cdf56d2b424757de5\n",
        "# http://cognitivemedium.com/assets/rmnist/Simard.pdf\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "from skimage.color import rgb2gray\n",
        "from scipy.ndimage import gaussian_filter, map_coordinates \n",
        "\n",
        "def elastic_transform(image, alpha, sigma, random_state=None):\n",
        "    if random_state is None:\n",
        "        random_state = np.random.RandomState(None)\n",
        "\n",
        "    shape = image.shape\n",
        "    dx = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=\"constant\", cval=0) * alpha\n",
        "    dy = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=\"constant\", cval=0) * alpha\n",
        "    dz = np.zeros_like(dx)\n",
        "    #print(dx, dy, dz)\n",
        "    x, y, z = np.meshgrid(np.arange(shape[0]), np.arange(shape[1]), np.arange(shape[2]))\n",
        "    print (x.shape)\n",
        "    indices = np.reshape(y+dy, (-1, 1)), np.reshape(x+dx, (-1, 1)), np.reshape(z, (-1, 1))\n",
        "\n",
        "    distored_image = map_coordinates(image, indices, order=1, mode='reflect')\n",
        "    return distored_image.reshape(image.shape)\n",
        "\n",
        "img = plt.imread('images/lena.png')\n",
        "img1 = elastic_transform(img, 8, 0.5)\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(img1), plt.axis('off'), plt.title('Elastic Deformation', size=20)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c416i_aqgdNH",
        "colab_type": "text"
      },
      "source": [
        "### Perspective Projection and Homography"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AbdXqBvgdNI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage.transform import ProjectiveTransform\n",
        "from skimage.io import imread\n",
        "from skimage.color import rgb2gray\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "im_src = (imread('images/humming.png'))\n",
        "height, width, dim = im_src.shape\n",
        "im_dst = np.zeros((height, width, dim))\n",
        "\n",
        "pt = ProjectiveTransform()\n",
        "src = np.array([[   0.,    0.],\n",
        "       [height-1,    0.],\n",
        "       [height-1,  width-1],\n",
        "       [   0.,  width-1]])\n",
        "dst = np.array([[ 295., 174.],\n",
        "       [ 540., 146. ],\n",
        "       [ 400., 777.],\n",
        "       [  60., 422.]])\n",
        "\n",
        "print(pt.estimate(src, dst))\n",
        "\n",
        "x, y = np.mgrid[:height, :width]\n",
        "dst_indices=np.hstack((x.reshape(-1, 1), y.reshape(-1,1))) \n",
        "src_indices = np.round(pt.inverse(dst_indices), 0).astype(int)\n",
        "valid_idx = np.where((src_indices[:,0] < height) & (src_indices[:,1] < width) & (src_indices[:,0] >= 0) & (src_indices[:,1] >= 0))\n",
        "dst_indicies_valid = dst_indices[valid_idx]\n",
        "src_indicies_valid = src_indices[valid_idx]\n",
        "im_dst[dst_indicies_valid[:,0],dst_indicies_valid[:,1]] = im_src[src_indicies_valid[:,0],src_indicies_valid[:,1]]\n",
        "im_dst = im_dst.astype(np.uint8) \n",
        "plt.figure(figsize=(20,10))\n",
        "plt.subplot(121), plt.imshow(im_src, cmap='gray'), plt.axis('off'), plt.title('Source image', size=30)\n",
        "plt.subplot(122), plt.imshow(im_dst, cmap='gray'), plt.axis('off'), plt.title('Destination image', size=30)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlFO8bDPgdNK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage.transform import ProjectiveTransform, warp\n",
        "from skimage.io import imread\n",
        "from skimage.color import rgb2gray\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "im_src = (imread('images/humming2.png'))\n",
        "height, width, dim = im_src.shape\n",
        "im_dst = np.zeros((height, width, dim))\n",
        "\n",
        "pt = ProjectiveTransform()\n",
        "src = np.array([[ 295., 174.],\n",
        "       [ 540., 146. ],\n",
        "       [ 400., 777.],\n",
        "       [  60., 422.]])\n",
        "dst = np.array([[   0.,    0.],\n",
        "       [height-1,    0.],\n",
        "       [height-1,  width-1],\n",
        "       [   0.,  width-1]])\n",
        "\n",
        "print(pt.estimate(src, dst))\n",
        "\n",
        "x, y = np.mgrid[:height, :width]\n",
        "dst_indices = np.hstack((x.reshape(-1, 1), y.reshape(-1,1))) \n",
        "src_indices = np.round(pt.inverse(dst_indices), 0).astype(int)\n",
        "valid_idx = np.where((src_indices[:,0] < height) & (src_indices[:,1] < width) & (src_indices[:,0] >= 0) & (src_indices[:,1] >= 0))\n",
        "dst_indicies_valid = dst_indices[valid_idx]\n",
        "src_indicies_valid = src_indices[valid_idx]\n",
        "im_dst[dst_indicies_valid[:,0],dst_indicies_valid[:,1]] = im_src[src_indicies_valid[:,0],src_indicies_valid[:,1]]\n",
        "im_dst = im_dst.astype(np.uint8) \n",
        "plt.figure(figsize=(20,10))\n",
        "plt.subplot(121), plt.imshow(im_src, cmap='gray'), plt.axis('off'), plt.title('Source image', size=30)\n",
        "plt.subplot(122), plt.imshow(im_dst, cmap='gray'), plt.axis('off'), plt.title('Destination image', size=30)\n",
        "plt.show()\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(warp(im_src.transpose(1,0,2), np.linalg.inv(pt.params), output_shape=(width,height)).transpose(1,0,2))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2XVB4OsgdNM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage.transform import ProjectiveTransform\n",
        "from skimage.io import imread\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "im_src = (imread('images/man_moon.png'))\n",
        "im_dst = imread('images/shutterstock.png')\n",
        "height, width, dim = im_src.shape\n",
        "\n",
        "pt = ProjectiveTransform()\n",
        "src = np.array([[   0.,    0.],\n",
        "       [height-1,    0.],\n",
        "       [height-1,  width-1],\n",
        "       [   0.,  width-1]])\n",
        "dst = np.array([[ 41., 74.],\n",
        "       [ 228., 72.],\n",
        "       [ 192., 272.],\n",
        "       [ 96., 272.]])\n",
        "\n",
        "print(pt.estimate(src, dst))\n",
        "\n",
        "x, y = np.mgrid[:im_dst.shape[0], :im_dst.shape[1]]\n",
        "dst_indices=np.hstack((x.reshape(-1, 1), y.reshape(-1,1))) \n",
        "src_indices = np.round(pt.inverse(dst_indices), 0).astype(int)\n",
        "valid_idx = np.where((src_indices[:,0] < height) & (src_indices[:,1] < width) & (src_indices[:,0] >= 0) & (src_indices[:,1] >= 0))\n",
        "dst_indicies_valid = dst_indices[valid_idx]\n",
        "src_indicies_valid = src_indices[valid_idx]\n",
        "im_dst[dst_indicies_valid[:,0],dst_indicies_valid[:,1]] = im_src[src_indicies_valid[:,0],src_indicies_valid[:,1]]\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.imshow(im_dst), plt.axis('off'), plt.title('Output Image', size=20)\n",
        "plt.savefig('images/homography_out.png', bbox_in='tight', pad_in=0)\n",
        "plt.close()\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.subplot(121), plt.imshow(im_src, cmap='gray'), plt.axis('off'), plt.title('Source image', size=30)\n",
        "plt.subplot(122), plt.imshow(im_dst, cmap='gray'), plt.axis('off'), plt.title('Destination image', size=30)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaSvchHrgdNO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage.transform import ProjectiveTransform\n",
        "from skimage.io import imread\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "im_src = imread('images/painting.png')\n",
        "im_dst = imread('images/graffiti.png')\n",
        "im_mask = imread('images/graffiti_mask.png')\n",
        "im_dst1 = np.copy(im_dst)\n",
        "height, width, dim = im_src.shape\n",
        "print(height, width, im_src.shape, im_dst.shape)\n",
        "\n",
        "pt = ProjectiveTransform()\n",
        "src = np.array([[   0.,    0.],\n",
        "       [height-1,    0.],\n",
        "       [height-1,  width-1],\n",
        "       [   0.,  width-1]])\n",
        "dst = np.array([[ 0., 0.],\n",
        "       [im_dst.shape[0]-1, 0],\n",
        "       [im_dst.shape[0]-1,  687],\n",
        "       [ 0., 659]])\n",
        "print(pt.estimate(src, dst))\n",
        "\n",
        "im_dst_masked = im_dst & im_mask\n",
        "\n",
        "x, y = np.mgrid[:im_dst.shape[0], :im_dst.shape[1]]\n",
        "dst_indices = np.hstack((x.reshape(-1, 1), y.reshape(-1,1))) \n",
        "src_indices = np.round(pt.inverse(dst_indices), 0).astype(int)\n",
        "valid_idx = np.where((src_indices[:,0] < height) & (src_indices[:,1] < width) & (src_indices[:,0] >= 0) & (src_indices[:,1] >= 0))\n",
        "dst_indicies_valid = dst_indices[valid_idx]\n",
        "src_indicies_valid = src_indices[valid_idx]\n",
        "im_dst[dst_indicies_valid[:,0],dst_indicies_valid[:,1]] = im_src[src_indicies_valid[:,0],src_indicies_valid[:,1]]\n",
        "im_dst &= (~im_mask) \n",
        "im_dst += im_dst_masked\n",
        "plt.figure(figsize=(20,30))\n",
        "plt.subplot(311), plt.imshow(im_src), plt.axis('off'), plt.title('Source image', size=30)\n",
        "plt.subplot(312), plt.imshow(im_dst1), plt.axis('off'), plt.title('Destination image', size=30)\n",
        "plt.subplot(313), plt.imshow(im_dst), plt.axis('off'), plt.title('Final image', size=30)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhBn4wcTgdNR",
        "colab_type": "text"
      },
      "source": [
        "### Pencil Sketches from images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aklg_Vyxj_UL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install medpy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGX_UTAugdNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "from skimage.color import rgb2gray\n",
        "from skimage import util\n",
        "from skimage import img_as_float\n",
        "import matplotlib.pylab as plt\n",
        "from medpy.filter.smoothing import anisotropic_diffusion\n",
        "from skimage.filters import gaussian, threshold_otsu\n",
        "\n",
        "def normalize(img):\n",
        "    return (img-np.min(img))/(np.max(img)-np.min(img))\n",
        "\n",
        "def sketch(img, edges):\n",
        "    output = np.multiply(img, edges)\n",
        "    output[output>1]=1\n",
        "    output[edges==1]=1\n",
        "    #output = normalize(output)\n",
        "    return output\n",
        "\n",
        "def edges_with_anisotropic_diffusion(img, niter=100, kappa=10, gamma=0.1):\n",
        "    #img = gaussian(img, sigma=0.05)\n",
        "    output = img - anisotropic_diffusion(img, niter=niter, kappa=kappa, gamma=gamma, voxelspacing=None, option=1)\n",
        "    output[output > 0] = 1\n",
        "    output[output < 0] = 0\n",
        "    #output = np.clip(output, 0, 1)\n",
        "    #thresh = threshold_otsu(output)\n",
        "    #output = np.invert(output > thresh)\n",
        "    return output\n",
        "\n",
        "def edges_with_dodge2(img):\n",
        "    img_blurred = gaussian(util.invert(img), sigma=5)\n",
        "    output = np.divide(img, util.invert(img_blurred) + 0.001) # avoid division by zero\n",
        "    print(np.max(output), np.min(output))\n",
        "    output = normalize(output)\n",
        "    thresh = threshold_otsu(output)\n",
        "    output = output > thresh\n",
        "    return output\n",
        "\n",
        "\n",
        "def sketch_with_dodge(img):\n",
        "    orig = img\n",
        "    blur = gaussian(util.invert(img), sigma=20)\n",
        "    result=blur/util.invert(orig) \n",
        "    result[result>1]=1\n",
        "    result[orig==1]=1\n",
        "    return result\n",
        "\n",
        "# with DOG\n",
        "def edges_with_DOG(img, k = 200, gamma = 1):\n",
        "    sigma = 0.5\n",
        "    output = gaussian(img, sigma=sigma) - gamma*gaussian(img, sigma=k*sigma)\n",
        "    output[output > 0] = 1\n",
        "    output[output < 0] = 0 \n",
        "    return output\n",
        "\n",
        "def sketch_with_XDOG(image, epsilon=0.01):\n",
        "  \"\"\"\n",
        "  Computes the eXtended Difference of Gaussians (XDoG) for a given image. This \n",
        "  is done by taking the regular Difference of Gaussians, thresholding it\n",
        "  at some value, and applying the hypertangent function the the unthresholded\n",
        "  values.\n",
        "  image: an n x m single channel matrix.\n",
        "  epsilon: the offset value when computing the hypertangent.\n",
        "  returns: an n x m single channel matrix representing the XDoG.\n",
        "  \"\"\"\n",
        "  phi = 10\n",
        "\n",
        "  difference = edges_with_DOG(image, 200, 0.98).astype(np.uint8)\n",
        "  #difference = sketch(image, difference)\n",
        "  #difference = normalize(difference)  \n",
        "\n",
        "  for i in range(0, len(difference)):\n",
        "    for j in range(0, len(difference[0])):\n",
        "      if difference[i][j] >= epsilon:\n",
        "        difference[i][j] = 1\n",
        "      else:\n",
        "        ht = np.tanh(phi*(difference[i][j] - epsilon))\n",
        "        difference[i][j] = 1 + ht\n",
        "  difference = normalize(difference)  \n",
        "  return difference\n",
        "\n",
        "def plot_sketches(img_file):\n",
        "    img = rgb2gray(imread(img_file))\n",
        "    plt.figure(figsize=(20,25))\n",
        "    output_aniso = sketch(img, edges_with_anisotropic_diffusion(img))\n",
        "    output_dog = sketch(img, edges_with_DOG(img, k=25))\n",
        "    output_xdog = sketch_with_XDOG(img)\n",
        "    output_dodge = sketch_with_dodge(img)\n",
        "    output_dodge2 = sketch(img, edges_with_dodge2(img))\n",
        "    plt.subplots_adjust(left=0, right=1, bottom=0, top=0.95, hspace=0.05, wspace=0.05) \n",
        "    plt.subplot(321), plt.imshow(img), plt.axis('off')\n",
        "    plt.title('Original Gray-scale image', size=20)\n",
        "    plt.subplot(322), plt.imshow(output_aniso), plt.axis('off')\n",
        "    plt.title('Sketch with anisotropic diffusion', size=20)\n",
        "    plt.subplot(323), plt.imshow(output_dog), plt.axis('off')\n",
        "    plt.title('Sketch with DOG', size=20)\n",
        "    plt.subplot(324), plt.imshow(output_xdog), plt.axis('off')\n",
        "    plt.title('Sketch with XDOG', size=20)\n",
        "    plt.subplot(325), plt.imshow(output_dodge), plt.axis('off')\n",
        "    plt.title('Sketch with Dodge', size=20)\n",
        "    plt.subplot(326), plt.imshow(output_dodge2), plt.axis('off')\n",
        "    plt.title('Sketch with Dodge2', size=20)\n",
        "    #plt.show()\n",
        "    plt.savefig(img_file.split('.')[0] + '_sketches_all.png', bbox_in='tight')\n",
        "\n",
        "plt.gray()\n",
        "img = 'images/bird.png'\n",
        "plot_sketches(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdrcXfeMgdNU",
        "colab_type": "text"
      },
      "source": [
        "### Cartoonizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcbegTdcgdNU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "num_down = 2       # number of downsampling steps\n",
        "num_bilateral = 7  # number of bilateral filtering steps\n",
        "\n",
        "    \n",
        "img = plt.imread(\"images/bean.png\")\n",
        "w, h, _ = img.shape\n",
        "  \n",
        "# downsample image using Gaussian pyramid\n",
        "img_color = np.copy(img)\n",
        "for _ in range(num_down):\n",
        "    img_color = cv2.pyrDown(img_color)\n",
        " \n",
        "# repeatedly apply small bilateral filter instead of\n",
        "# applying one large filter\n",
        "for _ in range(num_bilateral):\n",
        "    img_color = cv2.bilateralFilter(img_color, d=9,\n",
        "                                    sigmaColor=0.1,\n",
        "                                    sigmaSpace=0.01)\n",
        "\n",
        "# upsample image to original size\n",
        "for _ in range(num_down):\n",
        "    img_color = cv2.pyrUp(img_color)\n",
        "    \n",
        "img_color = cv2.resize(img_color, (img.shape[1], img.shape[0]))\n",
        "\n",
        "# convert to grayscale and apply median blur\n",
        "img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "img_blur = cv2.medianBlur((255*img_gray).astype(np.uint8), 7) # convert float32 to uint8\n",
        "\n",
        "# detect and enhance edges\n",
        "img_edge = cv2.adaptiveThreshold((255*img_blur).astype(np.uint8), 255,\n",
        "                                 cv2.ADAPTIVE_THRESH_MEAN_C, #ADAPTIVE_THRESH_GAUSSIAN_C, \n",
        "                                 cv2.THRESH_BINARY_INV,\n",
        "                                 blockSize=11,\n",
        "                                 C=0)\n",
        "\n",
        "# convert back to color, bit-AND with color image\n",
        "img_edge = cv2.cvtColor(img_edge, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "img_cartoon = cv2.bitwise_and((255*img_color).astype(np.uint8), img_edge)\n",
        "\n",
        "# display\n",
        "fig = plt.figure(figsize=(20,10))\n",
        "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05) \n",
        "plt.subplot(121)\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.title('Original Image', size=20)\n",
        "plt.subplot(122)\n",
        "plt.imshow(img_cartoon)\n",
        "plt.axis('off')\n",
        "plt.title('Cartoonized Image', size=20)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzKMUrxegdNW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "from medpy.filter.smoothing import anisotropic_diffusion\n",
        "\n",
        "img = plt.imread(\"images/bean.png\")\n",
        "output = img.copy()\n",
        "for i in range(3):\n",
        "    output[...,i] = anisotropic_diffusion(img[...,i], niter=50, kappa=0.1, gamma=0.05, voxelspacing=None, option=1)\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(output), plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2e4oGI4gdNY",
        "colab_type": "text"
      },
      "source": [
        "### Pencil-Sketches, Color-Pencil-Sketches and Stylized-Color images with opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i-4oih4gdNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import matplotlib.pylab as plt\n",
        "src = cv2.imread('images/bird.png')\n",
        "#dst = cv2.detailEnhance(src, sigma_s=10, sigma_r=0.15)\n",
        "dst_sketch, dst_color_sketch = cv2.pencilSketch(src, sigma_s=50, sigma_r=0.05, shade_factor=0.05)\n",
        "dst_water_color = cv2.stylization(src, sigma_s=50, sigma_r=0.05)\n",
        "plt.figure(figsize=(20,14))\n",
        "plt.subplot(221), plt.imshow(cv2.cvtColor(src, cv2.COLOR_BGR2RGB)), plt.axis('off'), plt.title('Original', size=20)\n",
        "plt.subplot(222), plt.imshow(dst_sketch, cmap='gray'), plt.axis('off'), plt.title('Pencil-Sketch', size=20)\n",
        "plt.subplot(223), plt.imshow(cv2.cvtColor(dst_color_sketch, cv2.COLOR_BGR2RGB)), plt.axis('off'), plt.title('Color-Pencil-Sketch', size=20)\n",
        "plt.subplot(224), plt.imshow(cv2.cvtColor(dst_water_color, cv2.COLOR_BGR2RGB)), plt.axis('off'), plt.title('Stylized-Color', size=20)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmLwOWVHgdNb",
        "colab_type": "text"
      },
      "source": [
        "### Image stained glass with Voronoi tessellation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9JTuhYtgdNd",
        "colab_type": "text"
      },
      "source": [
        "### Pointillism"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2AVmM-YkufX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pointillism"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2iScn5HgdNe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pointillism as pt\n",
        "point = pt.image(location='images/elephants.png', debug = True)\n",
        "point.make('balanced')\n",
        "point.display()\n",
        "#point.save_out(location='images', suffix='basic test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsMZVCZ3gdNg",
        "colab_type": "text"
      },
      "source": [
        "### Simulating Light art / long exposure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YCpX3qxgdNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from glob import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "def extract_frames(vid_file):\n",
        "    vidcap = cv2.VideoCapture(vid_file)\n",
        "    success,image = vidcap.read()\n",
        "    i = 1\n",
        "    success = True\n",
        "    while success and i <= 200:\n",
        "      cv2.imwrite('images/exposure/vid_{}.png'.format(i), image)\n",
        "      success,image = vidcap.read()\n",
        "      i += 1\n",
        "\n",
        "extract_frames('images/godafost.mp4') #cloud.mp4\n",
        "\n",
        "imfiles = glob('images/exposure/*.png')\n",
        "nfiles = len(imfiles)\n",
        "R1, G1, B1 = 0, 0, 0\n",
        "for i in range(nfiles):\n",
        "    image = cv2.imread(imfiles[i]).astype(float)\n",
        "    (B, G, R) = cv2.split(image)\n",
        "    R1 += R\n",
        "    B1 += B\n",
        "    G1 += G\n",
        "R1, G1, B1 = R1 / nfiles, G1 / nfiles, B1 / nfiles\n",
        "final = cv2.merge([B1, G1, R1])\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.imshow(cv2.cvtColor(image.astype(np.uint8), cv2.COLOR_BGR2RGB)), plt.axis('off')\n",
        "plt.title('An input image', size=20)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.imshow(cv2.cvtColor(final.astype(np.uint8), cv2.COLOR_BGR2RGB))\n",
        "plt.axis('off'), plt.title('Output image', size=20)\n",
        "plt.show()\n",
        "cv2.imwrite('images/godafost.png', final)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQM_ri0xgdNi",
        "colab_type": "text"
      },
      "source": [
        "### Extended Depth of Field with mahotas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcpfGktylI1j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install mahotas"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lS1Hi48CgdNj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://mahotas.readthedocs.io/en/latest/edf.html\n",
        "from glob import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "import mahotas as mh\n",
        "print(mh.__version__)\n",
        "\n",
        "def create_image_stack(vid_file, n = 200):\n",
        "    \n",
        "    vidcap = cv2.VideoCapture(vid_file)\n",
        "    success,image = vidcap.read()\n",
        "    i = 0\n",
        "    success = True\n",
        "    h, w = image.shape[:2]\n",
        "    imstack = np.zeros((n, h, w))\n",
        "    while success and i < n:\n",
        "      imstack[i,...] = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "      success,image = vidcap.read()\n",
        "      i += 1\n",
        "    return imstack\n",
        "\n",
        "image = create_image_stack('images/godafost.mp4') #cloud.mp4\n",
        "stack,h,w = image.shape\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.gray()\n",
        "plt.imshow(image[0,...].astype(np.uint8)), plt.axis('off')\n",
        "plt.title('An input image', size=20)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "focus = np.array([mh.sobel(t, just_filter=True) for t in image])\n",
        "best = np.argmax(focus, 0)\n",
        "image = image.reshape((stack,-1)) # image is now (stack, nr_pixels)\n",
        "image = image.transpose() # image is now (nr_pixels, stack)\n",
        "final = image[np.arange(len(image)), best.ravel()] # Select the right pixel at each location\n",
        "final = final.reshape((h,w)) # reshape to get final result\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.imshow(final.astype(np.uint8))\n",
        "plt.axis('off'), plt.title('Output image', size=20)\n",
        "plt.show()\n",
        "cv2.imwrite('images/edf.png', final)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyuD_TWPgdNl",
        "colab_type": "text"
      },
      "source": [
        "### Color Detection with opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SYC6UgagdNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%matplotlib inline\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "bck = cv2.imread(\"images/fish_bg.png\")\n",
        "img = cv2.imread(\"images/fish.png\")\n",
        "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "mask = cv2.inRange(hsv, (5, 75, 25), (25, 255, 255))\n",
        "\n",
        "## slice the orange fish\n",
        "imask = mask>0\n",
        "orange = np.zeros_like(img, np.uint8)\n",
        "orange[imask] = img[imask]\n",
        "\n",
        "yellow = img.copy()\n",
        "hsv[...,0] = hsv[...,0] + 20\n",
        "yellow[imask] = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)[imask]\n",
        "yellow = np.clip(yellow, 0, 255)\n",
        "\n",
        "bckfish = cv2.bitwise_and(bck,bck, mask=imask.astype(np.uint8))\n",
        "nofish = img.copy()\n",
        "nofish = cv2.bitwise_and(nofish,nofish, mask=(np.bitwise_not(imask)).astype(np.uint8))\n",
        "nofish = nofish + bckfish\n",
        "\n",
        "plt.figure(figsize=(20,12))\n",
        "plt.subplots_adjust(0,0,1,0.9,0.01,0.075)\n",
        "plt.subplot(221), plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)), plt.axis('off'), plt.title('original', size=20)\n",
        "plt.subplot(222), plt.imshow(cv2.cvtColor(orange, cv2.COLOR_BGR2RGB)), plt.axis('off'), plt.title('only fish', size=20)\n",
        "plt.subplot(223), plt.imshow(cv2.cvtColor(yellow, cv2.COLOR_BGR2RGB)), plt.axis('off'), plt.title('fish color changed', size=20)\n",
        "plt.subplot(224), plt.imshow(cv2.cvtColor(nofish, cv2.COLOR_BGR2RGB)), plt.axis('off'), plt.title('transparent fish', size=20)\n",
        "plt.suptitle('Color Detection with opencv-python', size=25)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l18mhd3SgdNn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}