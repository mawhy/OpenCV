{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Image Registration",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mawhy/OpenCV/blob/master/Image_Registration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tSrBKMUl2hQ",
        "colab_type": "text"
      },
      "source": [
        "# Image Processing CookBook\n",
        "## Image Registration\n",
        "In Polish means  \"nakładanie obrazów\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0kx8xEQ0dPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/PacktPublishing/Python-Image-Processing-Cookbook.git\n",
        "%cp -av \"/content/Python-Image-Processing-Cookbook/Chapter 05/images/\" \"/content/\"\n",
        "%cp -av \"/content/Python-Image-Processing-Cookbook/Chapter 05/models/\" \"/content/\"\n",
        "%rm -rf \"/content/Python-Image-Processing-Cookbook\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ygwzf0wnl2hR",
        "colab_type": "text"
      },
      "source": [
        "### Medical Image Registration with SimpleITK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_V5Qlmy0wkb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install SimpleITK"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bs0SiA5XoBV2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install \n",
        "!pip install opencv-python==4.2.0.34\n",
        "!pip install opencv-contrib-python==4.2.0.34"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBgdSGPGl2hS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://stackoverflow.com/questions/41692063/what-is-the-difference-between-image-registration-and-image-alignment\n",
        "# https://www.insight-journal.org/rire/download_training_data.php\n",
        "# https://itk.org/Wiki/SimpleITK/Tutorials/MICCAI2015\n",
        "%matplotlib inline\n",
        "import SimpleITK as sitk\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fixed_image =  sitk.ReadImage(\"images/ct_scan_11.jpg\", sitk.sitkFloat32)\n",
        "moving_image = sitk.ReadImage(\"images/mr_T1_06.jpg\", sitk.sitkFloat32) \n",
        "\n",
        "fixed_image_array = sitk.GetArrayFromImage(fixed_image)\n",
        "moving_image_array = sitk.GetArrayFromImage(moving_image)\n",
        "print(fixed_image_array.shape, moving_image_array.shape)\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.gray()\n",
        "plt.subplot(131), plt.imshow(fixed_image_array), plt.axis('off'), plt.title('CT-Scan Image', size=20)\n",
        "plt.subplot(132), plt.imshow(moving_image_array), plt.axis('off'), plt.title('MRI-T1 Image', size=20)\n",
        "plt.subplot(133), plt.imshow(0.6*fixed_image_array + 0.4*moving_image_array), plt.axis('off'), plt.title('Initial Alignment', size=20)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpS4H-Wql2hb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(2)\n",
        "registration_method = sitk.ImageRegistrationMethod()\n",
        "\n",
        "initial_transform = sitk.CenteredTransformInitializer(fixed_image, moving_image, sitk.Similarity2DTransform())\n",
        "   \n",
        "# Similarity metric settings.\n",
        "registration_method.SetMetricAsMattesMutualInformation(numberOfHistogramBins=50)\n",
        "registration_method.SetMetricSamplingStrategy(registration_method.RANDOM)\n",
        "registration_method.SetMetricSamplingPercentage(0.01)\n",
        "\n",
        "registration_method.SetInterpolator(sitk.sitkLinear)\n",
        "\n",
        "# Optimizer settings.\n",
        "registration_method.SetOptimizerAsGradientDescent(learningRate=1.0, numberOfIterations=100, convergenceMinimumValue=1e-6, convergenceWindowSize=10)\n",
        "registration_method.SetOptimizerScalesFromPhysicalShift()\n",
        "\n",
        "# Setup for the multi-resolution framework.            \n",
        "registration_method.SetShrinkFactorsPerLevel(shrinkFactors = [4,2,1])\n",
        "registration_method.SetSmoothingSigmasPerLevel(smoothingSigmas=[2,1,0])\n",
        "registration_method.SmoothingSigmasAreSpecifiedInPhysicalUnitsOn()\n",
        "\n",
        "# Don't optimize in-place, we would possibly like to run this cell multiple times.\n",
        "registration_method.SetInitialTransform(initial_transform, inPlace=False)\n",
        "\n",
        "final_transform = registration_method.Execute(sitk.Cast(fixed_image, sitk.sitkFloat32), \n",
        "                                               sitk.Cast(moving_image, sitk.sitkFloat32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rC0i82K2l2hd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(final_transform)\n",
        "resampler = sitk.ResampleImageFilter()\n",
        "resampler.SetReferenceImage(fixed_image);\n",
        "resampler.SetInterpolator(sitk.sitkLinear)\n",
        "resampler.SetDefaultPixelValue(100)\n",
        "resampler.SetTransform(final_transform)\n",
        " \n",
        "out = resampler.Execute(moving_image)\n",
        "simg1 = sitk.Cast(sitk.RescaleIntensity(fixed_image), sitk.sitkUInt8)\n",
        "simg2 = sitk.Cast(sitk.RescaleIntensity(out), sitk.sitkUInt8)\n",
        "cimg = sitk.Compose(simg1, simg2, simg1//2.+simg2//2.)\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.gray()\n",
        "plt.subplot(131), plt.imshow(fixed_image_array), plt.axis('off'), plt.title('CT-Scan Image', size=20)\n",
        "plt.subplot(132), plt.imshow(sitk.GetArrayFromImage(out)), plt.axis('off'), plt.title('Transformed MRI-T1 Image', size=20)\n",
        "plt.subplot(133), plt.imshow(sitk.GetArrayFromImage(cimg)), plt.axis('off'), plt.title('Final Alignment', size=20)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PUVQ88Fl2hg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://www.insight-journal.org/rire/download_training_data.php\n",
        "# https://itk.org/Wiki/SimpleITK/Tutorials/MICCAI2015\n",
        "import SimpleITK as sitk\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fixed =  sitk.ReadImage(\"images/mr_T1_01.jpg\", sitk.sitkFloat32)\n",
        "moving = sitk.ReadImage(\"images/mr_T1_01_trans.jpg\", sitk.sitkFloat32) \n",
        "\n",
        "R = sitk.ImageRegistrationMethod()\n",
        "R.SetMetricAsMeanSquares()\n",
        "R.SetOptimizerAsRegularStepGradientDescent(4.0, .01, 200 )\n",
        "R.SetInterpolator(sitk.sitkLinear)\n",
        "transfo = sitk.CenteredTransformInitializer(fixed, moving, sitk.Euler2DTransform())\n",
        "R.SetInitialTransform(transfo)\n",
        "outTx1 = R.Execute(fixed, moving)\n",
        "print(outTx1)\n",
        "print(\"Optimizer stop condition: {0}\".format(R.GetOptimizerStopConditionDescription()))\n",
        "print(\"Number of iterations: {0}\".format(R.GetOptimizerIteration()))\n",
        "R.SetMetricAsMattesMutualInformation(numberOfHistogramBins=50)\n",
        "R.SetOptimizerAsRegularStepGradientDescent(4.0, .01, 200 )\n",
        "R.SetInitialTransform(transfo)\n",
        "outTx2 = R.Execute(fixed, moving)\n",
        "print(outTx2)\n",
        "print(\"Optimizer stop condition: {0}\".format(R.GetOptimizerStopConditionDescription()))\n",
        "print(\"Number of iterations: {0}\".format(R.GetOptimizerIteration()))\n",
        "\n",
        "#sitk.WriteTransform(outTx, 'transfo_final.tfm')\n",
        "resampler = sitk.ResampleImageFilter()\n",
        "resampler.SetReferenceImage(fixed)\n",
        "resampler.SetInterpolator(sitk.sitkLinear)\n",
        "resampler.SetDefaultPixelValue(100)\n",
        "resampler.SetTransform(outTx1)\n",
        "out1 = resampler.Execute(moving)\n",
        "moving_image_array_trans1 = sitk.GetArrayFromImage(out1)\n",
        "simg1 = sitk.Cast(sitk.RescaleIntensity(fixed), sitk.sitkUInt8)\n",
        "simg2 = sitk.Cast(sitk.RescaleIntensity(out1), sitk.sitkUInt8)\n",
        "cimg1_array = sitk.GetArrayFromImage(sitk.Compose(simg1, simg2, simg1//2.+simg2//2.))\n",
        "resampler.SetTransform(outTx2)\n",
        "out2 = resampler.Execute(moving)\n",
        "moving_image_array_trans2 = sitk.GetArrayFromImage(out2)\n",
        "simg1 = sitk.Cast(sitk.RescaleIntensity(fixed), sitk.sitkUInt8)\n",
        "simg2 = sitk.Cast(sitk.RescaleIntensity(out2), sitk.sitkUInt8)\n",
        "cimg2_array = sitk.GetArrayFromImage(sitk.Compose(simg1, simg2, simg1//2.+simg2//2.))\n",
        "       \n",
        "fixed_image_array = sitk.GetArrayFromImage(fixed)\n",
        "moving_image_array = sitk.GetArrayFromImage(moving)\n",
        "print(fixed_image_array.shape, moving_image_array.shape)\n",
        "plt.figure(figsize=(20,30))\n",
        "plt.gray()\n",
        "plt.subplots_adjust(0,0,1,1,0.075,0.01)\n",
        "plt.subplot(321), plt.imshow(fixed_image_array), plt.axis('off'), plt.title('MR-T1 Image', size=20)\n",
        "plt.subplot(322), plt.imshow(moving_image_array), plt.axis('off'), plt.title('Shifted MR_T1 Image', size=20)\n",
        "plt.subplot(323), plt.imshow(fixed_image_array - moving_image_array_trans1), plt.axis('off'), plt.title('Difference Images (MeanSquare)', size=20)\n",
        "plt.subplot(324), plt.imshow(fixed_image_array - moving_image_array_trans2), plt.axis('off'), plt.title('Difference Images (MutualInformation)', size=20)\n",
        "plt.subplot(325), plt.imshow(cimg1_array), plt.axis('off'), plt.title('Aligned Images (MeanSquare)', size=20)\n",
        "plt.subplot(326), plt.imshow(cimg2_array), plt.axis('off'), plt.title('Aligned Images (MutualInformation)', size=20)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAGFedoLl2hi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkerboard = sitk.CheckerBoardImageFilter()\n",
        "before_reg_image = checkerboard.Execute (fixed, moving)\n",
        "after_reg_image = checkerboard.Execute (fixed, out2)\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.gray()\n",
        "plt.subplot(121), plt.imshow(sitk.GetArrayFromImage(before_reg_image)), plt.axis('off'), plt.title('Checkerboard before Registration Image', size=20)\n",
        "plt.subplot(122), plt.imshow(sitk.GetArrayFromImage(after_reg_image)), plt.axis('off'), plt.title('Checkerboard After Registration Image', size=20)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o64KqViKl2hl",
        "colab_type": "text"
      },
      "source": [
        "### Image Alignment with ECC algorithm\n",
        "[Good articles](https://www.learnopencv.com/image-alignment-ecc-in-opencv-c-python/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4rRqlNMl2hm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "print(cv2.__version__)\n",
        "# 4.2.0\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        " \n",
        "def compute_gradient(im) :\n",
        "    grad_x = cv2.Sobel(im,cv2.CV_32F,1,0,ksize=3)\n",
        "    grad_y = cv2.Sobel(im,cv2.CV_32F,0,1,ksize=3)\n",
        "    grad = cv2.addWeighted(np.absolute(grad_x), 0.5, np.absolute(grad_y), 0.5, 0)\n",
        "    return grad\n",
        "\n",
        "im_unaligned =  cv2.imread(\"images/me_unaligned.png\")\n",
        "\n",
        "height, width = im_unaligned.shape[:2]\n",
        "print(height, width)\n",
        "\n",
        "channels = ['B', 'G', 'R']\n",
        "\n",
        "plt.figure(figsize=(30,12))\n",
        "plt.gray()\n",
        "plt.subplot(1,4,1), plt.imshow(cv2.cvtColor(im_unaligned, cv2.COLOR_BGR2RGB)), plt.axis('off'), plt.title('Unaligned Image', size=20)\n",
        "for i in range(3):\n",
        "    plt.subplot(1,4,i+2), plt.imshow(im_unaligned[...,i]), plt.axis('off'), plt.title(channels[i], size=20)\n",
        "plt.suptitle('Unaligned Image and Color Channels', size=30)\n",
        "plt.show()\n",
        "\n",
        "# Initialize the output image with a copy of the input image\n",
        "im_aligned = im_unaligned.copy() \n",
        "\n",
        "# Define motion model\n",
        "warp_mode = cv2.MOTION_HOMOGRAPHY\n",
        "\n",
        "# Set the warp matrix to identity.\n",
        "warp_matrix = np.eye(3, 3, dtype=np.float32) if warp_mode == cv2.MOTION_HOMOGRAPHY else np.eye(2, 3, dtype=np.float32)\n",
        "\n",
        "# Set the stopping criteria for the algorithm.\n",
        "criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 500,  1e-6)\n",
        "\n",
        "# The blue and green channels will be aligned to the red channel, so compute the gradient of the red channel first\n",
        "im_grad2 = compute_gradient(im_unaligned[...,2])\n",
        "\n",
        "# Warp the blue and green channels to the red channel\n",
        "for i in range(2) :\n",
        "    print('Processing Channel {}...'.format(channels[i]))\n",
        "    (cc, warp_matrix) = cv2.findTransformECC (im_grad2, compute_gradient(im_unaligned[...,i]),warp_matrix, warp_mode, criteria, None, 5)\n",
        "\n",
        "    if warp_mode == cv2.MOTION_HOMOGRAPHY :\n",
        "        # Perspective warp - transformation is a Homography\n",
        "        im_aligned[...,i] = cv2.warpPerspective (im_unaligned[...,i], warp_matrix, (width,height), flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n",
        "    else :\n",
        "        # Affine warp - transformation is not a Homography\n",
        "        im_aligned[...,i] = cv2.warpAffine(im_unaligned[...,i], warp_matrix, (width, height), flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP);\n",
        "    print (warp_matrix)\n",
        "    \n",
        "channels = ['B', 'G', 'R']\n",
        "plt.figure(figsize=(30,12))\n",
        "plt.subplot(1,4,1), plt.imshow(cv2.cvtColor(im_aligned, cv2.COLOR_BGR2RGB)), plt.axis('off'), plt.title('Aligned Image (ECC)', size=20)\n",
        "for i in range(3):\n",
        "    plt.subplot(1,4,i+2), plt.imshow(im_aligned[...,i]), plt.axis('off'), plt.title(channels[i], size=20)\n",
        "plt.suptitle('Aligned Image and Color Channels', size=30)\n",
        "plt.show()\n",
        "\n",
        "cv2.imwrite(\"images/me_aligned.png\", im_aligned)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ez9mIo_vl2ho",
        "colab_type": "text"
      },
      "source": [
        "### Face Alignment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Egqyak6l2hp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imutils.face_utils import FaceAligner\n",
        "from imutils.face_utils import rect_to_bb\n",
        "import imutils\n",
        "import dlib\n",
        "import cv2\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "# initialize dlib's face detector (HOG-based) and then create\n",
        "# the facial landmark predictor and the face aligner\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor('models/shape_predictor_68_face_landmarks.dat')\n",
        "face_aligner = FaceAligner(predictor, desiredFaceWidth=256) \n",
        "# load the input image, resize it, and convert it to grayscale\n",
        "image = cv2.imread('images/scientists.png')\n",
        "image = imutils.resize(image, width=800)\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        " \n",
        "# show the original input image and detect faces in the grayscale image\n",
        "plt.figure(figsize=(20,20))\n",
        "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB)), plt.axis('off')\n",
        "plt.title('Original Image: Famous Indian Scientists', size=20)\n",
        "plt.show()\n",
        "rects = detector(gray, 2)\n",
        "print('Number of faces detected:', len(rects))\n",
        "i = 1\n",
        "# loop over the face detections\n",
        "plt.figure(figsize=(10,20))\n",
        "plt.subplots_adjust(0,0,1,1,0.05,0.12)\n",
        "for rect in rects:\n",
        "    # extract the ROI of the *original* face, then align the face\n",
        "    # using facial landmarks\n",
        "    (x, y, w, h) = rect_to_bb(rect)\n",
        "    face_original = imutils.resize(image[y:y + h, x:x + w], width=256)\n",
        "    face_aligned = face_aligner.align(image, gray, rect)\n",
        "\n",
        "    # display the output images\n",
        "    plt.subplot(9,4,i), plt.imshow(cv2.cvtColor(face_original, cv2.COLOR_BGR2RGB)), plt.title(\"Original\", size=15), plt.axis('off')\n",
        "    plt.subplot(9,4,i+1), plt.imshow(cv2.cvtColor(face_aligned, cv2.COLOR_BGR2RGB)), plt.title(\"Aligned\", size=15), plt.axis('off')\n",
        "    i += 2\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnyRjGe_l2hr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import dlib\n",
        "import cv2\n",
        "from imutils import face_utils\n",
        "from skimage.transform import AffineTransform, warp\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "# initialize dlib's face detector (HOG-based) and then create\n",
        "# the facial landmark predictor and the face aligner\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor('models/shape_predictor_68_face_landmarks.dat')\n",
        "# load the input image, resize it, and convert it to grayscale\n",
        "image = cv2.imread('images/monalisa.png')\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "rects = detector(gray, 2)\n",
        "\n",
        "faces = []\n",
        "face_landmarks = []\n",
        "for (i, rect) in enumerate(rects):\n",
        "    shape = predictor(gray, rect)\n",
        "    shape = face_utils.shape_to_np(shape)\n",
        "    (left, top, w, h) = face_utils.rect_to_bb(rect)\n",
        "    faces.append(image[top:top+h, left:left+w])\n",
        "    landmark = []\n",
        "    for (x, y) in shape:\n",
        "        cv2.circle(image, (x, y), 1, (0, 255, 0), 2)\n",
        "        landmark.append([x-left,y-top])\n",
        "    face_landmarks.append(np.array(landmark))\n",
        "        \n",
        "plt.figure(figsize=(20,13))\n",
        "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB)), plt.axis('off'), plt.title('Original image with Facial landmarks', size=20)\n",
        "plt.show()\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.subplot(121), plt.imshow(cv2.cvtColor(faces[0], cv2.COLOR_BGR2RGB)), plt.axis('off'), plt.title('Right Face', size=20)\n",
        "plt.subplot(122), plt.imshow(cv2.cvtColor(faces[1], cv2.COLOR_BGR2RGB)), plt.axis('off'), plt.title('Left Face', size=20)\n",
        "plt.show()\n",
        "\n",
        "transform = AffineTransform()\n",
        "transform.estimate(face_landmarks[0], face_landmarks[1])\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.gray()\n",
        "plt.imshow(warp(cv2.cvtColor(faces[1], cv2.COLOR_BGR2RGB), transform, output_shape=faces[0].shape)), plt.axis('off'), plt.title('Warped right image on the left image', size=20)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zCBlX6gl2hu",
        "colab_type": "text"
      },
      "source": [
        "### Face Morphing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tn4v551l2hu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.spatial import Delaunay\n",
        "from scipy import interpolate\n",
        "from skimage.io import imread\n",
        "import scipy.misc\n",
        "import cv2\n",
        "import dlib\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Find 68 face landmarks using dlib\n",
        "def get_face_landmarks(image, predictor_path = 'models/shape_predictor_68_face_landmarks.dat'):\n",
        "  detector = dlib.get_frontal_face_detector()\n",
        "  predictor = dlib.shape_predictor(predictor_path)\n",
        "  try:\n",
        "    dets = detector(image, 1)\n",
        "    points = np.zeros((68, 2))\n",
        "    for k, d in enumerate(dets):\n",
        "        # get the landmarks for the face in box d.\n",
        "        shape = predictor(image, d)\n",
        "        for i in range(68):\n",
        "            points[i, 0] = shape.part(i).x\n",
        "            points[i, 1] = shape.part(i).y\n",
        "  except Exception as e:\n",
        "    print('Failed finding face points: ', e)\n",
        "    return []\n",
        "  points = points.astype(np.int32)\n",
        "  return points\n",
        "\n",
        "def weighted_average_points(start_points, end_points, percent=0.5):\n",
        "  # Weighted average of two sets of supplied points\n",
        "  if percent <= 0:   return end_points\n",
        "  elif percent >= 1: return start_points\n",
        "  else: return np.asarray(start_points*percent + end_points*(1-percent), np.int32)\n",
        "\n",
        "def weighted_average(img1, img2, percent=0.5):\n",
        "  if percent <= 0: return img2\n",
        "  elif percent >= 1: return img1\n",
        "  else: return cv2.addWeighted(img1, percent, img2, 1-percent, 0)\n",
        "\n",
        "# interpolates over every image channel\n",
        "def bilinear_interpolate(img, coords):\n",
        "  int_coords = coords.astype(np.int32)\n",
        "  x0, y0 = int_coords\n",
        "  dx, dy = coords - int_coords\n",
        "  # 4 neighour pixels\n",
        "  q11, q21, q12, q22 = img[y0, x0], img[y0, x0+1], img[y0+1, x0], img[y0+1, x0+1]\n",
        "  btm = q21.T * dx + q11.T * (1 - dx)\n",
        "  top = q22.T * dx + q12.T * (1 - dx)\n",
        "  interpolated_pixels = top * dy + btm * (1 - dy)\n",
        "  return interpolated_pixels.T\n",
        "\n",
        "# generate x,y grid coordinates within the ROI of supplied points\n",
        "def get_grid_coordinates(points):\n",
        "  xmin, xmax = np.min(points[:, 0]), np.max(points[:, 0]) + 1\n",
        "  ymin, ymax = np.min(points[:, 1]), np.max(points[:, 1]) + 1\n",
        "  return np.asarray([(x, y) for y in range(ymin, ymax) for x in range(xmin, xmax)], np.uint32)\n",
        "\n",
        "# warp each triangle from the src_image only within the ROI of the destination image (points in dst_points).\n",
        "def process_warp(src_img, result_img, tri_affines, dst_points, delaunay):\n",
        "  roi_coords = get_grid_coordinates(dst_points)\n",
        "  # indices to vertices. -1 if pixel is not in any triangle\n",
        "  roi_tri_indices = delaunay.find_simplex(roi_coords)\n",
        "  for simplex_index in range(len(delaunay.simplices)):\n",
        "    coords = roi_coords[roi_tri_indices == simplex_index]\n",
        "    num_coords = len(coords)\n",
        "    out_coords = np.dot(tri_affines[simplex_index], np.vstack((coords.T, np.ones(num_coords))))\n",
        "    x, y = coords.T\n",
        "    result_img[y, x] = bilinear_interpolate(src_img, out_coords)\n",
        "\n",
        "# calculate the affine transformation matrix for each triangle vertex (x,y) from dest_points to src_points\n",
        "def gen_triangular_affine_matrices(vertices, src_points, dest_points):\n",
        "  ones = [1, 1, 1]\n",
        "  for tri_indices in vertices:\n",
        "    src_tri = np.vstack((src_points[tri_indices, :].T, ones))\n",
        "    dst_tri = np.vstack((dest_points[tri_indices, :].T, ones))\n",
        "    mat = np.dot(src_tri, np.linalg.inv(dst_tri))[:2, :]\n",
        "    yield mat\n",
        "\n",
        "def warp_image(src_img, src_points, dest_points, dest_shape):\n",
        "  num_chans = 3\n",
        "  src_img = src_img[:, :, :3]\n",
        "  rows, cols = dest_shape[:2]\n",
        "  result_img = np.zeros((rows, cols, num_chans), np.uint8)\n",
        "  delaunay = Delaunay(dest_points)\n",
        "  tri_affines = np.asarray(list(gen_triangular_affine_matrices(delaunay.simplices, src_points, dest_points)))\n",
        "  process_warp(src_img, result_img, tri_affines, dest_points, delaunay)\n",
        "  return result_img, delaunay\n",
        "\n",
        "def read_lion_landmarks():    \n",
        "    with open(\"models/lion_face_landmark.txt\") as key_file:\n",
        "        keypoints = [list(map(int, line.split())) for line in key_file]\n",
        "        return(np.array(keypoints))\n",
        "\n",
        "# load images\n",
        "src_path = 'images/me.png'\n",
        "dst_path = 'images/lion.png' \n",
        "\n",
        "src_img = imread(src_path)\n",
        "dst_img = imread(dst_path)\n",
        "\n",
        "size = dst_img.shape[:2]\n",
        "\n",
        "src_img = cv2.resize(src_img[...,:3], size)\n",
        "\n",
        "# define control points for warps\n",
        "src_points = get_face_landmarks(src_img)\n",
        "dst_points = read_lion_landmarks()\n",
        "\n",
        "points = weighted_average_points(src_points, dst_points, percent=50)\n",
        "src_face, src_delaunay = warp_image(src_img, src_points, points, size)\n",
        "end_face, end_delaunay = warp_image(dst_img, dst_points, points, size)\n",
        "\n",
        "print('here', len(src_points), len(dst_points))\n",
        "  \n",
        "fig = plt.figure(figsize=(20,10))\n",
        "plt.subplot(121), plt.imshow(src_img)\n",
        "for i in range(len(src_points)):\n",
        "    plt.plot(src_points[i,0], src_points[i,1], 'r.', markersize=20)\n",
        "plt.title('Source image', size=20), plt.axis('off')\n",
        "plt.subplot(122), plt.imshow(dst_img)\n",
        "for i in range(len(dst_points)):\n",
        "    plt.plot(dst_points[i,0], dst_points[i,1], 'g.', markersize=20)\n",
        "plt.title('Destination image', size=20), plt.axis('off')\n",
        "plt.suptitle('Facial Landmarks computed for the images', size=30)\n",
        "fig.subplots_adjust(wspace=0.01, left=0.1, right=0.9)\n",
        "plt.show()\n",
        "fig = plt.figure(figsize=(20,10))\n",
        "plt.subplot(121), plt.imshow(src_img)\n",
        "plt.triplot(src_points[:,0], src_points[:,1], src_delaunay.simplices.copy())\n",
        "plt.plot(src_points[:,0], src_points[:,1], 'o', color='red'), plt.title('Source image', size=20), plt.axis('off')\n",
        "plt.subplot(122), plt.imshow(dst_img)\n",
        "plt.triplot(dst_points[:,0], dst_points[:,1], end_delaunay.simplices.copy())\n",
        "plt.plot(dst_points[:,0], dst_points[:,1], 'o'), plt.title('Destination image', size=20), plt.axis('off')\n",
        "plt.suptitle('Delaunay triangulation of the images', size=30)\n",
        "fig.subplots_adjust(wspace=0.01, left=0.1, right=0.9)\n",
        "plt.show()\n",
        "\n",
        "fig = plt.figure(figsize=(18,20))\n",
        "fig.subplots_adjust(top=0.925, bottom=0, left=0, right=1, wspace=0.01, hspace=0.08)\n",
        "i = 1\n",
        "for percent in np.linspace(1, 0, 16):\n",
        "    points = weighted_average_points(src_points, dst_points, percent)\n",
        "    src_face, src_delaunay = warp_image(src_img, src_points, points, size)\n",
        "    end_face, end_delaunay = warp_image(dst_img, dst_points, points, size)\n",
        "    average_face = weighted_average(src_face, end_face, percent)\n",
        "    plt.subplot(4,4,i), plt.imshow(average_face), plt.title('alpha=' + str(round(percent,4)), size=20), plt.axis('off')\n",
        "    i += 1\n",
        "plt.suptitle('Face morphing', size=30)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qhyq4cRZl2hw",
        "colab_type": "text"
      },
      "source": [
        "### Robust Matching with RANSAC Algorithm using Harris Corner Brief Descriptors\n",
        "[Praca badawcza](https://www.researchgate.net/publication/292995470_Image_Features_Detection_Description_and_Matching)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szF-Rg7Xl2hx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage.feature import (corner_harris, corner_peaks, BRIEF, match_descriptors, plot_matches)\n",
        "from skimage.transform import ProjectiveTransform, warp\n",
        "from skimage.measure import ransac\n",
        "from skimage.io import imread\n",
        "from skimage.color import rgb2gray\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "np.random.seed(2)\n",
        "\n",
        "img1 = rgb2gray(imread('images/victoria3.png'))\n",
        "img2 = rgb2gray(imread('images/victoria4.png'))\n",
        "keypoints1 = corner_peaks(corner_harris(img1), min_distance=1)\n",
        "keypoints2 = corner_peaks(corner_harris(img2), min_distance=1)\n",
        "extractor = BRIEF(patch_size=10)\n",
        "extractor.extract(img1, keypoints1)\n",
        "descriptors1 = extractor.descriptors\n",
        "extractor.extract(img2, keypoints2)\n",
        "descriptors2 = extractor.descriptors\n",
        "matches = match_descriptors(descriptors1, descriptors2)\n",
        "\n",
        "src_keypoints = keypoints1[matches[:,0]]\n",
        "dst_keypoints = keypoints2[matches[:,1]]\n",
        "\n",
        "homography = ProjectiveTransform()\n",
        "homography.estimate(src_keypoints, dst_keypoints)\n",
        "\n",
        "\n",
        "homography_robust, inliers = ransac((src_keypoints, dst_keypoints), ProjectiveTransform, min_samples=4,\n",
        "                               residual_threshold=2, max_trials=500)\n",
        "outliers = inliers == False\n",
        "print(len(matches))\n",
        "\n",
        "robust_matches = match_descriptors(descriptors1[matches[:,0]][inliers], descriptors2[matches[:,1]][inliers])\n",
        "print(len(robust_matches))\n",
        "\n",
        "fig, ax = plt.subplots(nrows=2, ncols=2, sharex=True, sharey=True, figsize=(20,15))\n",
        "plt.gray()\n",
        "plt.subplots_adjust(0,0,1,1,0.05,0.05)\n",
        "plot_matches(ax[0,0], img1, img2, keypoints1, keypoints2, matches), ax[0,0].set_title('Matching without RANSAC', size=20)\n",
        "ax[0,1].imshow(warp(img2, homography, output_shape=img2.shape)), ax[0,1].set_title('Homography without RANSAC', size=20)\n",
        "plot_matches(ax[1,0], img1, img2, keypoints1, keypoints2, robust_matches), ax[1,0].set_title('Robust Matching with RANSAC', size=20)\n",
        "ax[1,1].imshow(warp(img2, homography_robust, output_shape=img2.shape)), ax[1,1].set_title('Robust Homography with RANSAC', size=20)\n",
        "for a in np.ravel(ax):\n",
        "    a.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehKTzvqZqmQ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "!pip install opencv-python==3.4.2.16\n",
        "!pip install opencv-contrib-python==3.4.2.16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ty6LxJIFl2hz",
        "colab_type": "text"
      },
      "source": [
        "### Image Mosaicing (Cylindrical Panorama)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0AOwX9ql2h0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "# for this problem let's work with opencv 3.4.2.16\n",
        "print(cv2.__version__)\n",
        "# 3.4.2\n",
        "# pip install opencv-contrib-python==3.4.2.16\n",
        "# pip install opencv-python==3.4.2.16\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import math\n",
        "import glob\n",
        "\n",
        "def compute_homography(image1, image2, bff_match=False):\n",
        "\n",
        "    sift = cv2.xfeatures2d.SIFT_create(edgeThreshold=10, sigma=1.5, contrastThreshold=0.08)\n",
        "    \n",
        "    kp1, des1 = sift.detectAndCompute(image1, None)\n",
        "    kp2, des2 = sift.detectAndCompute(image2, None)\n",
        "\n",
        "    # Brute force matching\n",
        "    bf = cv2.BFMatcher()\n",
        "    matches = bf.knnMatch(des1, trainDescriptors=des2, k=2)\n",
        "\n",
        "    # Lowes Ratio\n",
        "    good_matches = []\n",
        "    for m, n in matches:\n",
        "        if m.distance < .75 * n.distance:\n",
        "            good_matches.append(m)\n",
        "\n",
        "    src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches])\\\n",
        "        .reshape(-1, 1, 2)\n",
        "    dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches])\\\n",
        "        .reshape(-1, 1, 2)\n",
        "\n",
        "    if len(src_pts) > 4:\n",
        "        H, mask = cv2.findHomography(dst_pts, src_pts, cv2.RANSAC, 5)\n",
        "    else:\n",
        "        H = np.array([[0, 0, 0], [0, 0, 0], [0, 0, 0]])\n",
        "    return H\n",
        "\n",
        "\n",
        "def warp_image(image, H):\n",
        "\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2BGRA)\n",
        "    h, w, _ = image.shape\n",
        "\n",
        "    # Find min and max x, y of new image\n",
        "    p = np.array([[0, w, w, 0], [0, 0, h, h], [1, 1, 1, 1]])\n",
        "    p_prime = np.dot(H, p)\n",
        "\n",
        "    yrow = p_prime[1] / p_prime[2]\n",
        "    xrow = p_prime[0] / p_prime[2]\n",
        "    ymin = min(yrow)\n",
        "    xmin = min(xrow)\n",
        "    ymax = max(yrow)\n",
        "    xmax = max(xrow)\n",
        "\n",
        "    # Create a new matrix that removes offset and multiply by homography\n",
        "    new_mat = np.array([[1, 0, -1 * xmin], [0, 1, -1 * ymin], [0, 0, 1]])\n",
        "    H = np.dot(new_mat, H)\n",
        "\n",
        "    # height and width of new image frame\n",
        "    height = int(round(ymax - ymin))\n",
        "    width = int(round(xmax - xmin))\n",
        "    size = (width, height)\n",
        "    # Do the warp\n",
        "    warped = cv2.warpPerspective(src=image, M=H, dsize=size)\n",
        "\n",
        "    return warped, (int(xmin), int(ymin))\n",
        "\n",
        "def cylindrical_warp_image(img, H):\n",
        "    \n",
        "    h, w = img.shape[:2]\n",
        "    # pixel coordinates\n",
        "    y_i, x_i = np.indices((h, w))\n",
        "    X = np.stack([x_i,y_i,np.ones_like(x_i)],axis=-1).reshape(h*w, 3) # to homog\n",
        "    Hinv = np.linalg.inv(H) \n",
        "    X = Hinv.dot(X.T).T # normalized coords\n",
        "    # calculate cylindrical coords (sin\\theta, h, cos\\theta)\n",
        "    A = np.stack([np.sin(X[:,0]),X[:,1],np.cos(X[:,0])],axis=-1).reshape(w*h, 3)\n",
        "    B = H.dot(A.T).T # project back to image-pixels plane\n",
        "    # back from homog coords\n",
        "    B = B[:,:-1] / B[:,[-1]]\n",
        "    # make sure warp coords only within image bounds\n",
        "    B[(B[:,0] < 0) | (B[:,0] >= w) | (B[:,1] < 0) | (B[:,1] >= h)] = -1\n",
        "    B = B.reshape(h,w,-1)\n",
        "    \n",
        "    img_rgba = cv2.cvtColor(img,cv2.COLOR_BGR2BGRA) # for transparent borders...\n",
        "    # warp the image according to cylindrical coords\n",
        "    return cv2.remap(img_rgba, B[:,:,0].astype(np.float32), B[:,:,1].astype(np.float32), cv2.INTER_AREA, borderMode=cv2.BORDER_TRANSPARENT)\n",
        "\n",
        "def create_mosaic(images, origins):\n",
        "    # find central image\n",
        "    for i in range(0, len(origins)):\n",
        "        if origins[i] == (0, 0):\n",
        "            central_index = i\n",
        "            break\n",
        "\n",
        "    central_image = images[central_index]\n",
        "    central_origin = origins[central_index]\n",
        "    \n",
        "    # zip origins and images together\n",
        "    zipped = list(zip(origins, images))\n",
        "    \n",
        "    # sort by distance from origin (highest to lowest)\n",
        "    func = lambda x: math.sqrt(x[0][0] ** 2 + x[0][1] ** 2)\n",
        "    dist_sorted = sorted(zipped, key=func, reverse=True)\n",
        "    # sort by x value\n",
        "    x_sorted = sorted(zipped, key=lambda x: x[0][0])\n",
        "    # sort by y value\n",
        "    y_sorted = sorted(zipped, key=lambda x: x[0][1])\n",
        "\n",
        "    # determine the coordinates in the new frame of the central image\n",
        "    if x_sorted[0][0][0] > 0:\n",
        "        cent_x = 0  # leftmost image is central image\n",
        "    else:\n",
        "        cent_x = abs(x_sorted[0][0][0])\n",
        "\n",
        "    if y_sorted[0][0][1] > 0:\n",
        "        cent_y = 0  # topmost image is central image\n",
        "    else:\n",
        "        cent_y = abs(y_sorted[0][0][1])\n",
        "\n",
        "    # make a new list of the starting points in new frame of each image\n",
        "    spots = []\n",
        "    for origin in origins:\n",
        "        spots.append((origin[0]+cent_x, origin[1] + cent_y))\n",
        "\n",
        "    zipped = zip(spots, images)\n",
        "\n",
        "    # get height and width of new frame\n",
        "    total_height = 0\n",
        "    total_width = 0\n",
        "\n",
        "    for spot, image in zipped:\n",
        "        total_width = max(total_width, spot[0]+image.shape[1])\n",
        "        total_height = max(total_height, spot[1]+image.shape[0])\n",
        "\n",
        "    # print \"height \", total_height\n",
        "    # print \"width \", total_width\n",
        "\n",
        "    # new frame of panorama\n",
        "    stitch = np.zeros((total_height, total_width, 4), np.uint8)\n",
        "\n",
        "    # stitch images into frame by order of distance\n",
        "    for image in dist_sorted:\n",
        "        \n",
        "        offset_y = image[0][1] + cent_y\n",
        "        offset_x = image[0][0] + cent_x\n",
        "        end_y = offset_y + image[1].shape[0]\n",
        "        end_x = offset_x + image[1].shape[1]\n",
        "        \n",
        "        ####\n",
        "        stitch_cur = stitch[offset_y:end_y, offset_x:end_x, :4]\n",
        "        stitch_cur[image[1]>0] = image[1][image[1]>0]\n",
        "        ####\n",
        "                \n",
        "        #stitch[offset_y:end_y, offset_x:end_x, :4] = image[1]\n",
        "\n",
        "    return stitch\n",
        "\n",
        "def create_panorama(images, center):\n",
        "    \n",
        "    h,w,_ = images[0].shape\n",
        "    f = 1000 # 800\n",
        "    H = np.array([[f, 0, w/2], [0, f, h/2], [0, 0, 1]])\n",
        "    for i in range(len(images)):\n",
        "        images[i] = cylindrical_warp_image(images[i], H)\n",
        "    \n",
        "    panorama = None\n",
        "    for i in range(center):\n",
        "        print('Stitching images {}, {}'.format(i+1, i+2))\n",
        "        image_warped, image_origin = warp_image(images[i], compute_homography(images[i + 1], images[i]))\n",
        "        panorama = create_mosaic([image_warped, images[i+1]], [image_origin, (0,0)])\n",
        "        images[i + 1] = panorama\n",
        "\n",
        "    #print('Done left part')\n",
        "\n",
        "    for i in range(center, len(images)-1):\n",
        "        print('Stitching images {}, {}'.format(i+1, i+2))\n",
        "        image_warped, image_origin = warp_image(images[i+1], compute_homography(images[i], images[i + 1]))\n",
        "        panorama = create_mosaic([images[i], image_warped], [(0,0), image_origin])\n",
        "        images[i + 1] = panorama\n",
        "\n",
        "    #print('Done right part')\n",
        "    return panorama\n",
        "\n",
        "images = [ cv2.cvtColor(cv2.imread(img), cv2.COLOR_RGB2RGBA) for img in glob.glob('images/victoria*.png')]\n",
        "\n",
        "plt.figure(figsize=(20,4))\n",
        "plt.subplots_adjust(top = 0.8, bottom = 0, right = 1, left = 0, hspace = 0, wspace = 0.05)\n",
        "plt.margins(0,0)\n",
        "for i in range(len(images)):\n",
        "    plt.subplot(1,len(images),i+1), plt.imshow(cv2.cvtColor(images[i], cv2.COLOR_BGR2RGB)), plt.axis('off'), plt.title('Image {}'.format(i+1), size=15)\n",
        "plt.suptitle('Images to Stitch', size=20)\n",
        "plt.show()\n",
        "\n",
        "center = len(images) // 2\n",
        "#print(len(images), center)\n",
        "\n",
        "panorama = create_panorama(images, center)\n",
        "\n",
        "plt.figure(figsize=(20,8))\n",
        "plt.subplots_adjust(top = 0.9, bottom = 0, right = 1, left = 0, hspace = 0, wspace = 0)\n",
        "plt.margins(0,0)\n",
        "plt.imshow(cv2.cvtColor(panorama, cv2.COLOR_BGR2RGB)), plt.axis('off'), plt.title('Final Panorama Image', size=15)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "4IDidofTl2h2",
        "colab_type": "text"
      },
      "source": [
        "### Panorama with opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKaj8bcJl2h2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import glob\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "print(cv2.__version__)\n",
        "# 3.4.2\n",
        "\n",
        "# grab the paths to the input images and initialize our images list\n",
        "print(\"Loading images...\")\n",
        "images = [ cv2.cvtColor(cv2.imread(img), cv2.COLOR_BGR2RGB) for img in glob.glob('images/victoria*.png')]\n",
        "print('Number of images to stitch: {}'.format(len(images)))\n",
        "fig = plt.figure(figsize=(20, 5))\n",
        "for i in range(len(images)):\n",
        "    plt.subplot(1,len(images),i+1)\n",
        "    plt.imshow(images[i])\n",
        "    plt.axis('off')\n",
        "fig.subplots_adjust(left=0, right=1, bottom=0, top=0.95, hspace=0.05, wspace=0.05) \n",
        "plt.suptitle('Images to stich', size=25)\n",
        "plt.show()\n",
        "\n",
        "# initialize OpenCV's image sticher object and then perform the image\n",
        "# stitching\n",
        "print(\"Stitching images...\")\n",
        "stitcher = cv2.createStitcher()\n",
        "(status, stitched) = stitcher.stitch(images)\n",
        "print(status)\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.imshow(stitched), plt.axis('off'), plt.title('Final Panorama Image', size=20)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wkwtpFEl2h4",
        "colab_type": "text"
      },
      "source": [
        "### Finding similarity between an image and a set of images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DzUZFIql2h5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "print(cv2.__version__)\n",
        "# 3.4.2\n",
        "import numpy as np\n",
        "import glob\n",
        "import matplotlib.pylab as plt\n",
        "from collections import defaultdict\n",
        "\n",
        "query = cv2.imread(\"images/query.png\", cv2.CV_8U)\n",
        "\n",
        "matched_images = defaultdict(list)\n",
        "for image_file in glob.glob('images/search/*.png'):\n",
        "    \n",
        "    search_image = cv2.imread(image_file, cv2.CV_8U)\n",
        "    sift = cv2.xfeatures2d.SIFT_create()\n",
        "    kp_1, desc_1 = sift.detectAndCompute(query, None)\n",
        "    kp_2, desc_2 = sift.detectAndCompute(search_image, None)\n",
        "    index_params = dict(algorithm=0, trees=5)\n",
        "    search_params = dict()\n",
        "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "    matches = flann.knnMatch(desc_1, desc_2, k=2)\n",
        "    good_points = []\n",
        "    ratio = 0.6\n",
        "    for m, n in matches:\n",
        "        if m.distance < ratio*n.distance:\n",
        "            good_points.append(m)\n",
        "    num_good_points = len(good_points)\n",
        "    print('Image file = {}, Number of good matches = {}'.format(image_file, num_good_points))\n",
        "    if (num_good_points > 300) or (num_good_points < 10):\n",
        "        result = cv2.drawMatches(query, kp_1, search_image, kp_2, good_points, None)\n",
        "        plt.figure(figsize=(20,10))\n",
        "        plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB)), plt.axis('off')\n",
        "        plt.title(('Good match' if num_good_points > 300 else 'Poor match') + ' with {} matches'.format(num_good_points), size=20)\n",
        "        plt.show()\n",
        "\n",
        "    matched_images[len(good_points)].append(search_image)\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.gray()\n",
        "plt.imshow(query), plt.axis('off')\n",
        "plt.title('Original (Query) Image', size=20)\n",
        "plt.show()\n",
        "\n",
        "i = 1\n",
        "plt.figure(figsize=(20,35))\n",
        "plt.subplots_adjust(left=0, right=1, bottom=0, top=0.925, wspace=0.02, hspace=0.1)\n",
        "for num_matches in sorted(matched_images, reverse=True):\n",
        "    for image in matched_images[num_matches]:\n",
        "        plt.subplot(10, 4, i)\n",
        "        plt.imshow(image)\n",
        "        plt.axis('off')\n",
        "        plt.title('Image with {} good matches'.format(num_matches), size=15)\n",
        "        i += 1\n",
        "plt.suptitle('Images matched with the Query Image ranked by the number of good matches', size=20)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exHTZwVyl2h7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "query.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-XlocOWl2iA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://www.kaggle.com/duttadebadri/image-classification/downloads/image-classification.zip/2"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}